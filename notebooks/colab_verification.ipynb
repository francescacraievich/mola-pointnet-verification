{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PointNet Verification with α,β-CROWN on Google Colab\n",
    "\n",
    "This notebook verifies PointNet robustness using α,β-CROWN.\n",
    "Google Colab provides GPUs with 15GB VRAM (T4), enough for verification with large epsilon values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install torch numpy onnx onnxruntime pyyaml packaging\n",
    "!git clone https://github.com/Verified-Intelligence/alpha-beta-CROWN.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup files - assumes you uploaded:\n",
    "# - pointnet.pth\n",
    "# - test_groups.npy  \n",
    "# - test_labels.npy\n",
    "# to /content/\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Create folders\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('data/pointnet', exist_ok=True)\n",
    "\n",
    "# Copy files to correct locations\n",
    "shutil.copy('/content/pointnet.pth', 'models/pointnet.pth')\n",
    "shutil.copy('/content/test_groups.npy', 'data/pointnet/test_groups.npy')\n",
    "shutil.copy('/content/test_labels.npy', 'data/pointnet/test_labels.npy')\n",
    "\n",
    "print(\"Files ready!\")\n",
    "!ls -la models/\n",
    "!ls -la data/pointnet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PointNet Model Definition\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PointNetForVerification(nn.Module):\n",
    "    \"\"\"\n",
    "    PointNet for verification with T-Net (Spatial Transformer).\n",
    "    Based on: Qi et al., \"PointNet: Deep Learning on Point Sets\" (CVPR 2017)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_points=64, num_classes=2, use_tnet=True, pooling=\"max\"):\n",
    "        super().__init__()\n",
    "        self.num_points = num_points\n",
    "        self.num_classes = num_classes\n",
    "        self.use_tnet = use_tnet\n",
    "        self.pooling = pooling\n",
    "\n",
    "        if use_tnet:\n",
    "            # Input T-Net (3x3 transformation matrix)\n",
    "            self.tnet_conv1 = nn.Conv1d(3, 64, 1)\n",
    "            self.tnet_conv2 = nn.Conv1d(64, 128, 1)\n",
    "            self.tnet_conv3 = nn.Conv1d(128, 256, 1)\n",
    "            self.tnet_fc1 = nn.Linear(256, 128)\n",
    "            self.tnet_fc2 = nn.Linear(128, 64)\n",
    "            self.tnet_fc3 = nn.Linear(64, 9)\n",
    "            self.tnet_fc3.weight.data.zero_()\n",
    "            self.tnet_fc3.bias.data.copy_(torch.eye(3).view(-1))\n",
    "\n",
    "        # Point-wise MLP\n",
    "        self.conv1 = nn.Conv1d(3, 64, 1)\n",
    "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = nn.Conv1d(128, 256, 1)\n",
    "\n",
    "        # Classifier\n",
    "        self.fc1 = nn.Linear(256, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        if x.dim() == 2:\n",
    "            x = x.view(batch_size, self.num_points, 3)\n",
    "\n",
    "        if self.use_tnet:\n",
    "            x_t = x.transpose(1, 2)\n",
    "            t = F.relu(self.tnet_conv1(x_t))\n",
    "            t = F.relu(self.tnet_conv2(t))\n",
    "            t = F.relu(self.tnet_conv3(t))\n",
    "            if self.pooling == \"mean\":\n",
    "                t = torch.mean(t, dim=2)\n",
    "            else:\n",
    "                t = torch.max(t, dim=2)[0]\n",
    "            t = F.relu(self.tnet_fc1(t))\n",
    "            t = F.relu(self.tnet_fc2(t))\n",
    "            t = self.tnet_fc3(t)\n",
    "            t = t.view(batch_size, 3, 3)\n",
    "            x = torch.bmm(x, t)\n",
    "\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "\n",
    "        if self.pooling == \"mean\":\n",
    "            x = torch.mean(x, dim=2)\n",
    "        else:\n",
    "            x = torch.max(x, dim=2)[0]\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "print(\"PointNet model defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup alpha-beta-CROWN\n",
    "import sys\n",
    "sys.path.insert(0, '/content/alpha-beta-CROWN/complete_verifier')\n",
    "\n",
    "import numpy as np\n",
    "from api import ABCrownSolver, ConfigBuilder, VerificationSpec, input_vars, output_vars\n",
    "\n",
    "print(\"α,β-CROWN imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and data\n",
    "model = PointNetForVerification(num_points=64, num_classes=2, use_tnet=True, pooling=\"max\")\n",
    "checkpoint = torch.load('models/pointnet.pth', map_location='cpu', weights_only=True)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "X_test = np.load('data/pointnet/test_groups.npy')\n",
    "y_test = np.load('data/pointnet/test_labels.npy')\n",
    "\n",
    "print(f\"Model loaded successfully!\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "print(f\"Sample shape: {X_test[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_sample(model, sample, label, epsilon, timeout=120):\n",
    "    \"\"\"Verify a single sample using alpha-beta-CROWN.\"\"\"\n",
    "    if sample.shape == (3, 64):\n",
    "        sample_flat = sample.T.flatten()\n",
    "    else:\n",
    "        sample_flat = sample.flatten()\n",
    "\n",
    "    x = input_vars(192)\n",
    "    y = output_vars(2)\n",
    "\n",
    "    input_constraint = (x >= sample_flat - epsilon) & (x <= sample_flat + epsilon)\n",
    "    output_constraint = y[label] > y[1 - label]\n",
    "\n",
    "    spec = VerificationSpec.build_spec(\n",
    "        input_vars=x, output_vars=y,\n",
    "        input_constraint=input_constraint,\n",
    "        output_constraint=output_constraint,\n",
    "    )\n",
    "\n",
    "    cfg = ConfigBuilder.from_defaults().set(\n",
    "        bab__timeout=timeout,\n",
    "        general__enable_incomplete_verification=True,\n",
    "        general__complete_verifier=\"bab\",\n",
    "        general__conv_mode=\"matrix\",\n",
    "        attack__pgd_order=\"before\",\n",
    "        attack__pgd_steps=100,\n",
    "        attack__pgd_restarts=30,\n",
    "    )\n",
    "\n",
    "    solver = ABCrownSolver(spec, model, config=cfg)\n",
    "    result = solver.solve()\n",
    "\n",
    "    verified = result.status in [\"safe\", \"safe-incomplete\", \"verified\", \"unsat\"]\n",
    "    return {\"status\": result.status, \"verified\": verified}\n",
    "\n",
    "print(\"Verification function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run verification for multiple epsilon values\n",
    "# 0.04 ~ 6cm, 0.05 ~ 7.5cm (comparable to NSGA-III perturbations)\n",
    "epsilons = [0.005, 0.01, 0.02, 0.04, 0.05]\n",
    "n_samples = 10\n",
    "\n",
    "results = {}\n",
    "\n",
    "for eps in epsilons:\n",
    "    cm = eps * 150\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Epsilon: {eps} (~{cm:.1f} cm)\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    verified_count = 0\n",
    "    unsafe_count = 0\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        sample = X_test[i]\n",
    "        label = int(y_test[i])\n",
    "\n",
    "        try:\n",
    "            result = verify_sample(model, sample, label, eps)\n",
    "            status = \"VERIFIED\" if result[\"verified\"] else f\"UNSAFE ({result['status']})\"\n",
    "            if result[\"verified\"]:\n",
    "                verified_count += 1\n",
    "            else:\n",
    "                unsafe_count += 1\n",
    "        except Exception as e:\n",
    "            status = f\"ERROR: {str(e)[:50]}\"\n",
    "            unsafe_count += 1\n",
    "\n",
    "        print(f\"  Sample {i} (label={label}): {status}\")\n",
    "\n",
    "    results[eps] = {\n",
    "        \"cm\": cm,\n",
    "        \"verified\": verified_count,\n",
    "        \"unsafe\": unsafe_count,\n",
    "        \"verified_pct\": 100 * verified_count / n_samples\n",
    "    }\n",
    "\n",
    "    print(f\"\\nSummary: Verified={verified_count}/{n_samples} ({100*verified_count/n_samples:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL RESULTS - PointNet MAX-POOLING with T-Net\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Epsilon':>8} | {'~cm':>6} | {'Verified':>10} | {'Unsafe':>10}\")\n",
    "print(\"-\"*45)\n",
    "for eps, r in results.items():\n",
    "    print(f\"{eps:>8.3f} | {r['cm']:>5.1f}  | {r['verified_pct']:>8.1f}%  | {100-r['verified_pct']:>8.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Comparison with NSGA-III (SLAM attack):\")\n",
    "print(\"  NSGA-III perturbations: 0.98 - 5.02 cm\")\n",
    "print(\"  SLAM baseline error: 23 cm\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "import json\n",
    "from google.colab import files\n",
    "\n",
    "with open('verification_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"Results saved!\")\n",
    "print(json.dumps(results, indent=2))\n",
    "\n",
    "# Download results\n",
    "files.download('verification_results.json')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
