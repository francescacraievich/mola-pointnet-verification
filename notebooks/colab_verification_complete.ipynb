{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": "# PointNet Vanilla Training & Verification with α,β-CROWN\n\n## LiDAR Point Cloud Classification + Formal Verification\n\nThis notebook:\n1. **Loads** raw LiDAR frames (~14M points) from your repository\n2. **Loads NSGA-III Pareto genomes** for vulnerability-based labeling\n3. **Runs QUICK SANITY CHECK** before full training (5 epochs + 3 verification tests)\n4. **Trains** PointNet Vanilla with data augmentation on GPU (50 epochs)\n5. **Verifies** robustness properties using α,β-CROWN API\n\n### Key Innovation: NSGA-III Vulnerability Labeling\nLabels are computed using **MAX vulnerability across all Pareto-optimal genomes**:\n- 5 genomes from NSGA-III optimization (different attack strategies)\n- A region is CRITICAL if vulnerable to ANY of these attacks\n- Threshold derived from data (median vulnerability)\n- Direct link between \"what breaks SLAM\" and \"what PointNet should detect\"\n\n### Architecture: PointNet Vanilla (Qi et al., CVPR 2017)\n\n**Why Vanilla (no T-Net)?**\nBased on the ablation study in the original paper:\n- PointNet with T-Net: 89.2% accuracy on ModelNet40\n- PointNet **without** T-Net: 88.6% accuracy (**only 0.6% difference!**)\n\nBenefits of Vanilla architecture:\n1. **Memory**: Saves ~1-2GB GPU (no torch.bmm / BoundMatMul)\n2. **Verification**: Much better compatibility with α,β-CROWN\n3. **Scientific validity**: Ablation study proves minimal accuracy loss\n\n**Architecture:**\n- Point-wise MLP: 3→64→64→64→128→1024 (5 conv layers with BatchNorm)\n- **Single MaxPool**: Well-supported by recent auto_LiRPA versions\n- Classifier MLP: 1024→512→256→2 (with BatchNorm + Dropout)\n- **~1.8M parameters** (vs ~3.5M with T-Net)\n\n### Input Format: (N, 1024, 3) - xyz only!\n- xyz coordinates (3 channels)\n- **Note**: Geometric features (linearity, curvature, density_var, planarity) \n  are used for **labeling only**, NOT as input to the model.\n\n### Properties Verified:\n\n**Property 1: Local Robustness (L∞)**\n```\n∀x' with ||x' - x₀||∞ ≤ ε : f(x') = f(x₀)\n```\n\n**Property 2: Safety Property**\n```\n∀x' with ||x' - x₀||∞ ≤ ε ∧ f(x₀)=CRITICAL : f(x') ≠ NON_CRITICAL\n```\n\n### Memory Optimization\n- Aggressive cleanup with `gc.collect()` + `torch.cuda.empty_cache()`\n- Training model moved to CPU before verification\n- Cleanup between each verification sample"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-header"
   },
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "check-gpu",
    "outputId": "1f7e5966-0893-4601-80da-4cea0ecaf7c9"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fri Jan  2 17:52:23 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   40C    P8              9W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Check GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-deps"
   },
   "outputs": [],
   "source": "# Install dependencies\n!pip install torch numpy onnx onnxruntime pyyaml packaging appdirs sortedcontainers path.py -q\n\n# Clone alpha-beta-CROWN repository (for complete_verifier API)\n!git clone https://github.com/Verified-Intelligence/alpha-beta-CROWN.git 2>/dev/null || true\n\n# Install auto_LiRPA directly from GitHub\n!pip install git+https://github.com/Verified-Intelligence/auto_LiRPA.git --no-deps -q\n\nprint(\"Dependencies installed!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "setup-paths",
    "outputId": "455c08e7-7358-4737-e315-c83ad964d345"
   },
   "outputs": [],
   "source": "# Setup paths and imports\nimport sys\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nimport json\nfrom datetime import datetime\nfrom torch.utils.data import TensorDataset, DataLoader\n\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nprint(f\"PyTorch: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\nprint(f\"Device: {device}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "la7wHTOP6faN"
   },
   "outputs": [],
   "source": "# Import auto_LiRPA for verification\nfrom auto_LiRPA import BoundedModule, BoundedTensor, PerturbationLpNorm\nprint(\"auto_LiRPA imported successfully!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bkAEM9RK6r-8",
    "outputId": "4687c6aa-78f5-488e-a302-fa7486ef2bc7"
   },
   "outputs": [],
   "source": "# Set random seeds for reproducibility\nimport random\nrandom.seed(42)\nnp.random.seed(42)\ntorch.manual_seed(42)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(42)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "import-abcrown",
    "outputId": "a2de54de-d57a-4c9f-a5c4-e855e34a7b61"
   },
   "outputs": [],
   "source": "# Configuration\nN_POINTS = 1024        # Points per sample (original PointNet)\nIN_CHANNELS = 3        # xyz only! Model must learn geometry from raw coordinates\nNUM_CLASSES = 2        # CRITICAL vs NON_CRITICAL\nINPUT_DIM = N_POINTS * IN_CHANNELS  # 3072\n\n# Training config\nEPOCHS = 50\nBATCH_SIZE = 32\nLEARNING_RATE = 0.001\n\n# Verification config\nEPSILONS = [0.001, 0.003, 0.005, 0.007, 0.01]  # L-inf perturbation budgets\nN_VERIFY_SAMPLES = 20  # Samples to verify\n\nprint(f\"Configuration:\")\nprint(f\"  Points per sample: {N_POINTS}\")\nprint(f\"  Input channels: {IN_CHANNELS} (xyz only - features used for labeling only)\")\nprint(f\"  Input dimension: {INPUT_DIM}\")\nprint(f\"  Classes: {NUM_CLASSES}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model-header"
   },
   "source": "## 2. Load Data from GitHub\n\nData files are stored in the repository using Git LFS in `data/pointnet/`."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "model-defs",
    "outputId": "6202eee1-130e-43c3-8e9f-7d4c4f77b684"
   },
   "outputs": [],
   "source": "# Clone repository and fetch Git LFS data\nimport os\nimport shutil\n\nREPO_URL = \"https://github.com/francescacraievich/mola-pointnet-verification.git\"\nREPO_DIR = \"/content/mola-pointnet-verification\"\nRAW_DATA_PATH = f\"{REPO_DIR}/data/raw\"\n\n# Force re-clone to get latest data (remove old clone if exists)\nif os.path.exists(REPO_DIR):\n    print(f\"Removing old clone at {REPO_DIR}...\")\n    shutil.rmtree(REPO_DIR)\n\n# Install and setup Git LFS\nprint(\"Setting up Git LFS...\")\n!git lfs install\n\n# Clone with LFS\nprint(\"\\nCloning repository...\")\n!git clone {REPO_URL} {REPO_DIR}\n\n# Pull LFS files explicitly\nprint(\"\\nFetching LFS files...\")\n%cd {REPO_DIR}\n!git lfs pull\n%cd /content\n\nprint(\"\\nDone!\")\n\n# Verify raw data files exist\nprint(\"\\nChecking data files:\")\nraw_files = ['frame_sequence.npy', 'frame_sequence.timestamps.npy']\nfor f in raw_files:\n    path = os.path.join(RAW_DATA_PATH, f)\n    if os.path.exists(path):\n        size = os.path.getsize(path) / 1e6\n        print(f\"  ✓ {f}: {size:.1f} MB\")\n    else:\n        print(f\"  ✗ {f}: NOT FOUND\")\n        \n# Also check if files are LFS pointers (small size = pointer, not actual data)\nframe_path = os.path.join(RAW_DATA_PATH, 'frame_sequence.npy')\nif os.path.exists(frame_path):\n    size = os.path.getsize(frame_path)\n    if size < 1000:  # Less than 1KB = probably a pointer\n        print(f\"\\n⚠ WARNING: frame_sequence.npy is only {size} bytes - likely a Git LFS pointer!\")\n        print(\"   Running 'git lfs pull' again...\")\n        %cd {REPO_DIR}\n        !git lfs fetch --all\n        !git lfs checkout\n        %cd /content\n        # Check again\n        size = os.path.getsize(frame_path)\n        print(f\"   After LFS fetch: {size / 1e6:.1f} MB\")"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "data-header"
   },
   "source": "# Load raw frames and compute features ONCE (cached)\nfrom scipy.spatial import cKDTree\n\ndef compute_local_features(points, k=15):\n    \"\"\"\n    Compute geometric features for each point in the cloud.\n    \n    Returns:\n        linearity: Edge/line feature strength\n        curvature: Surface curvature  \n        density_var: Local density variation (scanline vulnerability)\n        planarity: How planar the local neighborhood is\n    \"\"\"\n    n = len(points)\n    xyz = points[:, :3]\n    \n    # Subsample for speed if too large\n    max_points = 50000\n    if n > max_points:\n        sample_idx = np.random.choice(n, max_points, replace=False)\n        xyz_sample = xyz[sample_idx]\n    else:\n        sample_idx = np.arange(n)\n        xyz_sample = xyz\n    \n    tree = cKDTree(xyz_sample)\n    distances, neighbors_idx = tree.query(xyz_sample, k=min(k + 1, len(xyz_sample)))\n    \n    linearity = np.zeros(len(xyz_sample))\n    curvature = np.zeros(len(xyz_sample))\n    planarity = np.zeros(len(xyz_sample))\n    \n    # Compute density variation\n    mean_dist = distances[:, 1:].mean(axis=1)\n    std_dist = distances[:, 1:].std(axis=1)\n    density_var = std_dist / (mean_dist + 1e-10)\n    \n    # Compute eigenvalue-based features\n    for i in range(len(xyz_sample)):\n        neighbors = xyz_sample[neighbors_idx[i]]\n        centered = neighbors - neighbors.mean(axis=0)\n        \n        if len(centered) >= 3:\n            cov = np.cov(centered.T)\n            try:\n                eigvals = np.sort(np.linalg.eigvalsh(cov))[::-1]\n                total = eigvals.sum() + 1e-10\n                linearity[i] = (eigvals[0] - eigvals[1]) / (eigvals[0] + 1e-10)\n                curvature[i] = eigvals[2] / total\n                planarity[i] = (eigvals[1] - eigvals[2]) / (eigvals[0] + 1e-10)\n            except:\n                pass\n    \n    # Map back to full point cloud if subsampled\n    if n > max_points:\n        _, nearest = tree.query(xyz, k=1)\n        return linearity[nearest], curvature[nearest], density_var[nearest], planarity[nearest]\n    \n    return linearity, curvature, density_var, planarity\n\n\n# Load frames\nprint(\"Loading raw frame sequence...\")\nframes = np.load(os.path.join(RAW_DATA_PATH, 'frame_sequence.npy'), allow_pickle=True)\nprint(f\"Loaded {len(frames)} frames\")\n\n# Count total points\ntotal_points = sum(len(f) for f in frames)\nprint(f\"Total points: {total_points:,}\")\nprint(f\"Average points per frame: {total_points // len(frames):,}\")\n\n# Pre-compute features for each frame (do this ONCE)\nprint(\"\\nPre-computing geometric features for each frame...\")\nprint(\"(This takes a few minutes but only happens once)\")\n\nframe_features = []\nfor i, frame in enumerate(frames):\n    if (i + 1) % 10 == 0:\n        print(f\"  Processing frame {i+1}/{len(frames)}...\")\n    \n    linearity, curvature, density_var, planarity = compute_local_features(frame, k=15)\n    \n    # Store features alongside frame\n    frame_features.append({\n        'xyz': frame[:, :3],\n        'linearity': linearity,\n        'curvature': curvature,\n        'density_var': density_var,\n        'planarity': planarity,\n    })\n\nprint(f\"\\nFeatures computed for all {len(frames)} frames!\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Load NSGA-III derived weights for labeling\n# This creates a direct link between adversarial attack results and PointNet training\n\n# Detect environment: Colab or local\nimport sys\nimport os\n\n# Check if running on Colab\nON_COLAB = 'google.colab' in sys.modules\n\nif ON_COLAB:\n    # On Colab, use the cloned repo path\n    SRC_PATH = REPO_DIR + '/src'\n    RUNS_PATH = REPO_DIR + '/runs'\nelse:\n    # Running locally - find the src directory relative to notebook\n    # notebooks/ is at the same level as src/\n    notebook_dir = os.path.dirname(os.path.abspath('__file__'))\n    if os.path.exists('../src'):\n        SRC_PATH = '../src'\n        RUNS_PATH = '../runs'\n    elif os.path.exists('src'):\n        SRC_PATH = 'src'\n        RUNS_PATH = 'runs'\n    else:\n        # Try absolute path from notebook location\n        SRC_PATH = '/home/francesca/mola-pointnet-verification/src'\n        RUNS_PATH = '/home/francesca/mola-pointnet-verification/runs'\n\nprint(f\"Environment: {'Colab' if ON_COLAB else 'Local'}\")\nprint(f\"Source path: {SRC_PATH}\")\nprint(f\"Runs path: {RUNS_PATH}\")\n\n# Add src to Python path\nif SRC_PATH not in sys.path:\n    sys.path.insert(0, SRC_PATH)\n\ntry:\n    from nsga3_integration import get_criticality_weights, get_pareto_front_summary\n    print(\"✓ nsga3_integration module loaded successfully!\")\n    \n    # Get weights - will use fallback if NSGA-III results not found\n    CRITICALITY_WEIGHTS = get_criticality_weights(\n        nsga3_results_dir=RUNS_PATH if os.path.exists(RUNS_PATH) else None,\n        run_id=10,  # Use latest run\n        fallback_weights={\n            \"linearity\": 0.0,\n            \"curvature\": 0.15,\n            \"density_var\": 0.25,\n            \"nonplanarity\": 0.60,\n        }\n    )\n    \n    # Try to get Pareto front summary for analysis\n    if os.path.exists(RUNS_PATH):\n        try:\n            pareto_summary = get_pareto_front_summary(RUNS_PATH, run_id=10)\n            if pareto_summary:\n                print(f\"\\nNSGA-III Pareto Front Summary:\")\n                print(f\"  Solutions: {pareto_summary.get('n_solutions', 'N/A')}\")\n                print(f\"  Best ATE: {pareto_summary.get('best_ate_cm', 'N/A'):.1f} cm\")\n                print(f\"  Baseline ATE: {pareto_summary.get('baseline_ate_cm', 23):.1f} cm\")\n                print(f\"  Critical threshold: {pareto_summary.get('critical_threshold_cm', 1.5):.1f} cm perturbation\")\n        except Exception as e:\n            print(f\"Could not load Pareto summary: {e}\")\n            \nexcept ImportError as e:\n    print(f\"nsga3_integration module not found: {e}\")\n    print(\"Using default weights...\")\n    CRITICALITY_WEIGHTS = {\n        \"linearity\": 0.0,\n        \"curvature\": 0.15,\n        \"density_var\": 0.25,\n        \"nonplanarity\": 0.60,\n    }\n\nprint(f\"\\nCriticality weights for labeling:\")\nfor feat, weight in CRITICALITY_WEIGHTS.items():\n    print(f\"  {feat}: {weight:.4f}\")\nprint(f\"\\nThese weights determine which regions are labeled as CRITICAL vs NON_CRITICAL\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "setup-files",
    "outputId": "d8e62543-ffe4-49e8-c042-299821f16a5c"
   },
   "outputs": [],
   "source": "# Load Pareto set from NSGA-III results for vulnerability-based labeling\n# This must come BEFORE creating datasets!\n\nfrom nsga3_integration import (\n    load_pareto_set,\n    compute_max_vulnerability,\n    compute_vulnerability_label,\n)\n\n# Load Pareto-optimal genomes (5 solutions from NSGA-III)\n# RUNS_PATH was defined in previous cell\nPARETO_SET = load_pareto_set(RUNS_PATH, run_id=10)\n\nif PARETO_SET is not None:\n    print(f\"✓ Loaded Pareto set: {PARETO_SET.shape} ({PARETO_SET.shape[0]} genomes)\")\n    \n    # Compute threshold from data (median vulnerability)\n    print(\"\\nComputing vulnerability distribution for threshold selection...\")\n    test_vulns = []\n    for i in range(100):\n        # Sample random neighborhood\n        frame_idx = np.random.randint(0, len(frame_features))\n        ff = frame_features[frame_idx]\n        seed_idx = np.random.randint(0, len(ff['xyz']))\n        \n        # Get neighborhood\n        tree = cKDTree(ff['xyz'])\n        _, neighbor_idx = tree.query(ff['xyz'][seed_idx], k=N_POINTS)\n        points = ff['xyz'][neighbor_idx]\n        points = points - points.mean(axis=0)  # Center\n        \n        curvature = ff['curvature'][neighbor_idx]\n        linearity = ff['linearity'][neighbor_idx]\n        \n        vuln = compute_max_vulnerability(points, PARETO_SET, curvature, linearity)\n        test_vulns.append(vuln)\n    \n    VULNERABILITY_THRESHOLD = float(np.median(test_vulns))\n    print(f\"\\nVulnerability statistics:\")\n    print(f\"  Min: {np.min(test_vulns):.4f}\")\n    print(f\"  Max: {np.max(test_vulns):.4f}\")\n    print(f\"  Mean: {np.mean(test_vulns):.4f}\")\n    print(f\"  Median (THRESHOLD): {VULNERABILITY_THRESHOLD:.4f}\")\nelse:\n    print(\"⚠ Pareto set not found - using fallback threshold\")\n    PARETO_SET = None\n    VULNERABILITY_THRESHOLD = 0.4"
  },
  {
   "cell_type": "markdown",
   "source": "## 2.5 Create Datasets with NSGA-III Vulnerability Labeling\n\nNow we create the training and test datasets using the Pareto genomes for labeling.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# On-the-fly Dataset class with Data Augmentation\n# Uses NSGA-III vulnerability-based labeling (genome-driven, not linear formula!)\nfrom torch.utils.data import Dataset\n\nclass LiDAROnTheFlyDataset(Dataset):\n    \"\"\"\n    Dataset that samples point cloud groups ON-THE-FLY from raw LiDAR frames.\n    \n    Each __getitem__ call samples a random local neighborhood from a random frame,\n    so the model sees different samples every epoch.\n    \n    **IMPORTANT**: Returns only xyz (3 channels) as input!\n    Geometric features are computed for LABELING only, not as model input.\n    \n    **LABELING**: Uses NSGA-III Pareto genomes to compute vulnerability.\n    A region is CRITICAL if it's vulnerable to ANY of the Pareto-optimal attacks.\n    \"\"\"\n    \n    def __init__(self, frame_features, pareto_set=None, threshold=0.5, \n                 fallback_weights=None, n_points=1024, samples_per_epoch=10000, \n                 seed=None, augment=False):\n        self.frame_features = frame_features\n        self.pareto_set = pareto_set\n        self.threshold = threshold\n        self.fallback_weights = fallback_weights or {\n            \"linearity\": 0.0,\n            \"curvature\": 0.15,\n            \"density_var\": 0.25,\n            \"nonplanarity\": 0.60,\n        }\n        self.n_points = n_points\n        self.samples_per_epoch = samples_per_epoch\n        self.seed = seed\n        self.augment = augment\n        \n        # Build KD-trees for each frame (once)\n        self.trees = [cKDTree(ff['xyz']) for ff in frame_features]\n        \n        # Frame weights based on number of points\n        self.frame_weights = np.array([len(ff['xyz']) for ff in frame_features])\n        self.frame_weights = self.frame_weights / self.frame_weights.sum()\n    \n    def __len__(self):\n        return self.samples_per_epoch\n    \n    def _augment_xyz(self, xyz):\n        \"\"\"Apply augmentation to xyz coordinates.\"\"\"\n        theta = np.random.uniform(0, 2 * np.pi)\n        cos_t, sin_t = np.cos(theta), np.sin(theta)\n        rotation = np.array([[cos_t, -sin_t, 0], [sin_t, cos_t, 0], [0, 0, 1]])\n        xyz = xyz @ rotation.T\n        scale = np.random.uniform(0.9, 1.1)\n        xyz = xyz * scale\n        jitter = np.random.normal(0, 0.01, size=xyz.shape)\n        xyz = xyz + jitter\n        return xyz.astype(np.float32)\n    \n    def __getitem__(self, idx):\n        if self.seed is not None:\n            np.random.seed(self.seed + idx)\n        \n        frame_idx = np.random.choice(len(self.frame_features), p=self.frame_weights)\n        ff = self.frame_features[frame_idx]\n        tree = self.trees[frame_idx]\n        xyz = ff['xyz']\n        \n        seed_idx = np.random.randint(0, len(xyz))\n        _, neighbor_idx = tree.query(xyz[seed_idx], k=self.n_points)\n        \n        if len(neighbor_idx) < self.n_points:\n            neighbor_idx = np.pad(neighbor_idx, (0, self.n_points - len(neighbor_idx)), mode='edge')\n        \n        group_xyz = xyz[neighbor_idx].copy()\n        group_xyz = group_xyz - group_xyz.mean(axis=0)\n        max_dist = np.abs(group_xyz).max()\n        if max_dist > 0:\n            group_xyz = group_xyz / max_dist\n        \n        if self.augment:\n            group_xyz = self._augment_xyz(group_xyz)\n        \n        # Extract features FOR LABELING ONLY\n        group_linearity = ff['linearity'][neighbor_idx]\n        group_curvature = ff['curvature'][neighbor_idx]\n        group_density_var = ff['density_var'][neighbor_idx]\n        group_planarity = ff['planarity'][neighbor_idx]\n        \n        # Random point dropout during training\n        if self.augment and np.random.random() < 0.3:\n            dropout_ratio = np.random.uniform(0.05, 0.15)\n            n_dropout = int(self.n_points * dropout_ratio)\n            dropout_idx = np.random.choice(self.n_points, n_dropout, replace=False)\n            keep_idx = np.setdiff1d(np.arange(self.n_points), dropout_idx)\n            replace_idx = np.random.choice(keep_idx, n_dropout, replace=True)\n            group_xyz[dropout_idx] = group_xyz[replace_idx]\n        \n        group = group_xyz.astype(np.float32)\n        \n        # Compute label using NSGA-III vulnerability (if available)\n        if self.pareto_set is not None:\n            label = compute_vulnerability_label(\n                group_xyz, self.pareto_set, self.threshold,\n                group_curvature, group_linearity\n            )\n        else:\n            # Fallback: use linear formula\n            def normalize(f):\n                f_min, f_max = f.min(), f.max()\n                return (f - f_min) / (f_max - f_min + 1e-6)\n            \n            score = (\n                normalize(group_linearity).mean() * self.fallback_weights.get(\"linearity\", 0.0) +\n                normalize(group_curvature).mean() * self.fallback_weights.get(\"curvature\", 0.0) +\n                normalize(group_density_var).mean() * self.fallback_weights.get(\"density_var\", 0.0) +\n                (1 - normalize(group_planarity).mean()) * self.fallback_weights.get(\"nonplanarity\", 0.0)\n            )\n            label = 0 if score >= 0.4 else 1\n        \n        return torch.from_numpy(group), label\n\n\n# Create datasets\nprint(\"Creating on-the-fly datasets with NSGA-III vulnerability labeling...\")\n\nif PARETO_SET is not None:\n    print(f\"Using {PARETO_SET.shape[0]} Pareto-optimal genomes for labeling\")\n    print(f\"Vulnerability threshold: {VULNERABILITY_THRESHOLD:.4f}\")\nelse:\n    print(\"Pareto set not available - using fallback weights\")\n\ntrain_dataset = LiDAROnTheFlyDataset(\n    frame_features, pareto_set=PARETO_SET, threshold=VULNERABILITY_THRESHOLD,\n    fallback_weights=CRITICALITY_WEIGHTS, n_points=N_POINTS,\n    samples_per_epoch=20000, seed=None, augment=True\n)\n\ntest_dataset = LiDAROnTheFlyDataset(\n    frame_features, pareto_set=PARETO_SET, threshold=VULNERABILITY_THRESHOLD,\n    fallback_weights=CRITICALITY_WEIGHTS, n_points=N_POINTS,\n    samples_per_epoch=4000, seed=42, augment=False\n)\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n\nprint(f\"\\nTrain: {len(train_dataset)} samples/epoch ({len(train_loader)} batches)\")\nprint(f\"Test: {len(test_dataset)} samples ({len(test_loader)} batches)\")\nprint(f\"Labeling: {'NSGA-III vulnerability (MAX across genomes)' if PARETO_SET is not None else 'Fallback weights'}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 3. PointNet Vanilla Model Definition\n\n**Based on the ablation study in Qi et al., \"PointNet: Deep Learning on Point Sets\" (CVPR 2017):**\n- PointNet with T-Net: 89.2% accuracy on ModelNet40\n- PointNet **without** T-Net: 88.6% accuracy (only 0.6% difference!)\n\n**Why Vanilla (no T-Net)?**\n1. **Memory**: T-Net uses `torch.bmm` which creates BoundMatMul - ~1-2GB extra GPU memory\n2. **Compatibility**: auto_LiRPA handles Conv1d+BatchNorm1d better without T-Net\n3. **Scientific validity**: Ablation study shows minimal accuracy difference\n\n**Architecture:**\n- **Point MLP**: 3→64→64→64→128→1024 with BatchNorm\n- **Single MaxPool**: Well-supported by recent auto_LiRPA versions\n- **Classifier**: 1024→512→256→2 with BatchNorm + Dropout(0.3)\n\n**Verification Method: CROWN** (backward bound propagation)\n- Tighter bounds than IBP\n- Well-supported for MaxPool1d in recent auto_LiRPA\n\n**Input**: (batch, 1024, 3) - xyz coordinates only!",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import gc\n\nclass PointNetVanilla(nn.Module):\n    \"\"\"\n    PointNet Vanilla - WITHOUT T-Net, optimized for verification.\n    \n    Based on ablation study in Qi et al. (CVPR 2017):\n    - With T-Net: 89.2% accuracy\n    - Without T-Net: 88.6% accuracy (only 0.6% difference!)\n    \n    Features:\n    - NO T-Net (saves ~1-2GB GPU memory, avoids torch.bmm issues)\n    - Single MaxPool (well-supported by recent auto_LiRPA)\n    - 5 conv layers: 3→64→64→64→128→1024\n    - BatchNorm on all layers\n    - Dropout(0.3) in classifier (training only)\n    \n    Input format: (batch, n_points, in_channels)\n    \"\"\"\n    def __init__(\n        self,\n        num_points=1024,\n        num_classes=2,\n        in_channels=3,\n        max_features=1024,\n    ):\n        super().__init__()\n        \n        self.num_points = num_points\n        self.num_classes = num_classes\n        self.in_channels = in_channels\n        self.max_features = max_features\n        self.input_dim = num_points * in_channels\n        \n        # Point-wise MLP (5 conv layers as in original PointNet)\n        self.conv1 = nn.Conv1d(in_channels, 64, 1)\n        self.conv2 = nn.Conv1d(64, 64, 1)\n        self.conv3 = nn.Conv1d(64, 64, 1)\n        self.conv4 = nn.Conv1d(64, 128, 1)\n        self.conv5 = nn.Conv1d(128, max_features, 1)\n        \n        self.bn1 = nn.BatchNorm1d(64)\n        self.bn2 = nn.BatchNorm1d(64)\n        self.bn3 = nn.BatchNorm1d(64)\n        self.bn4 = nn.BatchNorm1d(128)\n        self.bn5 = nn.BatchNorm1d(max_features)\n        \n        # Single MaxPool (well-supported by recent auto_LiRPA versions)\n        self.pooling = nn.MaxPool1d(kernel_size=num_points)\n        \n        # Classifier MLP\n        self.fc1 = nn.Linear(max_features, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, num_classes)\n        \n        self.bn_fc1 = nn.BatchNorm1d(512)\n        self.bn_fc2 = nn.BatchNorm1d(256)\n        self.dropout = nn.Dropout(p=0.3)\n    \n    def forward(self, x):\n        batch_size = x.shape[0]\n        \n        # Handle flattened input\n        if x.dim() == 2:\n            x = x.view(batch_size, self.num_points, self.in_channels)\n        \n        # Point-wise MLP\n        x = x.transpose(1, 2)  # (batch, in_channels, n_points)\n        x = F.relu(self.bn1(self.conv1(x)))  # (batch, 64, n_points)\n        x = F.relu(self.bn2(self.conv2(x)))  # (batch, 64, n_points)\n        x = F.relu(self.bn3(self.conv3(x)))  # (batch, 64, n_points)\n        x = F.relu(self.bn4(self.conv4(x)))  # (batch, 128, n_points)\n        x = F.relu(self.bn5(self.conv5(x)))  # (batch, max_features, n_points)\n        \n        # Global MaxPool\n        x = self.pooling(x)  # (batch, max_features, 1)\n        x = x.view(batch_size, self.max_features)  # (batch, max_features)\n        \n        # Classifier\n        x = F.relu(self.bn_fc1(self.fc1(x)))\n        x = self.dropout(x)\n        x = F.relu(self.bn_fc2(self.fc2(x)))\n        x = self.dropout(x)\n        x = self.fc3(x)\n        \n        return x\n\n\nclass PointNetVanillaVerify(nn.Module):\n    \"\"\"\n    PointNet Vanilla for α,β-CROWN Verification - NO Dropout.\n    \n    Same as PointNetVanilla but without Dropout for verification.\n    (Dropout + BatchNorm1d with batch_size=1 causes issues in auto_LiRPA)\n    \"\"\"\n    def __init__(\n        self,\n        num_points=1024,\n        num_classes=2,\n        in_channels=3,\n        max_features=1024,\n    ):\n        super().__init__()\n        \n        self.num_points = num_points\n        self.num_classes = num_classes\n        self.in_channels = in_channels\n        self.max_features = max_features\n        self.input_dim = num_points * in_channels\n        \n        # Point-wise MLP\n        self.conv1 = nn.Conv1d(in_channels, 64, 1)\n        self.conv2 = nn.Conv1d(64, 64, 1)\n        self.conv3 = nn.Conv1d(64, 64, 1)\n        self.conv4 = nn.Conv1d(64, 128, 1)\n        self.conv5 = nn.Conv1d(128, max_features, 1)\n        \n        self.bn1 = nn.BatchNorm1d(64)\n        self.bn2 = nn.BatchNorm1d(64)\n        self.bn3 = nn.BatchNorm1d(64)\n        self.bn4 = nn.BatchNorm1d(128)\n        self.bn5 = nn.BatchNorm1d(max_features)\n        \n        # Single MaxPool (well-supported by recent auto_LiRPA versions)\n        self.pooling = nn.MaxPool1d(kernel_size=num_points)\n        \n        # Classifier MLP (NO Dropout!)\n        self.fc1 = nn.Linear(max_features, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, num_classes)\n        \n        self.bn_fc1 = nn.BatchNorm1d(512)\n        self.bn_fc2 = nn.BatchNorm1d(256)\n    \n    def forward(self, x):\n        batch_size = x.shape[0]\n        \n        if x.dim() == 2:\n            x = x.view(batch_size, self.num_points, self.in_channels)\n        \n        x = x.transpose(1, 2)\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = F.relu(self.bn3(self.conv3(x)))\n        x = F.relu(self.bn4(self.conv4(x)))\n        x = F.relu(self.bn5(self.conv5(x)))\n        \n        x = self.pooling(x)\n        x = x.view(batch_size, self.max_features)\n        \n        x = F.relu(self.bn_fc1(self.fc1(x)))\n        x = F.relu(self.bn_fc2(self.fc2(x)))\n        x = self.fc3(x)\n        \n        return x\n\n\ndef transfer_weights_vanilla(full_model, verify_model):\n    \"\"\"Transfer weights from PointNetVanilla (with Dropout) to verification model (no Dropout).\"\"\"\n    # Copy conv layers\n    for i in range(1, 6):\n        getattr(verify_model, f'conv{i}').load_state_dict(\n            getattr(full_model, f'conv{i}').state_dict()\n        )\n        getattr(verify_model, f'bn{i}').load_state_dict(\n            getattr(full_model, f'bn{i}').state_dict()\n        )\n    \n    # Copy FC layers\n    for i in range(1, 4):\n        getattr(verify_model, f'fc{i}').load_state_dict(\n            getattr(full_model, f'fc{i}').state_dict()\n        )\n    \n    verify_model.bn_fc1.load_state_dict(full_model.bn_fc1.state_dict())\n    verify_model.bn_fc2.load_state_dict(full_model.bn_fc2.state_dict())\n    \n    return verify_model\n\n\ndef verify_robustness_lirpa(model, sample, label, epsilon, method='CROWN', use_gpu=True):\n    \"\"\"\n    Verify local robustness using auto_LiRPA with CROWN method.\n    \n    Recent versions of auto_LiRPA support MaxPool1d well with CROWN.\n    We use conv_mode='matrix' for Conv1d+BatchNorm1d compatibility.\n    \"\"\"\n    # CLEANUP BEFORE\n    torch.cuda.empty_cache()\n    gc.collect()\n    \n    model.eval()\n    \n    # Determine device\n    verify_device = 'cuda' if use_gpu and torch.cuda.is_available() else 'cpu'\n    model_verify = model.to(verify_device)\n    \n    sample_tensor = torch.FloatTensor(sample).unsqueeze(0).to(verify_device)\n    \n    # CRITICAL: Use batch_size > 1 for dummy input (required for BatchNorm1d)\n    dummy_input = torch.randn(2, sample_tensor.shape[1], sample_tensor.shape[2]).to(verify_device)\n    \n    bounded_model = None\n    try:\n        bounded_model = BoundedModule(\n            model_verify, \n            dummy_input,\n            device=verify_device,\n            bound_opts={\n                'conv_mode': 'matrix',  # Required for Conv1d + BatchNorm1d\n            }\n        )\n        \n        ptb = PerturbationLpNorm(norm=float('inf'), eps=epsilon)\n        bounded_input = BoundedTensor(sample_tensor, ptb)\n        \n        # Use CROWN for tighter bounds (recent auto_LiRPA supports MaxPool well)\n        lb, ub = bounded_model.compute_bounds(x=(bounded_input,), method=method)\n        \n        if label == 0:\n            margin = lb[0, 0] - ub[0, 1]\n        else:\n            margin = lb[0, 1] - ub[0, 0]\n        \n        verified = margin.item() > 0\n        \n        result = {\n            'verified': verified,\n            'margin': margin.item(),\n            'lb': lb.detach().cpu().numpy(),\n            'ub': ub.detach().cpu().numpy(),\n            'method': method\n        }\n        \n    finally:\n        # CLEANUP AFTER (even if error)\n        if bounded_model is not None:\n            del bounded_model\n        del dummy_input, sample_tensor\n        if verify_device == 'cuda':\n            torch.cuda.empty_cache()\n        gc.collect()\n    \n    return result\n\n\nprint(\"Model classes defined:\")\nprint(\"  - PointNetVanilla: Full model with Dropout (for training)\")\nprint(\"  - PointNetVanillaVerify: No Dropout (for verification)\")\nprint(\"  - verify_robustness_lirpa: Verification function (CROWN method)\")\nprint(f\"\\nKey features:\")\nprint(\"  - NO T-Net (saves ~1-2GB GPU memory)\")\nprint(\"  - Single MaxPool (well-supported by recent auto_LiRPA)\")\nprint(\"  - CROWN verification (tighter bounds than IBP)\")\nprint(\"  - Aggressive memory cleanup with gc.collect()\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. QUICK SANITY CHECK\n",
    "\n",
    "Before full training (~30 min), we run a quick check (~3 min):\n",
    "1. Train on 2000 samples for 5 epochs\n",
    "2. Check accuracy is reasonable (>55%)\n",
    "3. Test α,β-CROWN verification on 3 samples\n",
    "\n",
    "If the check fails, we stop and debug before wasting time on full training."
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "###########################################\n# QUICK SANITY CHECK (before full training)\n###########################################\n\nprint(\"=\" * 60)\nprint(\"QUICK SANITY CHECK\")\nprint(\"=\" * 60)\nprint(\"This check validates the pipeline before full training.\")\nprint(\"If it fails, we can fix issues without waiting 30+ minutes.\\n\")\n\n# 1. Create small datasets for quick check\nclass QuickCheckDataset(Dataset):\n    \"\"\"Small dataset for quick validation with NSGA-III vulnerability labeling.\"\"\"\n    \n    def __init__(self, frame_features, pareto_set, threshold, n_points=1024, \n                 samples_per_epoch=2000, seed=None, augment=False):\n        self.frame_features = frame_features\n        self.pareto_set = pareto_set\n        self.threshold = threshold\n        self.n_points = n_points\n        self.samples_per_epoch = samples_per_epoch\n        self.seed = seed\n        self.augment = augment\n        \n        # Build KD-trees\n        self.trees = [cKDTree(ff['xyz']) for ff in frame_features]\n        self.frame_weights = np.array([len(ff['xyz']) for ff in frame_features])\n        self.frame_weights = self.frame_weights / self.frame_weights.sum()\n    \n    def __len__(self):\n        return self.samples_per_epoch\n    \n    def __getitem__(self, idx):\n        if self.seed is not None:\n            np.random.seed(self.seed + idx)\n        \n        # Sample frame and point\n        frame_idx = np.random.choice(len(self.frame_features), p=self.frame_weights)\n        ff = self.frame_features[frame_idx]\n        tree = self.trees[frame_idx]\n        xyz = ff['xyz']\n        \n        seed_idx = np.random.randint(0, len(xyz))\n        _, neighbor_idx = tree.query(xyz[seed_idx], k=self.n_points)\n        \n        if len(neighbor_idx) < self.n_points:\n            neighbor_idx = np.pad(neighbor_idx, (0, self.n_points - len(neighbor_idx)), mode='edge')\n        \n        # Extract and normalize xyz\n        group_xyz = xyz[neighbor_idx].copy()\n        group_xyz = group_xyz - group_xyz.mean(axis=0)\n        max_dist = np.abs(group_xyz).max()\n        if max_dist > 0:\n            group_xyz = group_xyz / max_dist\n        \n        # Extract features for labeling\n        curvature = ff['curvature'][neighbor_idx]\n        linearity = ff['linearity'][neighbor_idx]\n        \n        # Compute label using NSGA-III vulnerability\n        if self.pareto_set is not None:\n            label = compute_vulnerability_label(\n                group_xyz, self.pareto_set, self.threshold, curvature, linearity\n            )\n        else:\n            # Fallback: use original linear formula\n            density_var = ff['density_var'][neighbor_idx].mean()\n            planarity = ff['planarity'][neighbor_idx].mean()\n            score = (\n                curvature.mean() * CRITICALITY_WEIGHTS.get(\"curvature\", 0.15) +\n                density_var * CRITICALITY_WEIGHTS.get(\"density_var\", 0.25) +\n                (1 - planarity) * CRITICALITY_WEIGHTS.get(\"nonplanarity\", 0.60)\n            )\n            label = 0 if score >= 0.4 else 1\n        \n        return torch.from_numpy(group_xyz.astype(np.float32)), label\n\n\n# Create quick check datasets\nquick_train = QuickCheckDataset(\n    frame_features, PARETO_SET, VULNERABILITY_THRESHOLD,\n    n_points=N_POINTS, samples_per_epoch=2000, seed=None, augment=True\n)\nquick_test = QuickCheckDataset(\n    frame_features, PARETO_SET, VULNERABILITY_THRESHOLD,\n    n_points=N_POINTS, samples_per_epoch=500, seed=42, augment=False\n)\n\nquick_train_loader = DataLoader(quick_train, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\nquick_test_loader = DataLoader(quick_test, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n\nprint(f\"Quick train: {len(quick_train)} samples\")\nprint(f\"Quick test: {len(quick_test)} samples\")\n\n# Check class distribution\ntrain_labels = [quick_train[i][1] for i in range(100)]\nprint(f\"\\nLabel distribution (first 100): {sum(train_labels)} NON_CRITICAL, {100 - sum(train_labels)} CRITICAL\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 2. Quick training (5 epochs)\nprint(\"\\n\" + \"-\" * 60)\nprint(\"Step 1: Quick Training (5 epochs)\")\nprint(\"-\" * 60)\n\n# Use PointNetVanilla (no T-Net) for both training and verification\nquick_model = PointNetVanilla(\n    num_points=N_POINTS,\n    num_classes=NUM_CLASSES,\n    in_channels=IN_CHANNELS,\n    max_features=1024,\n).to(device)\n\nn_params_quick = sum(p.numel() for p in quick_model.parameters())\nprint(f\"PointNetVanilla parameters: {n_params_quick:,}\")\n\nquick_criterion = nn.CrossEntropyLoss()\nquick_optimizer = torch.optim.Adam(quick_model.parameters(), lr=LEARNING_RATE)\n\nfor epoch in range(5):\n    quick_model.train()\n    train_loss, train_correct, train_total = 0, 0, 0\n    \n    for batch_data, batch_labels in quick_train_loader:\n        batch_data = batch_data.to(device)\n        batch_labels = batch_labels.to(device)\n        \n        quick_optimizer.zero_grad()\n        outputs = quick_model(batch_data)\n        loss = quick_criterion(outputs, batch_labels)\n        loss.backward()\n        quick_optimizer.step()\n        \n        train_loss += loss.item() * batch_data.size(0)\n        _, predicted = outputs.max(1)\n        train_correct += predicted.eq(batch_labels).sum().item()\n        train_total += batch_data.size(0)\n    \n    train_acc = 100.0 * train_correct / train_total\n    print(f\"  Epoch {epoch+1}/5: loss={train_loss/train_total:.4f}, acc={train_acc:.1f}%\")\n\n# Evaluate on quick test set\nquick_model.eval()\ntest_correct, test_total = 0, 0\nwith torch.no_grad():\n    for batch_data, batch_labels in quick_test_loader:\n        batch_data = batch_data.to(device)\n        batch_labels = batch_labels.to(device)\n        outputs = quick_model(batch_data)\n        _, predicted = outputs.max(1)\n        test_correct += predicted.eq(batch_labels).sum().item()\n        test_total += batch_data.size(0)\n\nquick_acc = 100.0 * test_correct / test_total\nprint(f\"\\n  Quick test accuracy: {quick_acc:.1f}%\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 3. Check accuracy threshold\nprint(\"\\n\" + \"-\" * 60)\nprint(\"Step 2: Accuracy Check\")\nprint(\"-\" * 60)\n\nMIN_ACCURACY = 55.0  # Minimum acceptable accuracy\n\nif quick_acc < MIN_ACCURACY:\n    print(f\"X FAIL: Accuracy {quick_acc:.1f}% is below threshold {MIN_ACCURACY}%\")\n    print(\"\\n   Possible issues:\")\n    print(\"   - Labels may be incorrect or too noisy\")\n    print(\"   - NSGA-III vulnerability threshold may need adjustment\")\n    print(\"   - Model may need different hyperparameters\")\n    raise ValueError(f\"Quick check failed - accuracy too low ({quick_acc:.1f}%)\")\nelse:\n    print(f\"PASS: Accuracy {quick_acc:.1f}% >= {MIN_ACCURACY}%\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "load-model",
    "outputId": "9dd2677a-3c02-4d99-a6e5-f4e379a06840"
   },
   "outputs": [],
   "source": "# 4. Test α,β-CROWN verification on 3 samples\nprint(\"\\n\" + \"-\" * 60)\nprint(\"Step 3: auto_LiRPA Verification Test (CROWN method)\")\nprint(\"-\" * 60)\n\n# Create verification model (PointNetVanillaVerify - no Dropout)\nquick_verify_model = PointNetVanillaVerify(\n    num_points=N_POINTS,\n    num_classes=NUM_CLASSES,\n    in_channels=IN_CHANNELS,\n    max_features=1024,\n)\nquick_verify_model = transfer_weights_vanilla(quick_model.cpu(), quick_verify_model)\nquick_verify_model.eval()\n\n# Get 3 test samples\nquick_test_samples = [quick_test[i][0].numpy() for i in range(3)]\nquick_test_labels = [quick_test[i][1] for i in range(3)]\n\n# Test verification\nQUICK_EPSILON = 0.005  # Test epsilon\nverification_ok = True\nverification_errors = []\n\nprint(f\"Testing with eps = {QUICK_EPSILON}\")\nprint(f\"Model: PointNetVanillaVerify (no T-Net, no Dropout)\")\nprint(f\"Method: CROWN (backward bound propagation)\")\nprint()\n\nfor i in range(3):\n    sample = quick_test_samples[i]\n    label = quick_test_labels[i]\n    label_str = \"CRITICAL\" if label == 0 else \"NON_CRITICAL\"\n    \n    try:\n        # verify_robustness_lirpa uses CROWN method by default\n        result = verify_robustness_lirpa(quick_verify_model, sample, label, QUICK_EPSILON, method='CROWN')\n        if result['verified']:\n            status = f\"VERIFIED (margin={result['margin']:.4f})\"\n        else:\n            status = f\"NOT VERIFIED (margin={result['margin']:.4f})\"\n        print(f\"  Sample {i} ({label_str}): {status}\")\n        \n    except Exception as e:\n        error_msg = str(e)\n        verification_errors.append(error_msg)\n        print(f\"  Sample {i} ({label_str}): ERROR\")\n        print(f\"    {error_msg[:80]}...\")\n        verification_ok = False\n\nif verification_errors:\n    print(f\"\\nX FAIL: Verification encountered {len(verification_errors)} error(s)\")\n    print(\"\\n   Possible issues:\")\n    print(\"   - Model architecture may be incompatible with auto_LiRPA\")\n    print(\"   - Batch normalization issues with batch_size=1\")\n    raise ValueError(\"Quick check failed - verification error\")\nelse:\n    print(\"\\nPASS: Verification works correctly\")"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "verify-header"
   },
   "source": "# 5. Quick Check Summary\nprint(\"\\n\" + \"=\" * 60)\nprint(\"QUICK CHECK PASSED!\")\nprint(\"=\" * 60)\nprint(f\"  - Training: 5 epochs completed\")\nprint(f\"  - Accuracy: {quick_acc:.1f}% (threshold: {MIN_ACCURACY}%)\")\nprint(f\"  - Verification: α,β-CROWN works on 3 samples\")\nprint(f\"  - Labeling: NSGA-III vulnerability-based\" if PARETO_SET is not None else \"  - Labeling: Fallback weights\")\nprint()\nprint(\"Proceeding with full training (50 epochs)...\")\nprint(\"=\" * 60)\n\n# Clean up quick check objects to free memory\ndel quick_model, quick_verify_model, quick_train, quick_test\ndel quick_train_loader, quick_test_loader\ntorch.cuda.empty_cache() if torch.cuda.is_available() else None",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "verify-funcs",
    "outputId": "1db38049-0bd6-4015-bd5d-8fcca9a6a669"
   },
   "outputs": [],
   "source": [
    "## 5. Full Training\n",
    "\n",
    "Now that the Quick Check passed, we train the full model for 50 epochs."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "prop1-header"
   },
   "source": "# Create model for full training - PointNetVanilla (no T-Net)\nmodel = PointNetVanilla(\n    num_points=N_POINTS,\n    num_classes=NUM_CLASSES,\n    in_channels=IN_CHANNELS,\n    max_features=1024,\n).to(device)\n\nn_params = sum(p.numel() for p in model.parameters())\nprint(f\"PointNetVanilla parameters: {n_params:,}\")\nprint(f\"\\nArchitecture:\")\nprint(f\"  - NO T-Net (saves ~1-2GB GPU memory)\")\nprint(f\"  - Single MaxPool (auto_LiRPA compatible)\")\nprint(f\"  - 5 conv layers: 3→64→64→64→128→1024\")\nprint(f\"  - Classifier: 1024→512→256→{NUM_CLASSES}\")\nprint(f\"\\nBased on ablation study (Qi et al.):\")\nprint(f\"  - With T-Net: 89.2% accuracy\")\nprint(f\"  - Without T-Net: 88.6% accuracy (only 0.6% diff!)\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "prop1-verify",
    "outputId": "89626b82-8db3-49df-b165-a3bf4702be4e"
   },
   "outputs": [],
   "source": "def train_epoch(model, loader, criterion, optimizer):\n    \"\"\"Train for one epoch.\"\"\"\n    model.train()\n    total_loss = 0\n    correct = 0\n    total = 0\n    \n    for batch_data, batch_labels in loader:\n        batch_data = batch_data.to(device)\n        batch_labels = batch_labels.to(device)\n        \n        optimizer.zero_grad()\n        \n        # Forward pass\n        outputs = model(batch_data)\n        loss = criterion(outputs, batch_labels)\n        \n        # No feature transform regularization needed (no T-Net!)\n        \n        # Backward pass\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item() * batch_data.size(0)\n        _, predicted = outputs.max(1)\n        correct += predicted.eq(batch_labels).sum().item()\n        total += batch_data.size(0)\n    \n    return total_loss / total, 100.0 * correct / total\n\n\ndef evaluate(model, loader):\n    \"\"\"Evaluate model on dataset.\"\"\"\n    model.eval()\n    correct = 0\n    total = 0\n    \n    with torch.no_grad():\n        for batch_data, batch_labels in loader:\n            batch_data = batch_data.to(device)\n            batch_labels = batch_labels.to(device)\n            \n            outputs = model(batch_data)\n            _, predicted = outputs.max(1)\n            correct += predicted.eq(batch_labels).sum().item()\n            total += batch_data.size(0)\n    \n    return 100.0 * correct / total"
  },
  {
   "id": "cell-25b",
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# Training loop\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n\nbest_acc = 0\nhistory = {'train_loss': [], 'train_acc': [], 'test_acc': []}\n\nprint(\"=\"*60)\nprint(\"Training PointNetVanilla (no T-Net)\")\nprint(\"=\"*60)\n\nfor epoch in range(EPOCHS):\n    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)\n    test_acc = evaluate(model, test_loader)\n    scheduler.step()\n    \n    history['train_loss'].append(train_loss)\n    history['train_acc'].append(train_acc)\n    history['test_acc'].append(test_acc)\n    \n    if test_acc > best_acc:\n        best_acc = test_acc\n        # Save best model\n        torch.save({\n            'model_state_dict': model.state_dict(),\n            'n_points': N_POINTS,\n            'num_classes': NUM_CLASSES,\n            'in_channels': IN_CHANNELS,\n            'model_type': 'PointNetVanilla',\n            'test_accuracy': best_acc,\n        }, 'pointnet_best.pth')\n    \n    if (epoch + 1) % 5 == 0 or epoch == 0:\n        print(f\"Epoch {epoch+1:3d}/{EPOCHS} | Loss: {train_loss:.4f} | \"\n              f\"Train Acc: {train_acc:.1f}% | Test Acc: {test_acc:.1f}% | Best: {best_acc:.1f}%\")\n\nprint(f\"\\nTraining complete! Best accuracy: {best_acc:.2f}%\")"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "prop2-header"
   },
   "source": "# Plot training curves\nimport matplotlib.pyplot as plt\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 4))\n\n# Loss\naxes[0].plot(history['train_loss'], 'b-', label='Train Loss')\naxes[0].set_xlabel('Epoch')\naxes[0].set_ylabel('Loss')\naxes[0].set_title('Training Loss')\naxes[0].legend()\naxes[0].grid(True, alpha=0.3)\n\n# Accuracy\naxes[1].plot(history['train_acc'], 'b-', label='Train Acc')\naxes[1].plot(history['test_acc'], 'r-', label='Test Acc')\naxes[1].axhline(y=best_acc, color='g', linestyle='--', label=f'Best: {best_acc:.1f}%')\naxes[1].set_xlabel('Epoch')\naxes[1].set_ylabel('Accuracy (%)')\naxes[1].set_title('Training & Test Accuracy')\naxes[1].legend()\naxes[1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('training_curves.png', dpi=150)\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "prop2-verify",
    "outputId": "f72a6c41-c915-452c-bf3d-e4050d9ed2cd"
   },
   "outputs": [],
   "source": "# Load best model for verification\ncheckpoint = torch.load('pointnet_best.pth', map_location=device)\nmodel.load_state_dict(checkpoint['model_state_dict'])\nmodel.eval()\nprint(f\"Loaded best model with test accuracy: {checkpoint['test_accuracy']:.2f}%\")\nprint(f\"Model type: {checkpoint.get('model_type', 'PointNetVanilla')}\")\n\n# AGGRESSIVE MEMORY CLEANUP before verification\nprint(\"\\nCleaning up GPU memory before verification...\")\ndel train_loader, test_loader, optimizer, scheduler, criterion\ntorch.cuda.empty_cache()\ngc.collect()\n\nif torch.cuda.is_available():\n    print(f\"GPU memory after cleanup: {torch.cuda.memory_allocated()/1e9:.2f} GB allocated\")\n    print(f\"GPU memory reserved: {torch.cuda.memory_reserved()/1e9:.2f} GB\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "results-header"
   },
   "source": "## 5. Verification with α,β-CROWN\n\nUsing auto_LiRPA API directly (native PyTorch support for Conv1d, MaxPool, etc.)\n\n**Model: PointNetVanillaVerify**\n- NO T-Net (avoids torch.bmm / BoundMatMul issues)\n- NO Dropout (required for auto_LiRPA compatibility)\n- Single MaxPool (well-supported by recent auto_LiRPA versions)\n- Full BatchNorm support with conv_mode='matrix'\n\n**Verification Method: CROWN**\n- Backward bound propagation (tighter bounds than IBP)\n- Recent auto_LiRPA versions support MaxPool1d well"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "results-summary",
    "outputId": "b4f82119-ba9d-4b70-f51a-581ba9d3f9ee"
   },
   "outputs": [],
   "source": "# Create verification model (PointNetVanillaVerify - no Dropout)\nverify_model = PointNetVanillaVerify(\n    num_points=N_POINTS,\n    num_classes=NUM_CLASSES,\n    in_channels=IN_CHANNELS,\n    max_features=1024,\n)\n\n# Transfer weights from trained model\nverify_model = transfer_weights_vanilla(model.cpu(), verify_model)\nverify_model.eval()\n\n# Move training model to CPU to free GPU memory\nmodel = model.cpu()\ntorch.cuda.empty_cache()\ngc.collect()\n\n# Create a quick test loader for accuracy comparison\nquick_verify_test = LiDAROnTheFlyDataset(\n    frame_features, pareto_set=PARETO_SET, threshold=VULNERABILITY_THRESHOLD,\n    fallback_weights=CRITICALITY_WEIGHTS, n_points=N_POINTS,\n    samples_per_epoch=500, seed=42, augment=False\n)\nquick_verify_loader = DataLoader(quick_verify_test, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n\n# Compare accuracy\nverify_model_gpu = verify_model.to(device)\nverify_acc = evaluate(verify_model_gpu, quick_verify_loader)\nverify_model = verify_model.cpu()\n\n# Cleanup\ndel quick_verify_loader, quick_verify_test, verify_model_gpu\ntorch.cuda.empty_cache()\ngc.collect()\n\nprint(f\"Original model (with Dropout) accuracy: {best_acc:.2f}%\")\nprint(f\"Verification model (no Dropout) accuracy: {verify_acc:.2f}%\")\nprint(f\"Accuracy difference: {abs(best_acc - verify_acc):.2f}%\")\nprint(\"\\nModel: PointNetVanillaVerify\")\nprint(\"  - NO T-Net (saves ~1-2GB GPU memory)\")\nprint(\"  - NO Dropout (for auto_LiRPA compatibility)\")\nprint(\"  - Single MaxPool (well-supported by recent auto_LiRPA)\")"
  },
  {
   "cell_type": "code",
   "source": "# Additional verification function for Safety property\n\ndef verify_safety_lirpa(model, sample, epsilon, method='CROWN'):\n    \"\"\"\n    Verify safety property using α,β-CROWN with memory cleanup.\n    \n    Property: For CRITICAL samples, no perturbation causes NON_CRITICAL classification.\n    \"\"\"\n    # CLEANUP BEFORE\n    torch.cuda.empty_cache()\n    gc.collect()\n    \n    model.eval()\n    model_cpu = model.cpu()\n    \n    sample_tensor = torch.FloatTensor(sample).unsqueeze(0)\n    \n    # First check prediction\n    with torch.no_grad():\n        output = model_cpu(sample_tensor)\n        pred = output.argmax(dim=1).item()\n        confidence = torch.softmax(output, dim=1)[0]\n    \n    # Only verify if predicted as CRITICAL (class 0)\n    if pred != 0:\n        return {\n            'verified': False,\n            'status': 'skipped_wrong_prediction',\n            'original_prediction': pred,\n            'confidence': confidence.numpy()\n        }\n    \n    # CRITICAL: Use batch_size > 1 for dummy input (required for BatchNorm1d)\n    dummy_input = torch.randn(2, sample_tensor.shape[1], sample_tensor.shape[2])\n    \n    bounded_model = None\n    try:\n        bounded_model = BoundedModule(\n            model_cpu, \n            dummy_input,\n            device='cpu',\n            bound_opts={\n                'conv_mode': 'matrix',  # Required for Conv1d + BatchNorm1d\n            }\n        )\n        \n        ptb = PerturbationLpNorm(norm=float('inf'), eps=epsilon)\n        bounded_input = BoundedTensor(sample_tensor, ptb)\n        \n        lb, ub = bounded_model.compute_bounds(x=(bounded_input,), method=method)\n        \n        # Safety: CRITICAL (class 0) should always have higher score than NON_CRITICAL (class 1)\n        margin = lb[0, 0] - ub[0, 1]\n        verified = margin.item() > 0\n        \n        result = {\n            'verified': verified,\n            'margin': margin.item(),\n            'lb': lb.detach().numpy(),\n            'ub': ub.detach().numpy(),\n            'method': method,\n            'original_prediction': pred,\n            'confidence': confidence.numpy()\n        }\n        \n    finally:\n        # CLEANUP AFTER\n        if bounded_model is not None:\n            del bounded_model\n        del dummy_input\n        gc.collect()\n    \n    return result\n\n\nprint(\"Verification functions ready:\")\nprint(\"  - verify_robustness_lirpa (with memory cleanup)\")\nprint(\"  - verify_safety_lirpa (with memory cleanup)\")\nprint(\"\\nKey settings for Conv1d + BatchNorm1d:\")\nprint(\"  - conv_mode='matrix': Required for 1D convolutions\")\nprint(\"  - Dummy input with batch_size=2: Required for BatchNorm1d\")\nprint(\"  - gc.collect() + empty_cache(): Aggressive memory cleanup\")\nprint(\"  - Method: CROWN (tighter bounds than IBP)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "save-results",
    "outputId": "1a67f20a-a2e5-4bd2-aff2-b59a53e84359"
   },
   "outputs": [],
   "source": "# Generate fixed verification samples from test dataset\n# We need numpy arrays for verification, so we extract them once\n\nprint(\"Generating fixed verification samples...\")\n\n# Create a fixed set of samples for verification (with seed for reproducibility)\n# Uses the same NSGA-III vulnerability labeling as training\nverify_dataset = LiDAROnTheFlyDataset(\n    frame_features,\n    pareto_set=PARETO_SET,\n    threshold=VULNERABILITY_THRESHOLD,\n    fallback_weights=CRITICALITY_WEIGHTS,\n    n_points=N_POINTS,\n    samples_per_epoch=N_VERIFY_SAMPLES * 2,  # Extra samples to ensure enough of each class\n    seed=12345,  # Fixed seed for verification\n    augment=False\n)\n\n# Extract samples and labels as numpy arrays\ntest_groups = []\ntest_labels = []\nfor i in range(len(verify_dataset)):\n    sample, label = verify_dataset[i]\n    test_groups.append(sample.numpy())\n    test_labels.append(label)\n\ntest_groups = np.array(test_groups)\ntest_labels = np.array(test_labels)\n\nprint(f\"Verification samples: {len(test_groups)}\")\nprint(f\"  CRITICAL (0): {sum(test_labels == 0)}\")\nprint(f\"  NON_CRITICAL (1): {sum(test_labels == 1)}\")\nprint(f\"\\nLabeling: {'NSGA-III vulnerability-based' if PARETO_SET is not None else 'Fallback weights'}\")"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "viz-header"
   },
   "source": "# Property 1: Local Robustness Verification with α,β-CROWN\n# Using PointNetVanillaVerify (no T-Net, no Dropout)\n\nprint(\"=\"*70)\nprint(\"PROPERTY 1: LOCAL ROBUSTNESS (L∞) with α,β-CROWN\")\nprint(\"Verifying: ∀x' with ||x' - x₀||∞ ≤ ε : f(x') = f(x₀)\")\nprint(\"Model: PointNetVanillaVerify (no T-Net, no Dropout)\")\nprint(\"Method: CROWN (backward bound propagation)\")\nprint(\"=\"*70)\n\n# Verification method to use\nVERIFY_METHOD = 'CROWN'  # Options: 'CROWN', 'alpha-CROWN', 'CROWN-Optimized'\n\nrobustness_results = {}\nerrors_log = []\n\nfor eps in EPSILONS:\n    print(f\"\\nε = {eps}\")\n    print(\"-\"*40)\n    \n    # Memory cleanup at start of each epsilon\n    torch.cuda.empty_cache()\n    gc.collect()\n    \n    verified_count = 0\n    total = 0\n    \n    for i in range(min(N_VERIFY_SAMPLES, len(test_groups))):\n        sample = test_groups[i]\n        label = int(test_labels[i])\n        label_str = \"CRITICAL\" if label == 0 else \"NON_CRITICAL\"\n        \n        try:\n            # verify_robustness_lirpa includes memory cleanup\n            result = verify_robustness_lirpa(verify_model, sample, label, eps, method=VERIFY_METHOD)\n            if result['verified']:\n                verified_count += 1\n                status = f\"✓ VERIFIED (margin={result['margin']:.4f})\"\n            else:\n                status = f\"✗ NOT VERIFIED (margin={result['margin']:.4f})\"\n            total += 1\n        except Exception as e:\n            error_msg = str(e)\n            errors_log.append(f\"Sample {i}, eps={eps}: {error_msg}\")\n            status = f\"⚠ ERROR: {error_msg[:60]}...\"\n        \n        print(f\"  Sample {i:3d} ({label_str:12}): {status}\")\n    \n    robustness_results[str(eps)] = {\n        'epsilon': eps,\n        'verified': verified_count,\n        'total': total,\n        'verified_pct': 100 * verified_count / total if total > 0 else 0,\n        'method': VERIFY_METHOD\n    }\n    \n    print(f\"\\n  Summary: {verified_count}/{total} verified ({robustness_results[str(eps)]['verified_pct']:.1f}%)\")\n\n# Print any errors encountered\nif errors_log:\n    print(\"\\n\" + \"=\"*70)\n    print(\"ERRORS ENCOUNTERED:\")\n    print(\"=\"*70)\n    for err in errors_log[:5]:\n        print(f\"  {err}\")\n    if len(errors_log) > 5:\n        print(f\"  ... and {len(errors_log) - 5} more errors\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Property 2: Safety Verification with α,β-CROWN\n# Using PointNetVanillaVerify (no T-Net, no Dropout)\n\nprint(\"=\"*70)\nprint(\"PROPERTY 2: SAFETY PROPERTY with α,β-CROWN\")\nprint(\"Verifying: For CRITICAL samples, never misclassified as NON_CRITICAL\")\nprint(\"Model: PointNetVanillaVerify (no T-Net, no Dropout)\")\nprint(\"Method: CROWN (backward bound propagation)\")\nprint(\"=\"*70)\n\n# Get CRITICAL samples (label=0)\ncritical_indices = np.where(test_labels == 0)[0]\nn_critical = min(N_VERIFY_SAMPLES, len(critical_indices))\n\nsafety_results = {}\nsafety_errors_log = []\n\nfor eps in EPSILONS:\n    print(f\"\\nε = {eps}\")\n    print(\"-\"*40)\n    \n    # Memory cleanup at start of each epsilon\n    torch.cuda.empty_cache()\n    gc.collect()\n    \n    verified_count = 0\n    skipped_count = 0\n    total = 0\n    \n    for i, idx in enumerate(critical_indices[:n_critical]):\n        sample = test_groups[idx]\n        \n        try:\n            # verify_safety_lirpa includes memory cleanup\n            result = verify_safety_lirpa(verify_model, sample, eps, method=VERIFY_METHOD)\n            \n            if result.get('status') == 'skipped_wrong_prediction':\n                skipped_count += 1\n                status = f\"⊘ SKIPPED (model predicts NON_CRITICAL)\"\n            elif result['verified']:\n                verified_count += 1\n                status = f\"✓ SAFE (margin={result['margin']:.4f})\"\n                total += 1\n            else:\n                status = f\"✗ UNSAFE (margin={result['margin']:.4f})\"\n                total += 1\n        except Exception as e:\n            error_msg = str(e)\n            safety_errors_log.append(f\"Sample {idx}, eps={eps}: {error_msg}\")\n            status = f\"⚠ ERROR: {error_msg[:60]}...\"\n        \n        print(f\"  Sample {idx:3d} (CRITICAL): {status}\")\n    \n    safety_results[str(eps)] = {\n        'epsilon': eps,\n        'verified': verified_count,\n        'total': total,\n        'skipped': skipped_count,\n        'verified_pct': 100 * verified_count / total if total > 0 else 0,\n        'method': VERIFY_METHOD\n    }\n    \n    print(f\"\\n  Summary: {verified_count}/{total} safe ({safety_results[str(eps)]['verified_pct']:.1f}%), {skipped_count} skipped\")\n\n# Print any errors encountered\nif safety_errors_log:\n    print(\"\\n\" + \"=\"*70)\n    print(\"ERRORS ENCOUNTERED:\")\n    print(\"=\"*70)\n    for err in safety_errors_log[:5]:\n        print(f\"  {err}\")\n    if len(safety_errors_log) > 5:\n        print(f\"  ... and {len(safety_errors_log) - 5} more errors\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "viz-plot",
    "outputId": "742083d8-4fd0-4606-f49d-a26ed054d4ba"
   },
   "outputs": [],
   "source": "## 6. Results Summary"
  },
  {
   "cell_type": "code",
   "source": "# Results Summary\nprint(\"\\n\" + \"=\"*70)\nprint(\"FINAL RESULTS SUMMARY\")\nprint(\"=\"*70)\n\n# Property 1 Table\nprint(\"\\n### PROPERTY 1: LOCAL ROBUSTNESS ###\")\nprint(f\"{'Epsilon':>10} | {'Verified':>10} | {'Total':>10} | {'Verified %':>12}\")\nprint(\"-\"*50)\nfor eps_str, r in robustness_results.items():\n    print(f\"{float(eps_str):>10.4f} | {r['verified']:>10} | {r['total']:>10} | {r['verified_pct']:>10.1f}%\")\n\n# Property 2 Table\nprint(f\"\\n### PROPERTY 2: SAFETY (CRITICAL -> never NON_CRITICAL) ###\")\nprint(f\"{'Epsilon':>10} | {'Safe':>10} | {'Total':>10} | {'Safe %':>12} | {'Skipped':>10}\")\nprint(\"-\"*65)\nfor eps_str, r in safety_results.items():\n    print(f\"{float(eps_str):>10.4f} | {r['verified']:>10} | {r['total']:>10} | {r['verified_pct']:>10.1f}% | {r['skipped']:>10}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Visualization\nimport matplotlib.pyplot as plt\n\neps_values = [float(e) for e in robustness_results.keys()]\nrobustness_pct = [r['verified_pct'] for r in robustness_results.values()]\nsafety_pct = [r['verified_pct'] for r in safety_results.values()]\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Plot 1: Robustness\nax1 = axes[0]\nax1.plot(eps_values, robustness_pct, 'b-o', linewidth=2, markersize=8)\nax1.axhline(y=50, color='r', linestyle='--', label='50% threshold')\nax1.set_xlabel('Perturbation (ε)', fontsize=12)\nax1.set_ylabel('Verified (%)', fontsize=12)\nax1.set_title('Property 1: Local Robustness', fontsize=14)\nax1.legend()\nax1.grid(True, alpha=0.3)\nax1.set_ylim([0, 105])\n\n# Plot 2: Safety\nax2 = axes[1]\ncolors = ['green' if p == 100 else ('orange' if p > 50 else 'red') for p in safety_pct]\nax2.bar(range(len(eps_values)), safety_pct, color=colors, alpha=0.7)\nax2.set_xticks(range(len(eps_values)))\nax2.set_xticklabels([f'{e:.3f}' for e in eps_values])\nax2.axhline(y=100, color='green', linestyle='-', linewidth=2, label='Safety verified')\nax2.set_xlabel('Perturbation (ε)', fontsize=12)\nax2.set_ylabel('Safe Samples (%)', fontsize=12)\nax2.set_title('Property 2: Safety (CRITICAL → never NON_CRITICAL)', fontsize=14)\nax2.legend()\nax2.grid(True, alpha=0.3, axis='y')\nax2.set_ylim([0, 105])\n\nplt.tight_layout()\nplt.savefig('verification_results.png', dpi=150, bbox_inches='tight')\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Save results locally\nfinal_results = {\n    \"timestamp\": datetime.now().isoformat(),\n    \"model_trained\": {\n        \"type\": \"PointNetVanilla\",\n        \"n_points\": N_POINTS,\n        \"in_channels\": IN_CHANNELS,\n        \"num_classes\": NUM_CLASSES,\n        \"use_tnet\": False,  # NO T-Net!\n        \"parameters\": n_params,\n        \"test_accuracy\": best_acc,\n        \"ablation_study_note\": \"Qi et al. shows PointNet without T-Net achieves 88.6% vs 89.2% with T-Net (only 0.6% difference)\"\n    },\n    \"model_verified\": {\n        \"type\": \"PointNetVanillaVerify\",\n        \"use_tnet\": False,\n        \"note\": \"No T-Net (saves ~1-2GB GPU memory, avoids torch.bmm issues). No Dropout for auto_LiRPA compatibility.\",\n        \"test_accuracy\": verify_acc,\n    },\n    \"verification_method\": f\"α,β-CROWN ({VERIFY_METHOD})\",\n    \"verification_settings\": {\n        \"method\": VERIFY_METHOD,\n        \"conv_mode\": \"matrix\",  # Required for Conv1d + BatchNorm1d\n        \"pooling\": \"Single MaxPool1d (well-supported by recent auto_LiRPA)\",\n        \"memory_cleanup\": \"gc.collect() + torch.cuda.empty_cache() before/after each verification\"\n    },\n    \"n_verify_samples\": N_VERIFY_SAMPLES,\n    \"property1_robustness\": robustness_results,\n    \"property2_safety\": safety_results,\n}\n\nwith open('verification_results.json', 'w') as f:\n    json.dump(final_results, f, indent=2)\n\nprint(\"Results saved locally:\")\nprint(\"  - pointnet_best.pth (model checkpoint)\")\nprint(\"  - verification_results.json\")\nprint(\"  - verification_results.png\")\nprint(\"  - training_curves.png\")\nprint(f\"\\nVerification performed using α,β-CROWN with method='{VERIFY_METHOD}'\")\nprint(f\"  Trained model accuracy: {best_acc:.2f}%\")\nprint(f\"  Verified model accuracy: {verify_acc:.2f}%\")\nprint(f\"\\nModel: PointNetVanilla (no T-Net)\")\nprint(\"  - Scientifically valid (ablation study: 88.6% vs 89.2%)\")\nprint(\"  - Memory efficient (no torch.bmm / BoundMatMul)\")\nprint(\"  - Single MaxPool (well-supported by recent auto_LiRPA)\")\nprint(\"\\nRun the next cell to download all files to your computer.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Download all files to your computer\nfrom google.colab import files\n\nprint(\"Downloading files...\")\nfiles.download('pointnet_best.pth')\nfiles.download('verification_results.json')\nfiles.download('verification_results.png')\nfiles.download('training_curves.png')\nprint(\"Done! Check your Downloads folder.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}