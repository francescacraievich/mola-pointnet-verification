{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": "# PointNet Training & Verification with α,β-CROWN\n\n## LiDAR Point Cloud Classification + Formal Verification\n\nThis notebook:\n1. **Loads** your LiDAR data from Google Drive\n2. **Trains** PointNet (original architecture) on GPU\n3. **Verifies** robustness properties using α,β-CROWN API\n\n### Architecture: Original PointNet (Qi et al., CVPR 2017)\n- Input T-Net (3x3) for spatial alignment\n- Feature T-Net (64x64) for feature alignment  \n- Point-wise MLP: 7→64→64→64→128→1024 (5 conv layers with BatchNorm)\n- Global max pooling\n- Classifier MLP: 1024→512→256→2 (with BatchNorm + Dropout)\n- **~3.5M parameters**\n\n### Input Format: (N, 1024, 7)\n- xyz coordinates (3 channels)\n- Geometric features (4 channels): linearity, curvature, density_var, planarity\n\n### Properties Verified:\n\n**Property 1: Local Robustness (L∞)**\n```\n∀x' with ||x' - x₀||∞ ≤ ε : f(x') = f(x₀)\n```\n\n**Property 2: Safety Property**\n```\n∀x' with ||x' - x₀||∞ ≤ ε ∧ f(x₀)=CRITICAL : f(x') ≠ NON_CRITICAL\n```"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-header"
   },
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "check-gpu",
    "outputId": "1f7e5966-0893-4601-80da-4cea0ecaf7c9"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fri Jan  2 17:52:23 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   40C    P8              9W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Check GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-deps"
   },
   "outputs": [],
   "source": "# Install dependencies\n!pip install torch numpy onnx onnxruntime pyyaml packaging appdirs sortedcontainers -q\n\n# Clone alpha-beta-CROWN\n!git clone https://github.com/Verified-Intelligence/alpha-beta-CROWN.git 2>/dev/null || true\n\n# NOTE: Google Drive mount removed - using local storage instead\n# If you need to upload data, use the file browser on the left or:\n# from google.colab import files\n# uploaded = files.upload()  # Upload your .npy files"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "setup-paths",
    "outputId": "455c08e7-7358-4737-e315-c83ad964d345"
   },
   "outputs": [],
   "source": "# Setup paths and imports\nimport sys\nsys.path.insert(0, '/content/alpha-beta-CROWN/auto_LiRPA')\nsys.path.insert(0, '/content/alpha-beta-CROWN/complete_verifier')\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nimport json\nfrom datetime import datetime\nfrom torch.utils.data import TensorDataset, DataLoader\n\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nprint(f\"PyTorch: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\nprint(f\"Device: {device}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "la7wHTOP6faN"
   },
   "outputs": [],
   "source": "# Mock onnxoptimizer to avoid compilation issues\nfrom types import ModuleType\nmock = ModuleType('onnxoptimizer')\nmock.optimize = lambda model, passes=None: model\nsys.modules['onnxoptimizer'] = mock\n\n# Import auto_LiRPA for verification\nfrom auto_LiRPA import BoundedModule, BoundedTensor, PerturbationLpNorm\nprint(\"auto_LiRPA imported successfully!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bkAEM9RK6r-8",
    "outputId": "4687c6aa-78f5-488e-a302-fa7486ef2bc7"
   },
   "outputs": [],
   "source": "# Set random seeds for reproducibility\nimport random\nrandom.seed(42)\nnp.random.seed(42)\ntorch.manual_seed(42)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(42)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "import-abcrown",
    "outputId": "a2de54de-d57a-4c9f-a5c4-e855e34a7b61"
   },
   "outputs": [],
   "source": "# Configuration\nN_POINTS = 1024        # Points per sample (original PointNet)\nIN_CHANNELS = 7        # xyz(3) + features(4)\nNUM_CLASSES = 2        # CRITICAL vs NON_CRITICAL\nINPUT_DIM = N_POINTS * IN_CHANNELS  # 7168\n\n# Training config\nEPOCHS = 50\nBATCH_SIZE = 32\nLEARNING_RATE = 0.001\n\n# Verification config\nEPSILONS = [0.001, 0.003, 0.005, 0.007, 0.01]  # L-inf perturbation budgets\nN_VERIFY_SAMPLES = 20  # Samples to verify\n\nprint(f\"Configuration:\")\nprint(f\"  Points per sample: {N_POINTS}\")\nprint(f\"  Input channels: {IN_CHANNELS} (xyz + 4 geometric features)\")\nprint(f\"  Input dimension: {INPUT_DIM}\")\nprint(f\"  Classes: {NUM_CLASSES}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model-header"
   },
   "source": "## 2. Load Data from GitHub\n\nData files are stored in the repository using Git LFS."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "model-defs",
    "outputId": "6202eee1-130e-43c3-8e9f-7d4c4f77b684"
   },
   "outputs": [],
   "source": "# Clone repository with Git LFS data\nimport os\n\nREPO_URL = \"https://github.com/francescacraievich/mola-pointnet-verification.git\"\nREPO_DIR = \"/content/mola-pointnet-verification\"\nDATA_PATH = f\"{REPO_DIR}/data/pointnet\"\n\nif not os.path.exists(REPO_DIR):\n    print(\"Cloning repository with Git LFS...\")\n    !git lfs install\n    !git clone {REPO_URL} {REPO_DIR}\n    print(\"Done!\")\nelse:\n    print(f\"Repository already cloned at {REPO_DIR}\")\n\n# Verify data files\ndata_files = ['train_groups.npy', 'train_labels.npy', 'test_groups.npy', 'test_labels.npy']\nfor f in data_files:\n    path = os.path.join(DATA_PATH, f)\n    if os.path.exists(path):\n        size = os.path.getsize(path) / 1e6\n        print(f\"✓ {f}: {size:.1f} MB\")\n    else:\n        print(f\"✗ {f}: NOT FOUND\")"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "data-header"
   },
   "source": "# Load the data\ntrain_groups = np.load(os.path.join(DATA_PATH, 'train_groups.npy'))\ntrain_labels = np.load(os.path.join(DATA_PATH, 'train_labels.npy'))\ntest_groups = np.load(os.path.join(DATA_PATH, 'test_groups.npy'))\ntest_labels = np.load(os.path.join(DATA_PATH, 'test_labels.npy'))\n\nprint(f\"Train data: {train_groups.shape}, labels: {train_labels.shape}\")\nprint(f\"Test data: {test_groups.shape}, labels: {test_labels.shape}\")\nprint(f\"Label distribution (train): CRITICAL={sum(train_labels==0)}, NON_CRITICAL={sum(train_labels==1)}\")\nprint(f\"Label distribution (test): CRITICAL={sum(test_labels==0)}, NON_CRITICAL={sum(test_labels==1)}\")\n\n# Verify shape\nassert train_groups.shape[1] == N_POINTS, f\"Expected {N_POINTS} points, got {train_groups.shape[1]}\"\nassert train_groups.shape[2] == IN_CHANNELS, f\"Expected {IN_CHANNELS} channels, got {train_groups.shape[2]}\"",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "setup-files",
    "outputId": "d8e62543-ffe4-49e8-c042-299821f16a5c"
   },
   "outputs": [],
   "source": "# Create DataLoaders\ntrain_dataset = TensorDataset(\n    torch.from_numpy(train_groups).float(),\n    torch.from_numpy(train_labels).long()\n)\ntest_dataset = TensorDataset(\n    torch.from_numpy(test_groups).float(),\n    torch.from_numpy(test_labels).long()\n)\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n\nprint(f\"Train batches: {len(train_loader)}\")\nprint(f\"Test batches: {len(test_loader)}\")"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "load-model",
    "outputId": "9dd2677a-3c02-4d99-a6e5-f4e379a06840"
   },
   "outputs": [],
   "source": "## 3. PointNet Model (Original Architecture)\n\nBased on Qi et al., \"PointNet: Deep Learning on Point Sets\" (CVPR 2017)\n\nArchitecture:\n- **T-Net 3x3**: Spatial transformer for xyz coordinates\n- **T-Net 64x64**: Feature transformer after first MLP\n- **Point MLP**: 7→64→64→[feat_trans]→64→128→1024 with BatchNorm\n- **Global MaxPool**: Symmetric aggregation\n- **Classifier**: 1024→512→256→2 with BatchNorm + Dropout(0.3)"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "verify-header"
   },
   "source": "class TNet(nn.Module):\n    \"\"\"\n    T-Net: Spatial Transformer Network for PointNet.\n    Predicts a k x k transformation matrix.\n    \n    Architecture (original):\n    - Conv1d: k → 64 → 128 → 1024\n    - MaxPool\n    - FC: 1024 → 512 → 256 → k*k\n    - All with BatchNorm\n    \"\"\"\n    def __init__(self, k=3):\n        super().__init__()\n        self.k = k\n        \n        # Shared MLP (implemented as Conv1d)\n        self.conv1 = nn.Conv1d(k, 64, 1)\n        self.conv2 = nn.Conv1d(64, 128, 1)\n        self.conv3 = nn.Conv1d(128, 1024, 1)\n        \n        self.bn1 = nn.BatchNorm1d(64)\n        self.bn2 = nn.BatchNorm1d(128)\n        self.bn3 = nn.BatchNorm1d(1024)\n        \n        # FC layers\n        self.fc1 = nn.Linear(1024, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, k * k)\n        \n        self.bn_fc1 = nn.BatchNorm1d(512)\n        self.bn_fc2 = nn.BatchNorm1d(256)\n        \n        # Initialize to identity\n        self.fc3.weight.data.zero_()\n        self.fc3.bias.data.copy_(torch.eye(k).view(-1))\n    \n    def forward(self, x):\n        \"\"\"\n        Args:\n            x: (batch, k, n_points)\n        Returns:\n            transform: (batch, k, k) transformation matrix\n        \"\"\"\n        batch_size = x.shape[0]\n        \n        x = F.relu(self.bn1(self.conv1(x)))\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = F.relu(self.bn3(self.conv3(x)))\n        \n        # Max pool over points\n        x = torch.max(x, dim=2)[0]  # (batch, 1024)\n        \n        x = F.relu(self.bn_fc1(self.fc1(x)))\n        x = F.relu(self.bn_fc2(self.fc2(x)))\n        x = self.fc3(x)\n        \n        # Reshape to k x k matrix\n        x = x.view(batch_size, self.k, self.k)\n        \n        return x\n\n\nclass PointNetForVerification(nn.Module):\n    \"\"\"\n    PointNet for Verification - IDENTICAL to original PointNet architecture.\n    \n    Based on: Qi et al., \"PointNet: Deep Learning on Point Sets\" (CVPR 2017)\n    \n    Features:\n    - Input T-Net (3x3) only transforms xyz, not extra features\n    - Feature T-Net (64x64) after conv2\n    - 5 conv layers: in_channels→64→64→64→128→1024\n    - BatchNorm on all layers\n    - Dropout(0.3) in classifier\n    \n    Input format: (batch, n_points, in_channels)\n    - in_channels=7: xyz(3) + features(4)\n    \"\"\"\n    def __init__(\n        self,\n        num_points=1024,\n        num_classes=2,\n        use_tnet=True,\n        feature_transform=True,\n        in_channels=7,\n    ):\n        super().__init__()\n        \n        self.num_points = num_points\n        self.num_classes = num_classes\n        self.use_tnet = use_tnet\n        self.feature_transform = feature_transform\n        self.in_channels = in_channels\n        self.input_dim = num_points * in_channels\n        \n        # Input T-Net (3x3) - only for xyz\n        if use_tnet:\n            self.input_tnet = TNet(k=3)\n        \n        # Feature T-Net (64x64)\n        if feature_transform:\n            self.feat_tnet = TNet(k=64)\n        \n        # Point-wise MLP (5 conv layers)\n        self.conv1 = nn.Conv1d(in_channels, 64, 1)\n        self.conv2 = nn.Conv1d(64, 64, 1)\n        self.conv3 = nn.Conv1d(64, 64, 1)\n        self.conv4 = nn.Conv1d(64, 128, 1)\n        self.conv5 = nn.Conv1d(128, 1024, 1)\n        \n        self.bn1 = nn.BatchNorm1d(64)\n        self.bn2 = nn.BatchNorm1d(64)\n        self.bn3 = nn.BatchNorm1d(64)\n        self.bn4 = nn.BatchNorm1d(128)\n        self.bn5 = nn.BatchNorm1d(1024)\n        \n        # Classifier MLP\n        self.fc1 = nn.Linear(1024, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, num_classes)\n        \n        self.bn_fc1 = nn.BatchNorm1d(512)\n        self.bn_fc2 = nn.BatchNorm1d(256)\n        self.dropout = nn.Dropout(p=0.3)\n    \n    def forward(self, x):\n        batch_size = x.shape[0]\n        \n        # Handle flattened input\n        if x.dim() == 2:\n            x = x.view(batch_size, self.num_points, self.in_channels)\n        \n        # Separate xyz and extra features\n        if self.in_channels > 3:\n            xyz = x[:, :, :3]  # (batch, n_points, 3)\n            extra_features = x[:, :, 3:]  # (batch, n_points, in_channels-3)\n        else:\n            xyz = x\n            extra_features = None\n        \n        # Input T-Net (only on xyz)\n        if self.use_tnet:\n            xyz_t = xyz.transpose(1, 2)  # (batch, 3, n_points)\n            input_trans = self.input_tnet(xyz_t)  # (batch, 3, 3)\n            xyz = torch.bmm(xyz, input_trans)  # (batch, n_points, 3)\n        \n        # Recombine\n        if extra_features is not None:\n            x = torch.cat([xyz, extra_features], dim=2)\n        else:\n            x = xyz\n        \n        # Point-wise MLP\n        x = x.transpose(1, 2)  # (batch, in_channels, n_points)\n        x = F.relu(self.bn1(self.conv1(x)))  # (batch, 64, n_points)\n        x = F.relu(self.bn2(self.conv2(x)))  # (batch, 64, n_points)\n        \n        # Feature T-Net\n        if self.feature_transform:\n            feat_trans = self.feat_tnet(x)  # (batch, 64, 64)\n            x = x.transpose(1, 2)  # (batch, n_points, 64)\n            x = torch.bmm(x, feat_trans)  # (batch, n_points, 64)\n            x = x.transpose(1, 2)  # (batch, 64, n_points)\n        \n        x = F.relu(self.bn3(self.conv3(x)))  # (batch, 64, n_points)\n        x = F.relu(self.bn4(self.conv4(x)))  # (batch, 128, n_points)\n        x = F.relu(self.bn5(self.conv5(x)))  # (batch, 1024, n_points)\n        \n        # Global max pooling\n        x = torch.max(x, dim=2)[0]  # (batch, 1024)\n        \n        # Classifier\n        x = F.relu(self.bn_fc1(self.fc1(x)))\n        x = self.dropout(x)\n        x = F.relu(self.bn_fc2(self.fc2(x)))\n        x = self.dropout(x)\n        x = self.fc3(x)\n        \n        return x\n    \n    def get_transforms(self, x):\n        \"\"\"Return input and feature transforms for regularization.\"\"\"\n        batch_size = x.shape[0]\n        \n        if x.dim() == 2:\n            x = x.view(batch_size, self.num_points, self.in_channels)\n        \n        if self.in_channels > 3:\n            xyz = x[:, :, :3]\n        else:\n            xyz = x\n        \n        input_trans = None\n        feat_trans = None\n        \n        if self.use_tnet:\n            xyz_t = xyz.transpose(1, 2)\n            input_trans = self.input_tnet(xyz_t)\n            xyz = torch.bmm(xyz, input_trans)\n        \n        if self.in_channels > 3:\n            x = torch.cat([xyz, x[:, :, 3:]], dim=2)\n        else:\n            x = xyz\n        \n        x = x.transpose(1, 2)\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = F.relu(self.bn2(self.conv2(x)))\n        \n        if self.feature_transform:\n            feat_trans = self.feat_tnet(x)\n        \n        return input_trans, feat_trans\n\n\n# Create model\nmodel = PointNetForVerification(\n    num_points=N_POINTS,\n    num_classes=NUM_CLASSES,\n    use_tnet=True,\n    feature_transform=True,\n    in_channels=IN_CHANNELS,\n).to(device)\n\nn_params = sum(p.numel() for p in model.parameters())\nprint(f\"PointNet parameters: {n_params:,}\")\nprint(f\"Expected: ~3.5M parameters\")"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "verify-funcs",
    "outputId": "1db38049-0bd6-4015-bd5d-8fcca9a6a669"
   },
   "outputs": [],
   "source": "## 4. Training"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "prop1-header"
   },
   "source": "def feature_transform_regularizer(trans):\n    \"\"\"Regularization loss for feature transform to be close to orthogonal.\"\"\"\n    d = trans.size()[1]\n    I = torch.eye(d, device=trans.device).unsqueeze(0)\n    loss = torch.mean(torch.norm(I - torch.bmm(trans, trans.transpose(2, 1)), dim=(1, 2)))\n    return loss\n\n\ndef train_epoch(model, loader, criterion, optimizer):\n    \"\"\"Train for one epoch.\"\"\"\n    model.train()\n    total_loss = 0\n    correct = 0\n    total = 0\n    \n    for batch_data, batch_labels in loader:\n        batch_data = batch_data.to(device)\n        batch_labels = batch_labels.to(device)\n        \n        optimizer.zero_grad()\n        \n        # Forward pass\n        outputs = model(batch_data)\n        loss = criterion(outputs, batch_labels)\n        \n        # Add feature transform regularization\n        if model.feature_transform:\n            _, feat_trans = model.get_transforms(batch_data)\n            if feat_trans is not None:\n                loss = loss + 0.001 * feature_transform_regularizer(feat_trans)\n        \n        # Backward pass\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item() * batch_data.size(0)\n        _, predicted = outputs.max(1)\n        correct += predicted.eq(batch_labels).sum().item()\n        total += batch_data.size(0)\n    \n    return total_loss / total, 100.0 * correct / total\n\n\ndef evaluate(model, loader):\n    \"\"\"Evaluate model on dataset.\"\"\"\n    model.eval()\n    correct = 0\n    total = 0\n    \n    with torch.no_grad():\n        for batch_data, batch_labels in loader:\n            batch_data = batch_data.to(device)\n            batch_labels = batch_labels.to(device)\n            \n            outputs = model(batch_data)\n            _, predicted = outputs.max(1)\n            correct += predicted.eq(batch_labels).sum().item()\n            total += batch_data.size(0)\n    \n    return 100.0 * correct / total"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "prop1-verify",
    "outputId": "89626b82-8db3-49df-b165-a3bf4702be4e"
   },
   "outputs": [],
   "source": "# Training loop\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n\nbest_acc = 0\nhistory = {'train_loss': [], 'train_acc': [], 'test_acc': []}\n\nprint(\"=\"*60)\nprint(\"Training PointNet\")\nprint(\"=\"*60)\n\nfor epoch in range(EPOCHS):\n    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)\n    test_acc = evaluate(model, test_loader)\n    scheduler.step()\n    \n    history['train_loss'].append(train_loss)\n    history['train_acc'].append(train_acc)\n    history['test_acc'].append(test_acc)\n    \n    if test_acc > best_acc:\n        best_acc = test_acc\n        # Save best model\n        torch.save({\n            'model_state_dict': model.state_dict(),\n            'n_points': N_POINTS,\n            'num_classes': NUM_CLASSES,\n            'in_channels': IN_CHANNELS,\n            'use_tnet': True,\n            'feature_transform': True,\n            'test_accuracy': best_acc,\n        }, 'pointnet_best.pth')\n    \n    if (epoch + 1) % 5 == 0 or epoch == 0:\n        print(f\"Epoch {epoch+1:3d}/{EPOCHS} | Loss: {train_loss:.4f} | \"\n              f\"Train Acc: {train_acc:.1f}% | Test Acc: {test_acc:.1f}% | Best: {best_acc:.1f}%\")\n\nprint(f\"\\nTraining complete! Best accuracy: {best_acc:.2f}%\")"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "prop2-header"
   },
   "source": "# Plot training curves\nimport matplotlib.pyplot as plt\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 4))\n\n# Loss\naxes[0].plot(history['train_loss'], 'b-', label='Train Loss')\naxes[0].set_xlabel('Epoch')\naxes[0].set_ylabel('Loss')\naxes[0].set_title('Training Loss')\naxes[0].legend()\naxes[0].grid(True, alpha=0.3)\n\n# Accuracy\naxes[1].plot(history['train_acc'], 'b-', label='Train Acc')\naxes[1].plot(history['test_acc'], 'r-', label='Test Acc')\naxes[1].axhline(y=best_acc, color='g', linestyle='--', label=f'Best: {best_acc:.1f}%')\naxes[1].set_xlabel('Epoch')\naxes[1].set_ylabel('Accuracy (%)')\naxes[1].set_title('Training & Test Accuracy')\naxes[1].legend()\naxes[1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('training_curves.png', dpi=150)\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "prop2-verify",
    "outputId": "f72a6c41-c915-452c-bf3d-e4050d9ed2cd"
   },
   "outputs": [],
   "source": "# Load best model for verification\ncheckpoint = torch.load('pointnet_best.pth', map_location=device)\nmodel.load_state_dict(checkpoint['model_state_dict'])\nmodel.eval()\nprint(f\"Loaded best model with test accuracy: {checkpoint['test_accuracy']:.2f}%\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "results-header"
   },
   "source": "## 5. Verification with auto_LiRPA\n\nUsing auto_LiRPA API directly (native PyTorch support for Conv1d, MaxPool, etc.)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "results-summary",
    "outputId": "b4f82119-ba9d-4b70-f51a-581ba9d3f9ee"
   },
   "outputs": [],
   "source": "def verify_robustness_lirpa(model, sample, label, epsilon, method='IBP+backward'):\n    \"\"\"\n    Verify local robustness using auto_LiRPA.\n    \n    Property: ∀x' with ||x' - x₀||∞ ≤ ε : f(x') = f(x₀)\n    \n    Args:\n        model: PyTorch model\n        sample: Input sample (n_points, in_channels)\n        label: True label\n        epsilon: L-inf perturbation bound\n        method: Bound propagation method ('IBP', 'IBP+backward', 'CROWN')\n    \n    Returns:\n        dict with verification result\n    \"\"\"\n    model.eval()\n    model_cpu = model.cpu()\n    \n    # Prepare input\n    sample_tensor = torch.FloatTensor(sample).unsqueeze(0)  # (1, n_points, in_channels)\n    \n    # Create bounded model\n    bounded_model = BoundedModule(model_cpu, sample_tensor, device='cpu')\n    \n    # Define perturbation\n    ptb = PerturbationLpNorm(norm=float('inf'), eps=epsilon)\n    bounded_input = BoundedTensor(sample_tensor, ptb)\n    \n    # Compute bounds\n    lb, ub = bounded_model.compute_bounds(x=(bounded_input,), method=method)\n    \n    # Check if correct class is always highest\n    # For binary classification: label=0 means class 0 > class 1, label=1 means class 1 > class 0\n    if label == 0:\n        # Need lb[0] > ub[1] (class 0 always higher than class 1)\n        margin = lb[0, 0] - ub[0, 1]\n    else:\n        # Need lb[1] > ub[0] (class 1 always higher than class 0)\n        margin = lb[0, 1] - ub[0, 0]\n    \n    verified = margin.item() > 0\n    \n    # Move model back to device\n    model.to(device)\n    \n    return {\n        'verified': verified,\n        'margin': margin.item(),\n        'lb': lb.detach().numpy(),\n        'ub': ub.detach().numpy(),\n        'method': method\n    }\n\n\ndef verify_safety_lirpa(model, sample, epsilon, method='IBP+backward'):\n    \"\"\"\n    Verify safety property using auto_LiRPA.\n    \n    Property: For CRITICAL samples, no perturbation causes NON_CRITICAL classification.\n    \n    Args:\n        model: PyTorch model\n        sample: Input sample (n_points, in_channels)\n        epsilon: L-inf perturbation bound\n        method: Bound propagation method\n    \n    Returns:\n        dict with verification result\n    \"\"\"\n    model.eval()\n    model_cpu = model.cpu()\n    \n    # Prepare input\n    sample_tensor = torch.FloatTensor(sample).unsqueeze(0)\n    \n    # First check prediction\n    with torch.no_grad():\n        output = model_cpu(sample_tensor)\n        pred = output.argmax(dim=1).item()\n        confidence = torch.softmax(output, dim=1)[0]\n    \n    # Only verify if predicted as CRITICAL (class 0)\n    if pred != 0:\n        model.to(device)\n        return {\n            'verified': False,\n            'status': 'skipped_wrong_prediction',\n            'original_prediction': pred,\n            'confidence': confidence.numpy()\n        }\n    \n    # Create bounded model\n    bounded_model = BoundedModule(model_cpu, sample_tensor, device='cpu')\n    \n    # Define perturbation\n    ptb = PerturbationLpNorm(norm=float('inf'), eps=epsilon)\n    bounded_input = BoundedTensor(sample_tensor, ptb)\n    \n    # Compute bounds\n    lb, ub = bounded_model.compute_bounds(x=(bounded_input,), method=method)\n    \n    # Safety: CRITICAL (class 0) should always have higher score than NON_CRITICAL (class 1)\n    # Need lb[0] > ub[1]\n    margin = lb[0, 0] - ub[0, 1]\n    verified = margin.item() > 0\n    \n    model.to(device)\n    \n    return {\n        'verified': verified,\n        'margin': margin.item(),\n        'lb': lb.detach().numpy(),\n        'ub': ub.detach().numpy(),\n        'method': method,\n        'original_prediction': pred,\n        'confidence': confidence.numpy()\n    }\n\n\nprint(\"Verification functions defined using auto_LiRPA API!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "save-results",
    "outputId": "1a67f20a-a2e5-4bd2-aff2-b59a53e84359"
   },
   "outputs": [],
   "source": "# Property 1: Local Robustness Verification\nprint(\"=\"*70)\nprint(\"PROPERTY 1: LOCAL ROBUSTNESS (L∞)\")\nprint(\"Verifying: ∀x' with ||x' - x₀||∞ ≤ ε : f(x') = f(x₀)\")\nprint(\"=\"*70)\n\nrobustness_results = {}\n\nfor eps in EPSILONS:\n    print(f\"\\nε = {eps}\")\n    print(\"-\"*40)\n    \n    verified_count = 0\n    total = 0\n    \n    for i in range(N_VERIFY_SAMPLES):\n        sample = test_groups[i]\n        label = int(test_labels[i])\n        label_str = \"CRITICAL\" if label == 0 else \"NON_CRITICAL\"\n        \n        try:\n            result = verify_robustness_lirpa(model, sample, label, eps)\n            if result['verified']:\n                verified_count += 1\n                status = f\"✓ VERIFIED (margin={result['margin']:.4f})\"\n            else:\n                status = f\"✗ NOT VERIFIED (margin={result['margin']:.4f})\"\n            total += 1\n        except Exception as e:\n            status = f\"⚠ ERROR: {str(e)[:30]}\"\n        \n        print(f\"  Sample {i:3d} ({label_str:12}): {status}\")\n    \n    robustness_results[str(eps)] = {\n        'epsilon': eps,\n        'verified': verified_count,\n        'total': total,\n        'verified_pct': 100 * verified_count / total if total > 0 else 0\n    }\n    \n    print(f\"\\n  Summary: {verified_count}/{total} verified ({robustness_results[str(eps)]['verified_pct']:.1f}%)\")"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "viz-header"
   },
   "source": "# Property 2: Safety Verification\nprint(\"=\"*70)\nprint(\"PROPERTY 2: SAFETY PROPERTY\")\nprint(\"Verifying: For CRITICAL samples, never misclassified as NON_CRITICAL\")\nprint(\"=\"*70)\n\n# Get CRITICAL samples (label=0)\ncritical_indices = np.where(test_labels == 0)[0]\nn_critical = min(N_VERIFY_SAMPLES, len(critical_indices))\n\nsafety_results = {}\n\nfor eps in EPSILONS:\n    print(f\"\\nε = {eps}\")\n    print(\"-\"*40)\n    \n    verified_count = 0\n    skipped_count = 0\n    total = 0\n    \n    for i, idx in enumerate(critical_indices[:n_critical]):\n        sample = test_groups[idx]\n        \n        try:\n            result = verify_safety_lirpa(model, sample, eps)\n            \n            if result.get('status') == 'skipped_wrong_prediction':\n                skipped_count += 1\n                status = f\"⊘ SKIPPED (model predicts NON_CRITICAL)\"\n            elif result['verified']:\n                verified_count += 1\n                status = f\"✓ SAFE (margin={result['margin']:.4f})\"\n                total += 1\n            else:\n                status = f\"✗ UNSAFE (margin={result['margin']:.4f})\"\n                total += 1\n        except Exception as e:\n            status = f\"⚠ ERROR: {str(e)[:30]}\"\n        \n        print(f\"  Sample {idx:3d} (CRITICAL): {status}\")\n    \n    safety_results[str(eps)] = {\n        'epsilon': eps,\n        'verified': verified_count,\n        'total': total,\n        'skipped': skipped_count,\n        'verified_pct': 100 * verified_count / total if total > 0 else 0\n    }\n    \n    print(f\"\\n  Summary: {verified_count}/{total} safe ({safety_results[str(eps)]['verified_pct']:.1f}%), {skipped_count} skipped\")"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "viz-plot",
    "outputId": "742083d8-4fd0-4606-f49d-a26ed054d4ba"
   },
   "outputs": [],
   "source": "## 6. Results Summary"
  },
  {
   "cell_type": "code",
   "source": "# Results Summary\nprint(\"\\n\" + \"=\"*70)\nprint(\"FINAL RESULTS SUMMARY\")\nprint(\"=\"*70)\n\n# Property 1 Table\nprint(\"\\n### PROPERTY 1: LOCAL ROBUSTNESS ###\")\nprint(f\"{'Epsilon':>10} | {'Verified':>10} | {'Total':>10} | {'Verified %':>12}\")\nprint(\"-\"*50)\nfor eps_str, r in robustness_results.items():\n    print(f\"{float(eps_str):>10.4f} | {r['verified']:>10} | {r['total']:>10} | {r['verified_pct']:>10.1f}%\")\n\n# Property 2 Table\nprint(f\"\\n### PROPERTY 2: SAFETY (CRITICAL -> never NON_CRITICAL) ###\")\nprint(f\"{'Epsilon':>10} | {'Safe':>10} | {'Total':>10} | {'Safe %':>12} | {'Skipped':>10}\")\nprint(\"-\"*65)\nfor eps_str, r in safety_results.items():\n    print(f\"{float(eps_str):>10.4f} | {r['verified']:>10} | {r['total']:>10} | {r['verified_pct']:>10.1f}% | {r['skipped']:>10}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Visualization\nimport matplotlib.pyplot as plt\n\neps_values = [float(e) for e in robustness_results.keys()]\nrobustness_pct = [r['verified_pct'] for r in robustness_results.values()]\nsafety_pct = [r['verified_pct'] for r in safety_results.values()]\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Plot 1: Robustness\nax1 = axes[0]\nax1.plot(eps_values, robustness_pct, 'b-o', linewidth=2, markersize=8)\nax1.axhline(y=50, color='r', linestyle='--', label='50% threshold')\nax1.set_xlabel('Perturbation (ε)', fontsize=12)\nax1.set_ylabel('Verified (%)', fontsize=12)\nax1.set_title('Property 1: Local Robustness', fontsize=14)\nax1.legend()\nax1.grid(True, alpha=0.3)\nax1.set_ylim([0, 105])\n\n# Plot 2: Safety\nax2 = axes[1]\ncolors = ['green' if p == 100 else ('orange' if p > 50 else 'red') for p in safety_pct]\nax2.bar(range(len(eps_values)), safety_pct, color=colors, alpha=0.7)\nax2.set_xticks(range(len(eps_values)))\nax2.set_xticklabels([f'{e:.3f}' for e in eps_values])\nax2.axhline(y=100, color='green', linestyle='-', linewidth=2, label='Safety verified')\nax2.set_xlabel('Perturbation (ε)', fontsize=12)\nax2.set_ylabel('Safe Samples (%)', fontsize=12)\nax2.set_title('Property 2: Safety (CRITICAL → never NON_CRITICAL)', fontsize=14)\nax2.legend()\nax2.grid(True, alpha=0.3, axis='y')\nax2.set_ylim([0, 105])\n\nplt.tight_layout()\nplt.savefig('verification_results.png', dpi=150, bbox_inches='tight')\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Save results locally\nfinal_results = {\n    \"timestamp\": datetime.now().isoformat(),\n    \"model\": {\n        \"type\": \"PointNetForVerification\",\n        \"n_points\": N_POINTS,\n        \"in_channels\": IN_CHANNELS,\n        \"num_classes\": NUM_CLASSES,\n        \"use_tnet\": True,\n        \"feature_transform\": True,\n        \"parameters\": n_params,\n        \"test_accuracy\": best_acc,\n    },\n    \"verification_method\": \"auto_LiRPA (IBP+backward)\",\n    \"n_verify_samples\": N_VERIFY_SAMPLES,\n    \"property1_robustness\": robustness_results,\n    \"property2_safety\": safety_results,\n}\n\nwith open('verification_results.json', 'w') as f:\n    json.dump(final_results, f, indent=2)\n\nprint(\"Results saved locally:\")\nprint(\"  - pointnet_best.pth (model checkpoint)\")\nprint(\"  - verification_results.json\")\nprint(\"  - verification_results.png\")\nprint(\"  - training_curves.png\")\nprint(\"\\nRun the next cell to download all files to your computer.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Download all files to your computer\nfrom google.colab import files\n\nprint(\"Downloading files...\")\nfiles.download('pointnet_best.pth')\nfiles.download('verification_results.json')\nfiles.download('verification_results.png')\nfiles.download('training_curves.png')\nprint(\"Done! Check your Downloads folder.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}