{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": "# PointNet Training & Verification with α,β-CROWN\n\n## LiDAR Point Cloud Classification + Formal Verification\n\nThis notebook:\n1. **Loads** raw LiDAR frames (~14M points) from your repository\n2. **Loads NSGA-III Pareto genomes** for vulnerability-based labeling\n3. **Runs QUICK SANITY CHECK** before full training (5 epochs + 3 verification tests)\n4. **Trains** PointNet with data augmentation on GPU (50 epochs)\n5. **Verifies** robustness properties using α,β-CROWN API\n\n### Key Innovation: NSGA-III Vulnerability Labeling\nLabels are computed using **MAX vulnerability across all Pareto-optimal genomes**:\n- 5 genomes from NSGA-III optimization (different attack strategies)\n- A region is CRITICAL if vulnerable to ANY of these attacks\n- Threshold derived from data (median vulnerability)\n- Direct link between \"what breaks SLAM\" and \"what PointNet should detect\"\n\n### Quick Sanity Check (NEW!)\nBefore wasting 30+ minutes on full training, we run a quick check:\n- Train 5 epochs on 2000 samples (~3 min)\n- Check accuracy >= 55%\n- Test α,β-CROWN verification on 3 samples\n- **FAIL FAST** if something is wrong!\n\n### Architecture: Original PointNet (Qi et al., CVPR 2017)\n- Input T-Net (3x3) for spatial alignment\n- Feature T-Net (64x64) for feature alignment  \n- Point-wise MLP: 3→64→64→64→128→1024 (5 conv layers with BatchNorm)\n- Global max pooling\n- Classifier MLP: 1024→512→256→2 (with BatchNorm + Dropout)\n- **~3.5M parameters**\n\n### Input Format: (N, 1024, 3) - xyz only!\n- xyz coordinates (3 channels)\n- **Note**: Geometric features (linearity, curvature, density_var, planarity) \n  are used for **labeling only**, NOT as input to the model.\n  This ensures the model must learn geometry from raw coordinates!\n\n### Label Computation (NSGA-III vulnerability):\n```python\nmax_vulnerability = max([vuln(genome) for genome in pareto_set])\nlabel = CRITICAL if max_vulnerability >= threshold else NON_CRITICAL\n```\n\n### Properties Verified:\n\n**Property 1: Local Robustness (L∞)**\n```\n∀x' with ||x' - x₀||∞ ≤ ε : f(x') = f(x₀)\n```\n\n**Property 2: Safety Property**\n```\n∀x' with ||x' - x₀||∞ ≤ ε ∧ f(x₀)=CRITICAL : f(x') ≠ NON_CRITICAL\n```"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-header"
   },
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "check-gpu",
    "outputId": "1f7e5966-0893-4601-80da-4cea0ecaf7c9"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fri Jan  2 17:52:23 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   40C    P8              9W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Check GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-deps"
   },
   "outputs": [],
   "source": "# Install dependencies\n!pip install torch numpy onnx onnxruntime pyyaml packaging appdirs sortedcontainers path.py -q\n\n# Clone alpha-beta-CROWN repository (for complete_verifier API)\n!git clone https://github.com/Verified-Intelligence/alpha-beta-CROWN.git 2>/dev/null || true\n\n# Install auto_LiRPA directly from GitHub\n!pip install git+https://github.com/Verified-Intelligence/auto_LiRPA.git --no-deps -q\n\nprint(\"Dependencies installed!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "setup-paths",
    "outputId": "455c08e7-7358-4737-e315-c83ad964d345"
   },
   "outputs": [],
   "source": "# Setup paths and imports\nimport sys\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nimport json\nfrom datetime import datetime\nfrom torch.utils.data import TensorDataset, DataLoader\n\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nprint(f\"PyTorch: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\nprint(f\"Device: {device}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "la7wHTOP6faN"
   },
   "outputs": [],
   "source": "# Import auto_LiRPA for verification\nfrom auto_LiRPA import BoundedModule, BoundedTensor, PerturbationLpNorm\nprint(\"auto_LiRPA imported successfully!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bkAEM9RK6r-8",
    "outputId": "4687c6aa-78f5-488e-a302-fa7486ef2bc7"
   },
   "outputs": [],
   "source": "# Set random seeds for reproducibility\nimport random\nrandom.seed(42)\nnp.random.seed(42)\ntorch.manual_seed(42)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(42)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "import-abcrown",
    "outputId": "a2de54de-d57a-4c9f-a5c4-e855e34a7b61"
   },
   "outputs": [],
   "source": "# Configuration\nN_POINTS = 1024        # Points per sample (original PointNet)\nIN_CHANNELS = 3        # xyz only! Model must learn geometry from raw coordinates\nNUM_CLASSES = 2        # CRITICAL vs NON_CRITICAL\nINPUT_DIM = N_POINTS * IN_CHANNELS  # 3072\n\n# Training config\nEPOCHS = 50\nBATCH_SIZE = 32\nLEARNING_RATE = 0.001\n\n# Verification config\nEPSILONS = [0.001, 0.003, 0.005, 0.007, 0.01]  # L-inf perturbation budgets\nN_VERIFY_SAMPLES = 20  # Samples to verify\n\nprint(f\"Configuration:\")\nprint(f\"  Points per sample: {N_POINTS}\")\nprint(f\"  Input channels: {IN_CHANNELS} (xyz only - features used for labeling only)\")\nprint(f\"  Input dimension: {INPUT_DIM}\")\nprint(f\"  Classes: {NUM_CLASSES}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model-header"
   },
   "source": "## 2. Load Data from GitHub\n\nData files are stored in the repository using Git LFS in `data/pointnet/`."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "model-defs",
    "outputId": "6202eee1-130e-43c3-8e9f-7d4c4f77b684"
   },
   "outputs": [],
   "source": "# Clone repository and fetch Git LFS data\nimport os\nimport shutil\n\nREPO_URL = \"https://github.com/francescacraievich/mola-pointnet-verification.git\"\nREPO_DIR = \"/content/mola-pointnet-verification\"\nRAW_DATA_PATH = f\"{REPO_DIR}/data/raw\"\n\n# Force re-clone to get latest data (remove old clone if exists)\nif os.path.exists(REPO_DIR):\n    print(f\"Removing old clone at {REPO_DIR}...\")\n    shutil.rmtree(REPO_DIR)\n\n# Install and setup Git LFS\nprint(\"Setting up Git LFS...\")\n!git lfs install\n\n# Clone with LFS\nprint(\"\\nCloning repository...\")\n!git clone {REPO_URL} {REPO_DIR}\n\n# Pull LFS files explicitly\nprint(\"\\nFetching LFS files...\")\n%cd {REPO_DIR}\n!git lfs pull\n%cd /content\n\nprint(\"\\nDone!\")\n\n# Verify raw data files exist\nprint(\"\\nChecking data files:\")\nraw_files = ['frame_sequence.npy', 'frame_sequence.timestamps.npy']\nfor f in raw_files:\n    path = os.path.join(RAW_DATA_PATH, f)\n    if os.path.exists(path):\n        size = os.path.getsize(path) / 1e6\n        print(f\"  ✓ {f}: {size:.1f} MB\")\n    else:\n        print(f\"  ✗ {f}: NOT FOUND\")\n        \n# Also check if files are LFS pointers (small size = pointer, not actual data)\nframe_path = os.path.join(RAW_DATA_PATH, 'frame_sequence.npy')\nif os.path.exists(frame_path):\n    size = os.path.getsize(frame_path)\n    if size < 1000:  # Less than 1KB = probably a pointer\n        print(f\"\\n⚠ WARNING: frame_sequence.npy is only {size} bytes - likely a Git LFS pointer!\")\n        print(\"   Running 'git lfs pull' again...\")\n        %cd {REPO_DIR}\n        !git lfs fetch --all\n        !git lfs checkout\n        %cd /content\n        # Check again\n        size = os.path.getsize(frame_path)\n        print(f\"   After LFS fetch: {size / 1e6:.1f} MB\")"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "data-header"
   },
   "source": "# Load raw frames and compute features ONCE (cached)\nfrom scipy.spatial import cKDTree\n\ndef compute_local_features(points, k=15):\n    \"\"\"\n    Compute geometric features for each point in the cloud.\n    \n    Returns:\n        linearity: Edge/line feature strength\n        curvature: Surface curvature  \n        density_var: Local density variation (scanline vulnerability)\n        planarity: How planar the local neighborhood is\n    \"\"\"\n    n = len(points)\n    xyz = points[:, :3]\n    \n    # Subsample for speed if too large\n    max_points = 50000\n    if n > max_points:\n        sample_idx = np.random.choice(n, max_points, replace=False)\n        xyz_sample = xyz[sample_idx]\n    else:\n        sample_idx = np.arange(n)\n        xyz_sample = xyz\n    \n    tree = cKDTree(xyz_sample)\n    distances, neighbors_idx = tree.query(xyz_sample, k=min(k + 1, len(xyz_sample)))\n    \n    linearity = np.zeros(len(xyz_sample))\n    curvature = np.zeros(len(xyz_sample))\n    planarity = np.zeros(len(xyz_sample))\n    \n    # Compute density variation\n    mean_dist = distances[:, 1:].mean(axis=1)\n    std_dist = distances[:, 1:].std(axis=1)\n    density_var = std_dist / (mean_dist + 1e-10)\n    \n    # Compute eigenvalue-based features\n    for i in range(len(xyz_sample)):\n        neighbors = xyz_sample[neighbors_idx[i]]\n        centered = neighbors - neighbors.mean(axis=0)\n        \n        if len(centered) >= 3:\n            cov = np.cov(centered.T)\n            try:\n                eigvals = np.sort(np.linalg.eigvalsh(cov))[::-1]\n                total = eigvals.sum() + 1e-10\n                linearity[i] = (eigvals[0] - eigvals[1]) / (eigvals[0] + 1e-10)\n                curvature[i] = eigvals[2] / total\n                planarity[i] = (eigvals[1] - eigvals[2]) / (eigvals[0] + 1e-10)\n            except:\n                pass\n    \n    # Map back to full point cloud if subsampled\n    if n > max_points:\n        _, nearest = tree.query(xyz, k=1)\n        return linearity[nearest], curvature[nearest], density_var[nearest], planarity[nearest]\n    \n    return linearity, curvature, density_var, planarity\n\n\n# Load frames\nprint(\"Loading raw frame sequence...\")\nframes = np.load(os.path.join(RAW_DATA_PATH, 'frame_sequence.npy'), allow_pickle=True)\nprint(f\"Loaded {len(frames)} frames\")\n\n# Count total points\ntotal_points = sum(len(f) for f in frames)\nprint(f\"Total points: {total_points:,}\")\nprint(f\"Average points per frame: {total_points // len(frames):,}\")\n\n# Pre-compute features for each frame (do this ONCE)\nprint(\"\\nPre-computing geometric features for each frame...\")\nprint(\"(This takes a few minutes but only happens once)\")\n\nframe_features = []\nfor i, frame in enumerate(frames):\n    if (i + 1) % 10 == 0:\n        print(f\"  Processing frame {i+1}/{len(frames)}...\")\n    \n    linearity, curvature, density_var, planarity = compute_local_features(frame, k=15)\n    \n    # Store features alongside frame\n    frame_features.append({\n        'xyz': frame[:, :3],\n        'linearity': linearity,\n        'curvature': curvature,\n        'density_var': density_var,\n        'planarity': planarity,\n    })\n\nprint(f\"\\nFeatures computed for all {len(frames)} frames!\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Load NSGA-III derived weights for labeling\n# This creates a direct link between adversarial attack results and PointNet training\n\n# Detect environment: Colab or local\nimport sys\nimport os\n\n# Check if running on Colab\nON_COLAB = 'google.colab' in sys.modules\n\nif ON_COLAB:\n    # On Colab, use the cloned repo path\n    SRC_PATH = REPO_DIR + '/src'\n    RUNS_PATH = REPO_DIR + '/runs'\nelse:\n    # Running locally - find the src directory relative to notebook\n    # notebooks/ is at the same level as src/\n    notebook_dir = os.path.dirname(os.path.abspath('__file__'))\n    if os.path.exists('../src'):\n        SRC_PATH = '../src'\n        RUNS_PATH = '../runs'\n    elif os.path.exists('src'):\n        SRC_PATH = 'src'\n        RUNS_PATH = 'runs'\n    else:\n        # Try absolute path from notebook location\n        SRC_PATH = '/home/francesca/mola-pointnet-verification/src'\n        RUNS_PATH = '/home/francesca/mola-pointnet-verification/runs'\n\nprint(f\"Environment: {'Colab' if ON_COLAB else 'Local'}\")\nprint(f\"Source path: {SRC_PATH}\")\nprint(f\"Runs path: {RUNS_PATH}\")\n\n# Add src to Python path\nif SRC_PATH not in sys.path:\n    sys.path.insert(0, SRC_PATH)\n\ntry:\n    from nsga3_integration import get_criticality_weights, get_pareto_front_summary\n    print(\"✓ nsga3_integration module loaded successfully!\")\n    \n    # Get weights - will use fallback if NSGA-III results not found\n    CRITICALITY_WEIGHTS = get_criticality_weights(\n        nsga3_results_dir=RUNS_PATH if os.path.exists(RUNS_PATH) else None,\n        run_id=12,  # Use latest run\n        fallback_weights={\n            \"linearity\": 0.0,\n            \"curvature\": 0.15,\n            \"density_var\": 0.25,\n            \"nonplanarity\": 0.60,\n        }\n    )\n    \n    # Try to get Pareto front summary for analysis\n    if os.path.exists(RUNS_PATH):\n        try:\n            pareto_summary = get_pareto_front_summary(RUNS_PATH, run_id=12)\n            if pareto_summary:\n                print(f\"\\nNSGA-III Pareto Front Summary:\")\n                print(f\"  Solutions: {pareto_summary.get('n_solutions', 'N/A')}\")\n                print(f\"  Best ATE: {pareto_summary.get('best_ate_cm', 'N/A'):.1f} cm\")\n                print(f\"  Baseline ATE: {pareto_summary.get('baseline_ate_cm', 23):.1f} cm\")\n                print(f\"  Critical threshold: {pareto_summary.get('critical_threshold_cm', 1.5):.1f} cm perturbation\")\n        except Exception as e:\n            print(f\"Could not load Pareto summary: {e}\")\n            \nexcept ImportError as e:\n    print(f\"nsga3_integration module not found: {e}\")\n    print(\"Using default weights...\")\n    CRITICALITY_WEIGHTS = {\n        \"linearity\": 0.0,\n        \"curvature\": 0.15,\n        \"density_var\": 0.25,\n        \"nonplanarity\": 0.60,\n    }\n\nprint(f\"\\nCriticality weights for labeling:\")\nfor feat, weight in CRITICALITY_WEIGHTS.items():\n    print(f\"  {feat}: {weight:.4f}\")\nprint(f\"\\nThese weights determine which regions are labeled as CRITICAL vs NON_CRITICAL\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "setup-files",
    "outputId": "d8e62543-ffe4-49e8-c042-299821f16a5c"
   },
   "outputs": [],
   "source": "# Load Pareto set from NSGA-III results for vulnerability-based labeling\n# This must come BEFORE creating datasets!\n\nfrom nsga3_integration import (\n    load_pareto_set,\n    compute_max_vulnerability,\n    compute_vulnerability_label,\n)\n\n# Load Pareto-optimal genomes (5 solutions from NSGA-III)\n# RUNS_PATH was defined in previous cell\nPARETO_SET = load_pareto_set(RUNS_PATH, run_id=12)\n\nif PARETO_SET is not None:\n    print(f\"✓ Loaded Pareto set: {PARETO_SET.shape} ({PARETO_SET.shape[0]} genomes)\")\n    \n    # Compute threshold from data (median vulnerability)\n    print(\"\\nComputing vulnerability distribution for threshold selection...\")\n    test_vulns = []\n    for i in range(100):\n        # Sample random neighborhood\n        frame_idx = np.random.randint(0, len(frame_features))\n        ff = frame_features[frame_idx]\n        seed_idx = np.random.randint(0, len(ff['xyz']))\n        \n        # Get neighborhood\n        tree = cKDTree(ff['xyz'])\n        _, neighbor_idx = tree.query(ff['xyz'][seed_idx], k=N_POINTS)\n        points = ff['xyz'][neighbor_idx]\n        points = points - points.mean(axis=0)  # Center\n        \n        curvature = ff['curvature'][neighbor_idx]\n        linearity = ff['linearity'][neighbor_idx]\n        \n        vuln = compute_max_vulnerability(points, PARETO_SET, curvature, linearity)\n        test_vulns.append(vuln)\n    \n    VULNERABILITY_THRESHOLD = float(np.median(test_vulns))\n    print(f\"\\nVulnerability statistics:\")\n    print(f\"  Min: {np.min(test_vulns):.4f}\")\n    print(f\"  Max: {np.max(test_vulns):.4f}\")\n    print(f\"  Mean: {np.mean(test_vulns):.4f}\")\n    print(f\"  Median (THRESHOLD): {VULNERABILITY_THRESHOLD:.4f}\")\nelse:\n    print(\"⚠ Pareto set not found - using fallback threshold\")\n    PARETO_SET = None\n    VULNERABILITY_THRESHOLD = 0.4"
  },
  {
   "cell_type": "markdown",
   "source": "## 2.5 Create Datasets with NSGA-III Vulnerability Labeling\n\nNow we create the training and test datasets using the Pareto genomes for labeling.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# On-the-fly Dataset class with Data Augmentation\n# Uses NSGA-III vulnerability-based labeling (genome-driven, not linear formula!)\nfrom torch.utils.data import Dataset\n\nclass LiDAROnTheFlyDataset(Dataset):\n    \"\"\"\n    Dataset that samples point cloud groups ON-THE-FLY from raw LiDAR frames.\n    \n    Each __getitem__ call samples a random local neighborhood from a random frame,\n    so the model sees different samples every epoch.\n    \n    **IMPORTANT**: Returns only xyz (3 channels) as input!\n    Geometric features are computed for LABELING only, not as model input.\n    \n    **LABELING**: Uses NSGA-III Pareto genomes to compute vulnerability.\n    A region is CRITICAL if it's vulnerable to ANY of the Pareto-optimal attacks.\n    \"\"\"\n    \n    def __init__(self, frame_features, pareto_set=None, threshold=0.5, \n                 fallback_weights=None, n_points=1024, samples_per_epoch=10000, \n                 seed=None, augment=False):\n        self.frame_features = frame_features\n        self.pareto_set = pareto_set\n        self.threshold = threshold\n        self.fallback_weights = fallback_weights or {\n            \"linearity\": 0.0,\n            \"curvature\": 0.15,\n            \"density_var\": 0.25,\n            \"nonplanarity\": 0.60,\n        }\n        self.n_points = n_points\n        self.samples_per_epoch = samples_per_epoch\n        self.seed = seed\n        self.augment = augment\n        \n        # Build KD-trees for each frame (once)\n        self.trees = [cKDTree(ff['xyz']) for ff in frame_features]\n        \n        # Frame weights based on number of points\n        self.frame_weights = np.array([len(ff['xyz']) for ff in frame_features])\n        self.frame_weights = self.frame_weights / self.frame_weights.sum()\n    \n    def __len__(self):\n        return self.samples_per_epoch\n    \n    def _augment_xyz(self, xyz):\n        \"\"\"Apply augmentation to xyz coordinates.\"\"\"\n        theta = np.random.uniform(0, 2 * np.pi)\n        cos_t, sin_t = np.cos(theta), np.sin(theta)\n        rotation = np.array([[cos_t, -sin_t, 0], [sin_t, cos_t, 0], [0, 0, 1]])\n        xyz = xyz @ rotation.T\n        scale = np.random.uniform(0.9, 1.1)\n        xyz = xyz * scale\n        jitter = np.random.normal(0, 0.01, size=xyz.shape)\n        xyz = xyz + jitter\n        return xyz.astype(np.float32)\n    \n    def __getitem__(self, idx):\n        if self.seed is not None:\n            np.random.seed(self.seed + idx)\n        \n        frame_idx = np.random.choice(len(self.frame_features), p=self.frame_weights)\n        ff = self.frame_features[frame_idx]\n        tree = self.trees[frame_idx]\n        xyz = ff['xyz']\n        \n        seed_idx = np.random.randint(0, len(xyz))\n        _, neighbor_idx = tree.query(xyz[seed_idx], k=self.n_points)\n        \n        if len(neighbor_idx) < self.n_points:\n            neighbor_idx = np.pad(neighbor_idx, (0, self.n_points - len(neighbor_idx)), mode='edge')\n        \n        group_xyz = xyz[neighbor_idx].copy()\n        group_xyz = group_xyz - group_xyz.mean(axis=0)\n        max_dist = np.abs(group_xyz).max()\n        if max_dist > 0:\n            group_xyz = group_xyz / max_dist\n        \n        if self.augment:\n            group_xyz = self._augment_xyz(group_xyz)\n        \n        # Extract features FOR LABELING ONLY\n        group_linearity = ff['linearity'][neighbor_idx]\n        group_curvature = ff['curvature'][neighbor_idx]\n        group_density_var = ff['density_var'][neighbor_idx]\n        group_planarity = ff['planarity'][neighbor_idx]\n        \n        # Random point dropout during training\n        if self.augment and np.random.random() < 0.3:\n            dropout_ratio = np.random.uniform(0.05, 0.15)\n            n_dropout = int(self.n_points * dropout_ratio)\n            dropout_idx = np.random.choice(self.n_points, n_dropout, replace=False)\n            keep_idx = np.setdiff1d(np.arange(self.n_points), dropout_idx)\n            replace_idx = np.random.choice(keep_idx, n_dropout, replace=True)\n            group_xyz[dropout_idx] = group_xyz[replace_idx]\n        \n        group = group_xyz.astype(np.float32)\n        \n        # Compute label using NSGA-III vulnerability (if available)\n        if self.pareto_set is not None:\n            label = compute_vulnerability_label(\n                group_xyz, self.pareto_set, self.threshold,\n                group_curvature, group_linearity\n            )\n        else:\n            # Fallback: use linear formula\n            def normalize(f):\n                f_min, f_max = f.min(), f.max()\n                return (f - f_min) / (f_max - f_min + 1e-6)\n            \n            score = (\n                normalize(group_linearity).mean() * self.fallback_weights.get(\"linearity\", 0.0) +\n                normalize(group_curvature).mean() * self.fallback_weights.get(\"curvature\", 0.0) +\n                normalize(group_density_var).mean() * self.fallback_weights.get(\"density_var\", 0.0) +\n                (1 - normalize(group_planarity).mean()) * self.fallback_weights.get(\"nonplanarity\", 0.0)\n            )\n            label = 0 if score >= 0.4 else 1\n        \n        return torch.from_numpy(group), label\n\n\n# Create datasets\nprint(\"Creating on-the-fly datasets with NSGA-III vulnerability labeling...\")\n\nif PARETO_SET is not None:\n    print(f\"Using {PARETO_SET.shape[0]} Pareto-optimal genomes for labeling\")\n    print(f\"Vulnerability threshold: {VULNERABILITY_THRESHOLD:.4f}\")\nelse:\n    print(\"Pareto set not available - using fallback weights\")\n\ntrain_dataset = LiDAROnTheFlyDataset(\n    frame_features, pareto_set=PARETO_SET, threshold=VULNERABILITY_THRESHOLD,\n    fallback_weights=CRITICALITY_WEIGHTS, n_points=N_POINTS,\n    samples_per_epoch=20000, seed=None, augment=True\n)\n\ntest_dataset = LiDAROnTheFlyDataset(\n    frame_features, pareto_set=PARETO_SET, threshold=VULNERABILITY_THRESHOLD,\n    fallback_weights=CRITICALITY_WEIGHTS, n_points=N_POINTS,\n    samples_per_epoch=4000, seed=42, augment=False\n)\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n\nprint(f\"\\nTrain: {len(train_dataset)} samples/epoch ({len(train_loader)} batches)\")\nprint(f\"Test: {len(test_dataset)} samples ({len(test_loader)} batches)\")\nprint(f\"Labeling: {'NSGA-III vulnerability (MAX across genomes)' if PARETO_SET is not None else 'Fallback weights'}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 2.6 QUICK SANITY CHECK\n\nBefore full training (~30 min), we run a quick check (~3 min):\n1. Train on 2000 samples for 5 epochs\n2. Check accuracy is reasonable (>55%)\n3. Test α,β-CROWN verification on 3 samples\n\nIf the check fails, we stop and debug before wasting time on full training.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "###########################################\n# QUICK SANITY CHECK (before full training)\n###########################################\n\nprint(\"=\" * 60)\nprint(\"QUICK SANITY CHECK\")\nprint(\"=\" * 60)\nprint(\"This check validates the pipeline before full training.\")\nprint(\"If it fails, we can fix issues without waiting 30+ minutes.\\n\")\n\n# 1. Create small datasets for quick check\n# Use vulnerability-based labeling if PARETO_SET is available\nclass QuickCheckDataset(Dataset):\n    \"\"\"Small dataset for quick validation with NSGA-III vulnerability labeling.\"\"\"\n    \n    def __init__(self, frame_features, pareto_set, threshold, n_points=1024, \n                 samples_per_epoch=2000, seed=None, augment=False):\n        self.frame_features = frame_features\n        self.pareto_set = pareto_set\n        self.threshold = threshold\n        self.n_points = n_points\n        self.samples_per_epoch = samples_per_epoch\n        self.seed = seed\n        self.augment = augment\n        \n        # Build KD-trees\n        self.trees = [cKDTree(ff['xyz']) for ff in frame_features]\n        self.frame_weights = np.array([len(ff['xyz']) for ff in frame_features])\n        self.frame_weights = self.frame_weights / self.frame_weights.sum()\n    \n    def __len__(self):\n        return self.samples_per_epoch\n    \n    def __getitem__(self, idx):\n        if self.seed is not None:\n            np.random.seed(self.seed + idx)\n        \n        # Sample frame and point\n        frame_idx = np.random.choice(len(self.frame_features), p=self.frame_weights)\n        ff = self.frame_features[frame_idx]\n        tree = self.trees[frame_idx]\n        xyz = ff['xyz']\n        \n        seed_idx = np.random.randint(0, len(xyz))\n        _, neighbor_idx = tree.query(xyz[seed_idx], k=self.n_points)\n        \n        if len(neighbor_idx) < self.n_points:\n            neighbor_idx = np.pad(neighbor_idx, (0, self.n_points - len(neighbor_idx)), mode='edge')\n        \n        # Extract and normalize xyz\n        group_xyz = xyz[neighbor_idx].copy()\n        group_xyz = group_xyz - group_xyz.mean(axis=0)\n        max_dist = np.abs(group_xyz).max()\n        if max_dist > 0:\n            group_xyz = group_xyz / max_dist\n        \n        # Extract features for labeling\n        curvature = ff['curvature'][neighbor_idx]\n        linearity = ff['linearity'][neighbor_idx]\n        \n        # Compute label using NSGA-III vulnerability\n        if self.pareto_set is not None:\n            label = compute_vulnerability_label(\n                group_xyz, self.pareto_set, self.threshold, curvature, linearity\n            )\n        else:\n            # Fallback: use original linear formula\n            density_var = ff['density_var'][neighbor_idx].mean()\n            planarity = ff['planarity'][neighbor_idx].mean()\n            score = (\n                curvature.mean() * CRITICALITY_WEIGHTS.get(\"curvature\", 0.15) +\n                density_var * CRITICALITY_WEIGHTS.get(\"density_var\", 0.25) +\n                (1 - planarity) * CRITICALITY_WEIGHTS.get(\"nonplanarity\", 0.60)\n            )\n            label = 0 if score >= 0.4 else 1\n        \n        return torch.from_numpy(group_xyz.astype(np.float32)), label\n\n\n# Create quick check datasets\nquick_train = QuickCheckDataset(\n    frame_features, PARETO_SET, VULNERABILITY_THRESHOLD,\n    n_points=N_POINTS, samples_per_epoch=2000, seed=None, augment=True\n)\nquick_test = QuickCheckDataset(\n    frame_features, PARETO_SET, VULNERABILITY_THRESHOLD,\n    n_points=N_POINTS, samples_per_epoch=500, seed=42, augment=False\n)\n\nquick_train_loader = DataLoader(quick_train, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\nquick_test_loader = DataLoader(quick_test, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n\nprint(f\"Quick train: {len(quick_train)} samples\")\nprint(f\"Quick test: {len(quick_test)} samples\")\n\n# Check class distribution\ntrain_labels = [quick_train[i][1] for i in range(100)]\nprint(f\"\\nLabel distribution (first 100): {sum(train_labels)} NON_CRITICAL, {100 - sum(train_labels)} CRITICAL\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 2. Quick training (5 epochs)\nprint(\"\\n\" + \"-\" * 60)\nprint(\"Step 1: Quick Training (5 epochs)\")\nprint(\"-\" * 60)\n\nquick_model = PointNetForVerification(\n    num_points=N_POINTS,\n    num_classes=NUM_CLASSES,\n    use_tnet=True,\n    feature_transform=True,\n    in_channels=IN_CHANNELS,\n).to(device)\n\nquick_criterion = nn.CrossEntropyLoss()\nquick_optimizer = torch.optim.Adam(quick_model.parameters(), lr=LEARNING_RATE)\n\nfor epoch in range(5):\n    quick_model.train()\n    train_loss, train_correct, train_total = 0, 0, 0\n    \n    for batch_data, batch_labels in quick_train_loader:\n        batch_data = batch_data.to(device)\n        batch_labels = batch_labels.to(device)\n        \n        quick_optimizer.zero_grad()\n        outputs = quick_model(batch_data)\n        loss = quick_criterion(outputs, batch_labels)\n        loss.backward()\n        quick_optimizer.step()\n        \n        train_loss += loss.item() * batch_data.size(0)\n        _, predicted = outputs.max(1)\n        train_correct += predicted.eq(batch_labels).sum().item()\n        train_total += batch_data.size(0)\n    \n    train_acc = 100.0 * train_correct / train_total\n    print(f\"  Epoch {epoch+1}/5: loss={train_loss/train_total:.4f}, acc={train_acc:.1f}%\")\n\n# Evaluate on quick test set\nquick_model.eval()\ntest_correct, test_total = 0, 0\nwith torch.no_grad():\n    for batch_data, batch_labels in quick_test_loader:\n        batch_data = batch_data.to(device)\n        batch_labels = batch_labels.to(device)\n        outputs = quick_model(batch_data)\n        _, predicted = outputs.max(1)\n        test_correct += predicted.eq(batch_labels).sum().item()\n        test_total += batch_data.size(0)\n\nquick_acc = 100.0 * test_correct / test_total\nprint(f\"\\n  Quick test accuracy: {quick_acc:.1f}%\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 3. Check accuracy threshold\nprint(\"\\n\" + \"-\" * 60)\nprint(\"Step 2: Accuracy Check\")\nprint(\"-\" * 60)\n\nMIN_ACCURACY = 55.0  # Minimum acceptable accuracy\n\nif quick_acc < MIN_ACCURACY:\n    print(f\"❌ FAIL: Accuracy {quick_acc:.1f}% is below threshold {MIN_ACCURACY}%\")\n    print(\"\\n   Possible issues:\")\n    print(\"   - Labels may be incorrect or too noisy\")\n    print(\"   - NSGA-III vulnerability threshold may need adjustment\")\n    print(\"   - Model may need different hyperparameters\")\n    raise ValueError(f\"Quick check failed - accuracy too low ({quick_acc:.1f}%)\")\nelse:\n    print(f\"✓ PASS: Accuracy {quick_acc:.1f}% >= {MIN_ACCURACY}%\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 4. Test α,β-CROWN verification on 3 samples\nprint(\"\\n\" + \"-\" * 60)\nprint(\"Step 3: α,β-CROWN Verification Test\")\nprint(\"-\" * 60)\n\n# Create verification model (remove dropout)\nquick_verify_model = PointNetVerify(\n    num_points=N_POINTS,\n    num_classes=NUM_CLASSES,\n    in_channels=IN_CHANNELS,\n    use_tnet=True,\n    feature_transform=True,\n)\nquick_verify_model = transfer_weights_to_verify(quick_model.cpu(), quick_verify_model)\nquick_verify_model.eval()\n\n# Get 3 test samples\nquick_test_samples = [quick_test[i][0].numpy() for i in range(3)]\nquick_test_labels = [quick_test[i][1] for i in range(3)]\n\n# Test verification\nQUICK_EPSILON = 0.005  # Test epsilon\nverification_ok = True\nverification_errors = []\n\nprint(f\"Testing with ε = {QUICK_EPSILON}\")\nprint()\n\nfor i in range(3):\n    sample = quick_test_samples[i]\n    label = quick_test_labels[i]\n    label_str = \"CRITICAL\" if label == 0 else \"NON_CRITICAL\"\n    \n    try:\n        result = verify_robustness_lirpa(quick_verify_model, sample, label, QUICK_EPSILON)\n        if result['verified']:\n            status = f\"✓ VERIFIED (margin={result['margin']:.4f})\"\n        else:\n            status = f\"✗ NOT VERIFIED (margin={result['margin']:.4f})\"\n        print(f\"  Sample {i} ({label_str}): {status}\")\n        \n    except Exception as e:\n        error_msg = str(e)\n        verification_errors.append(error_msg)\n        print(f\"  Sample {i} ({label_str}): ❌ ERROR\")\n        print(f\"    {error_msg[:80]}...\")\n        verification_ok = False\n\nif verification_errors:\n    print(f\"\\n❌ FAIL: Verification encountered {len(verification_errors)} error(s)\")\n    print(\"\\n   Possible issues:\")\n    print(\"   - Model architecture may be incompatible with auto_LiRPA\")\n    print(\"   - Batch normalization issues with batch_size=1\")\n    print(\"   - T-Net torch.bmm operation may need special handling\")\n    raise ValueError(\"Quick check failed - verification error\")\nelse:\n    print(\"\\n✓ PASS: Verification works correctly\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# 5. Quick Check Summary\nprint(\"\\n\" + \"=\" * 60)\nprint(\"✓ QUICK CHECK PASSED!\")\nprint(\"=\" * 60)\nprint(f\"  - Training: 5 epochs completed\")\nprint(f\"  - Accuracy: {quick_acc:.1f}% (threshold: {MIN_ACCURACY}%)\")\nprint(f\"  - Verification: α,β-CROWN works on 3 samples\")\nprint(f\"  - Labeling: NSGA-III vulnerability-based\" if PARETO_SET is not None else \"  - Labeling: Fallback weights\")\nprint()\nprint(\"Proceeding with full training (50 epochs)...\")\nprint(\"=\" * 60)\n\n# Clean up quick check objects to free memory\ndel quick_model, quick_verify_model, quick_train, quick_test\ndel quick_train_loader, quick_test_loader\ntorch.cuda.empty_cache() if torch.cuda.is_available() else None",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "load-model",
    "outputId": "9dd2677a-3c02-4d99-a6e5-f4e379a06840"
   },
   "outputs": [],
   "source": "## 3. PointNet Model (Original Architecture)\n\nBased on Qi et al., \"PointNet: Deep Learning on Point Sets\" (CVPR 2017)\n\nArchitecture:\n- **T-Net 3x3**: Spatial transformer for xyz coordinates\n- **T-Net 64x64**: Feature transformer after first MLP\n- **Point MLP**: 3→64→64→[feat_trans]→64→128→1024 with BatchNorm\n- **Global MaxPool**: Symmetric aggregation\n- **Classifier**: 1024→512→256→2 with BatchNorm + Dropout(0.3)\n\n**Input**: (batch, 1024, 3) - xyz coordinates only!\nThe model must learn to classify critical vs non-critical regions\npurely from the geometric structure of the point cloud."
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "verify-header"
   },
   "source": "class TNet(nn.Module):\n    \"\"\"\n    T-Net: Spatial Transformer Network for PointNet.\n    Predicts a k x k transformation matrix.\n    \n    Architecture (original):\n    - Conv1d: k → 64 → 128 → 1024\n    - MaxPool\n    - FC: 1024 → 512 → 256 → k*k\n    - All with BatchNorm\n    \"\"\"\n    def __init__(self, k=3):\n        super().__init__()\n        self.k = k\n        \n        # Shared MLP (implemented as Conv1d)\n        self.conv1 = nn.Conv1d(k, 64, 1)\n        self.conv2 = nn.Conv1d(64, 128, 1)\n        self.conv3 = nn.Conv1d(128, 1024, 1)\n        \n        self.bn1 = nn.BatchNorm1d(64)\n        self.bn2 = nn.BatchNorm1d(128)\n        self.bn3 = nn.BatchNorm1d(1024)\n        \n        # FC layers\n        self.fc1 = nn.Linear(1024, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, k * k)\n        \n        self.bn_fc1 = nn.BatchNorm1d(512)\n        self.bn_fc2 = nn.BatchNorm1d(256)\n        \n        # Initialize to identity\n        self.fc3.weight.data.zero_()\n        self.fc3.bias.data.copy_(torch.eye(k).view(-1))\n    \n    def forward(self, x):\n        \"\"\"\n        Args:\n            x: (batch, k, n_points)\n        Returns:\n            transform: (batch, k, k) transformation matrix\n        \"\"\"\n        batch_size = x.shape[0]\n        \n        x = F.relu(self.bn1(self.conv1(x)))\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = F.relu(self.bn3(self.conv3(x)))\n        \n        # Max pool over points\n        x = torch.max(x, dim=2)[0]  # (batch, 1024)\n        \n        x = F.relu(self.bn_fc1(self.fc1(x)))\n        x = F.relu(self.bn_fc2(self.fc2(x)))\n        x = self.fc3(x)\n        \n        # Reshape to k x k matrix\n        x = x.view(batch_size, self.k, self.k)\n        \n        return x\n\n\nclass PointNetForVerification(nn.Module):\n    \"\"\"\n    PointNet for Verification - IDENTICAL to original PointNet architecture.\n    \n    Based on: Qi et al., \"PointNet: Deep Learning on Point Sets\" (CVPR 2017)\n    \n    Features:\n    - Input T-Net (3x3) only transforms xyz, not extra features\n    - Feature T-Net (64x64) after conv2\n    - 5 conv layers: in_channels→64→64→64→128→1024\n    - BatchNorm on all layers\n    - Dropout(0.3) in classifier\n    \n    Input format: (batch, n_points, in_channels)\n    - in_channels=7: xyz(3) + features(4)\n    \"\"\"\n    def __init__(\n        self,\n        num_points=1024,\n        num_classes=2,\n        use_tnet=True,\n        feature_transform=True,\n        in_channels=7,\n    ):\n        super().__init__()\n        \n        self.num_points = num_points\n        self.num_classes = num_classes\n        self.use_tnet = use_tnet\n        self.feature_transform = feature_transform\n        self.in_channels = in_channels\n        self.input_dim = num_points * in_channels\n        \n        # Input T-Net (3x3) - only for xyz\n        if use_tnet:\n            self.input_tnet = TNet(k=3)\n        \n        # Feature T-Net (64x64)\n        if feature_transform:\n            self.feat_tnet = TNet(k=64)\n        \n        # Point-wise MLP (5 conv layers)\n        self.conv1 = nn.Conv1d(in_channels, 64, 1)\n        self.conv2 = nn.Conv1d(64, 64, 1)\n        self.conv3 = nn.Conv1d(64, 64, 1)\n        self.conv4 = nn.Conv1d(64, 128, 1)\n        self.conv5 = nn.Conv1d(128, 1024, 1)\n        \n        self.bn1 = nn.BatchNorm1d(64)\n        self.bn2 = nn.BatchNorm1d(64)\n        self.bn3 = nn.BatchNorm1d(64)\n        self.bn4 = nn.BatchNorm1d(128)\n        self.bn5 = nn.BatchNorm1d(1024)\n        \n        # Classifier MLP\n        self.fc1 = nn.Linear(1024, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, num_classes)\n        \n        self.bn_fc1 = nn.BatchNorm1d(512)\n        self.bn_fc2 = nn.BatchNorm1d(256)\n        self.dropout = nn.Dropout(p=0.3)\n    \n    def forward(self, x):\n        batch_size = x.shape[0]\n        \n        # Handle flattened input\n        if x.dim() == 2:\n            x = x.view(batch_size, self.num_points, self.in_channels)\n        \n        # Separate xyz and extra features\n        if self.in_channels > 3:\n            xyz = x[:, :, :3]  # (batch, n_points, 3)\n            extra_features = x[:, :, 3:]  # (batch, n_points, in_channels-3)\n        else:\n            xyz = x\n            extra_features = None\n        \n        # Input T-Net (only on xyz)\n        if self.use_tnet:\n            xyz_t = xyz.transpose(1, 2)  # (batch, 3, n_points)\n            input_trans = self.input_tnet(xyz_t)  # (batch, 3, 3)\n            xyz = torch.bmm(xyz, input_trans)  # (batch, n_points, 3)\n        \n        # Recombine\n        if extra_features is not None:\n            x = torch.cat([xyz, extra_features], dim=2)\n        else:\n            x = xyz\n        \n        # Point-wise MLP\n        x = x.transpose(1, 2)  # (batch, in_channels, n_points)\n        x = F.relu(self.bn1(self.conv1(x)))  # (batch, 64, n_points)\n        x = F.relu(self.bn2(self.conv2(x)))  # (batch, 64, n_points)\n        \n        # Feature T-Net\n        if self.feature_transform:\n            feat_trans = self.feat_tnet(x)  # (batch, 64, 64)\n            x = x.transpose(1, 2)  # (batch, n_points, 64)\n            x = torch.bmm(x, feat_trans)  # (batch, n_points, 64)\n            x = x.transpose(1, 2)  # (batch, 64, n_points)\n        \n        x = F.relu(self.bn3(self.conv3(x)))  # (batch, 64, n_points)\n        x = F.relu(self.bn4(self.conv4(x)))  # (batch, 128, n_points)\n        x = F.relu(self.bn5(self.conv5(x)))  # (batch, 1024, n_points)\n        \n        # Global max pooling\n        x = torch.max(x, dim=2)[0]  # (batch, 1024)\n        \n        # Classifier\n        x = F.relu(self.bn_fc1(self.fc1(x)))\n        x = self.dropout(x)\n        x = F.relu(self.bn_fc2(self.fc2(x)))\n        x = self.dropout(x)\n        x = self.fc3(x)\n        \n        return x\n    \n    def get_transforms(self, x):\n        \"\"\"Return input and feature transforms for regularization.\"\"\"\n        batch_size = x.shape[0]\n        \n        if x.dim() == 2:\n            x = x.view(batch_size, self.num_points, self.in_channels)\n        \n        if self.in_channels > 3:\n            xyz = x[:, :, :3]\n        else:\n            xyz = x\n        \n        input_trans = None\n        feat_trans = None\n        \n        if self.use_tnet:\n            xyz_t = xyz.transpose(1, 2)\n            input_trans = self.input_tnet(xyz_t)\n            xyz = torch.bmm(xyz, input_trans)\n        \n        if self.in_channels > 3:\n            x = torch.cat([xyz, x[:, :, 3:]], dim=2)\n        else:\n            x = xyz\n        \n        x = x.transpose(1, 2)\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = F.relu(self.bn2(self.conv2(x)))\n        \n        if self.feature_transform:\n            feat_trans = self.feat_tnet(x)\n        \n        return input_trans, feat_trans\n\n\n# Create model\nmodel = PointNetForVerification(\n    num_points=N_POINTS,\n    num_classes=NUM_CLASSES,\n    use_tnet=True,\n    feature_transform=True,\n    in_channels=IN_CHANNELS,\n).to(device)\n\nn_params = sum(p.numel() for p in model.parameters())\nprint(f\"PointNet parameters: {n_params:,}\")\nprint(f\"Expected: ~3.5M parameters\")"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "verify-funcs",
    "outputId": "1db38049-0bd6-4015-bd5d-8fcca9a6a669"
   },
   "outputs": [],
   "source": "## 4. Training"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "prop1-header"
   },
   "source": "def feature_transform_regularizer(trans):\n    \"\"\"Regularization loss for feature transform to be close to orthogonal.\"\"\"\n    d = trans.size()[1]\n    I = torch.eye(d, device=trans.device).unsqueeze(0)\n    loss = torch.mean(torch.norm(I - torch.bmm(trans, trans.transpose(2, 1)), dim=(1, 2)))\n    return loss\n\n\ndef train_epoch(model, loader, criterion, optimizer):\n    \"\"\"Train for one epoch.\"\"\"\n    model.train()\n    total_loss = 0\n    correct = 0\n    total = 0\n    \n    for batch_data, batch_labels in loader:\n        batch_data = batch_data.to(device)\n        batch_labels = batch_labels.to(device)\n        \n        optimizer.zero_grad()\n        \n        # Forward pass\n        outputs = model(batch_data)\n        loss = criterion(outputs, batch_labels)\n        \n        # Add feature transform regularization\n        if model.feature_transform:\n            _, feat_trans = model.get_transforms(batch_data)\n            if feat_trans is not None:\n                loss = loss + 0.001 * feature_transform_regularizer(feat_trans)\n        \n        # Backward pass\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item() * batch_data.size(0)\n        _, predicted = outputs.max(1)\n        correct += predicted.eq(batch_labels).sum().item()\n        total += batch_data.size(0)\n    \n    return total_loss / total, 100.0 * correct / total\n\n\ndef evaluate(model, loader):\n    \"\"\"Evaluate model on dataset.\"\"\"\n    model.eval()\n    correct = 0\n    total = 0\n    \n    with torch.no_grad():\n        for batch_data, batch_labels in loader:\n            batch_data = batch_data.to(device)\n            batch_labels = batch_labels.to(device)\n            \n            outputs = model(batch_data)\n            _, predicted = outputs.max(1)\n            correct += predicted.eq(batch_labels).sum().item()\n            total += batch_data.size(0)\n    \n    return 100.0 * correct / total"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "prop1-verify",
    "outputId": "89626b82-8db3-49df-b165-a3bf4702be4e"
   },
   "outputs": [],
   "source": "# Training loop\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n\nbest_acc = 0\nhistory = {'train_loss': [], 'train_acc': [], 'test_acc': []}\n\nprint(\"=\"*60)\nprint(\"Training PointNet\")\nprint(\"=\"*60)\n\nfor epoch in range(EPOCHS):\n    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)\n    test_acc = evaluate(model, test_loader)\n    scheduler.step()\n    \n    history['train_loss'].append(train_loss)\n    history['train_acc'].append(train_acc)\n    history['test_acc'].append(test_acc)\n    \n    if test_acc > best_acc:\n        best_acc = test_acc\n        # Save best model\n        torch.save({\n            'model_state_dict': model.state_dict(),\n            'n_points': N_POINTS,\n            'num_classes': NUM_CLASSES,\n            'in_channels': IN_CHANNELS,\n            'use_tnet': True,\n            'feature_transform': True,\n            'test_accuracy': best_acc,\n        }, 'pointnet_best.pth')\n    \n    if (epoch + 1) % 5 == 0 or epoch == 0:\n        print(f\"Epoch {epoch+1:3d}/{EPOCHS} | Loss: {train_loss:.4f} | \"\n              f\"Train Acc: {train_acc:.1f}% | Test Acc: {test_acc:.1f}% | Best: {best_acc:.1f}%\")\n\nprint(f\"\\nTraining complete! Best accuracy: {best_acc:.2f}%\")"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "prop2-header"
   },
   "source": "# Plot training curves\nimport matplotlib.pyplot as plt\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 4))\n\n# Loss\naxes[0].plot(history['train_loss'], 'b-', label='Train Loss')\naxes[0].set_xlabel('Epoch')\naxes[0].set_ylabel('Loss')\naxes[0].set_title('Training Loss')\naxes[0].legend()\naxes[0].grid(True, alpha=0.3)\n\n# Accuracy\naxes[1].plot(history['train_acc'], 'b-', label='Train Acc')\naxes[1].plot(history['test_acc'], 'r-', label='Test Acc')\naxes[1].axhline(y=best_acc, color='g', linestyle='--', label=f'Best: {best_acc:.1f}%')\naxes[1].set_xlabel('Epoch')\naxes[1].set_ylabel('Accuracy (%)')\naxes[1].set_title('Training & Test Accuracy')\naxes[1].legend()\naxes[1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('training_curves.png', dpi=150)\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "prop2-verify",
    "outputId": "f72a6c41-c915-452c-bf3d-e4050d9ed2cd"
   },
   "outputs": [],
   "source": "# Load best model for verification\ncheckpoint = torch.load('pointnet_best.pth', map_location=device)\nmodel.load_state_dict(checkpoint['model_state_dict'])\nmodel.eval()\nprint(f\"Loaded best model with test accuracy: {checkpoint['test_accuracy']:.2f}%\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "results-header"
   },
   "source": "<cell_type>markdown</cell_type>## 5. Verification with auto_LiRPA\n\nUsing auto_LiRPA API directly (native PyTorch support for Conv1d, MaxPool, etc.)\n\n**IMPORTANT**: The original PointNet with T-Net uses `torch.bmm` (batch matrix multiplication) \nwhich is not supported by auto_LiRPA's bound propagation. We create a simplified model \nWITHOUT T-Net specifically for verification."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "results-summary",
    "outputId": "b4f82119-ba9d-4b70-f51a-581ba9d3f9ee"
   },
   "outputs": [],
   "source": "# Create a verification-friendly model WITH T-Net but WITHOUT Dropout\n# \n# auto_LiRPA limitations:\n# 1. Dropout + BatchNorm1d with batch_size=1 → NOT supported\n# 2. BoundReduceMax with perturbed indices → requires fixed_reducemax_index=True\n# 3. torch.bmm → Should work (maps to BoundMatMul)\n#\n# We keep T-Net but remove Dropout for verification compatibility.\n\nclass PointNetVerify(nn.Module):\n    \"\"\"\n    PointNet for α,β-CROWN Verification - WITH T-Net, WITHOUT Dropout.\n    \n    This is the SAME architecture as PointNetForVerification but without Dropout,\n    which is not supported by auto_LiRPA with BatchNorm1d and batch_size=1.\n    \n    Architecture (original PointNet):\n    - Input T-Net (3x3) for spatial alignment\n    - Feature T-Net (64x64) after conv2\n    - Point-wise MLP: 7→64→64→64→128→1024 with BatchNorm\n    - Global MaxPool\n    - Classifier: 1024→512→256→2 with BatchNorm (NO Dropout)\n    \"\"\"\n    def __init__(self, num_points=1024, num_classes=2, in_channels=7,\n                 use_tnet=True, feature_transform=True):\n        super().__init__()\n        self.num_points = num_points\n        self.num_classes = num_classes\n        self.in_channels = in_channels\n        self.use_tnet = use_tnet\n        self.feature_transform = feature_transform\n        self.input_dim = num_points * in_channels\n        \n        # Input T-Net (3x3) - only for xyz\n        if use_tnet:\n            self.input_tnet = TNet(k=3)\n        \n        # Feature T-Net (64x64)\n        if feature_transform:\n            self.feat_tnet = TNet(k=64)\n        \n        # Point-wise MLP (same as original)\n        self.conv1 = nn.Conv1d(in_channels, 64, 1)\n        self.conv2 = nn.Conv1d(64, 64, 1)\n        self.conv3 = nn.Conv1d(64, 64, 1)\n        self.conv4 = nn.Conv1d(64, 128, 1)\n        self.conv5 = nn.Conv1d(128, 1024, 1)\n        \n        self.bn1 = nn.BatchNorm1d(64)\n        self.bn2 = nn.BatchNorm1d(64)\n        self.bn3 = nn.BatchNorm1d(64)\n        self.bn4 = nn.BatchNorm1d(128)\n        self.bn5 = nn.BatchNorm1d(1024)\n        \n        # Classifier MLP (NO Dropout for verification compatibility)\n        self.fc1 = nn.Linear(1024, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, num_classes)\n        \n        self.bn_fc1 = nn.BatchNorm1d(512)\n        self.bn_fc2 = nn.BatchNorm1d(256)\n        # NO self.dropout - removed for auto_LiRPA compatibility\n    \n    def forward(self, x):\n        batch_size = x.shape[0]\n        \n        # Handle flattened input\n        if x.dim() == 2:\n            x = x.view(batch_size, self.num_points, self.in_channels)\n        \n        # Separate xyz and extra features\n        if self.in_channels > 3:\n            xyz = x[:, :, :3]  # (batch, n_points, 3)\n            extra_features = x[:, :, 3:]  # (batch, n_points, in_channels-3)\n        else:\n            xyz = x\n            extra_features = None\n        \n        # Input T-Net (only on xyz)\n        if self.use_tnet:\n            xyz_t = xyz.transpose(1, 2)  # (batch, 3, n_points)\n            input_trans = self.input_tnet(xyz_t)  # (batch, 3, 3)\n            xyz = torch.bmm(xyz, input_trans)  # (batch, n_points, 3)\n        \n        # Recombine\n        if extra_features is not None:\n            x = torch.cat([xyz, extra_features], dim=2)\n        else:\n            x = xyz\n        \n        # Point-wise MLP\n        x = x.transpose(1, 2)  # (batch, in_channels, n_points)\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = F.relu(self.bn2(self.conv2(x)))\n        \n        # Feature T-Net\n        if self.feature_transform:\n            feat_trans = self.feat_tnet(x)  # (batch, 64, 64)\n            x = x.transpose(1, 2)  # (batch, n_points, 64)\n            x = torch.bmm(x, feat_trans)  # (batch, n_points, 64)\n            x = x.transpose(1, 2)  # (batch, 64, n_points)\n        \n        x = F.relu(self.bn3(self.conv3(x)))\n        x = F.relu(self.bn4(self.conv4(x)))\n        x = F.relu(self.bn5(self.conv5(x)))\n        \n        # Global max pooling\n        x = torch.max(x, dim=2)[0]  # (batch, 1024)\n        \n        # Classifier (NO Dropout)\n        x = F.relu(self.bn_fc1(self.fc1(x)))\n        x = F.relu(self.bn_fc2(self.fc2(x)))\n        x = self.fc3(x)\n        \n        return x\n\n\ndef transfer_weights_to_verify(full_model, verify_model):\n    \"\"\"\n    Transfer weights from full PointNet (with Dropout) to verification model (no Dropout).\n    All layers are identical except Dropout is removed.\n    \"\"\"\n    # Copy T-Net weights if present\n    if hasattr(full_model, 'input_tnet') and hasattr(verify_model, 'input_tnet'):\n        verify_model.input_tnet.load_state_dict(full_model.input_tnet.state_dict())\n    \n    if hasattr(full_model, 'feat_tnet') and hasattr(verify_model, 'feat_tnet'):\n        verify_model.feat_tnet.load_state_dict(full_model.feat_tnet.state_dict())\n    \n    # Copy conv and bn layers\n    for i in range(1, 6):\n        getattr(verify_model, f'conv{i}').load_state_dict(\n            getattr(full_model, f'conv{i}').state_dict()\n        )\n        getattr(verify_model, f'bn{i}').load_state_dict(\n            getattr(full_model, f'bn{i}').state_dict()\n        )\n    \n    # Copy fc layers\n    for i in range(1, 4):\n        getattr(verify_model, f'fc{i}').load_state_dict(\n            getattr(full_model, f'fc{i}').state_dict()\n        )\n    \n    # Copy fc batchnorm\n    verify_model.bn_fc1.load_state_dict(full_model.bn_fc1.state_dict())\n    verify_model.bn_fc2.load_state_dict(full_model.bn_fc2.state_dict())\n    \n    return verify_model\n\n\n# Create verification model WITH T-Net\nverify_model = PointNetVerify(\n    num_points=N_POINTS,\n    num_classes=NUM_CLASSES,\n    in_channels=IN_CHANNELS,\n    use_tnet=True,           # Keep T-Net!\n    feature_transform=True   # Keep feature transform!\n)\n\n# Transfer weights from trained model\nverify_model = transfer_weights_to_verify(model, verify_model)\nverify_model.eval()\n\n# Compare accuracy\nverify_model_gpu = verify_model.to(device)\nverify_acc = evaluate(verify_model_gpu, test_loader)\nprint(f\"Original model (with Dropout) accuracy: {best_acc:.2f}%\")\nprint(f\"Verification model (no Dropout) accuracy: {verify_acc:.2f}%\")\nprint(f\"Accuracy difference: {abs(best_acc - verify_acc):.2f}%\")\nprint(\"\\nNote: T-Net is KEPT in verification model!\")\nprint(\"      Only Dropout is removed (not needed in eval mode anyway).\")"
  },
  {
   "cell_type": "code",
   "source": "# Verification functions using α,β-CROWN\n# Key settings for PointNet verification:\n# 1. fixed_reducemax_index=True: Assume max indices don't change (valid for small ε)\n# 2. method='CROWN' or 'alpha-CROWN': Use CROWN bounds, not just IBP\n\ndef verify_robustness_lirpa(model, sample, label, epsilon, method='CROWN'):\n    \"\"\"\n    Verify local robustness using α,β-CROWN.\n    \n    Property: ∀x' with ||x' - x₀||∞ ≤ ε : f(x') = f(x₀)\n    \n    Args:\n        model: PyTorch model (PointNetVerify)\n        sample: Input sample (n_points, in_channels)\n        label: Ground truth label (0=CRITICAL, 1=NON_CRITICAL)\n        epsilon: L∞ perturbation budget\n        method: Verification method ('CROWN', 'alpha-CROWN', 'CROWN-Optimized')\n    \n    Returns:\n        dict with 'verified', 'margin', 'lb', 'ub'\n    \"\"\"\n    model.eval()\n    model_cpu = model.cpu()\n    \n    # Prepare input\n    sample_tensor = torch.FloatTensor(sample).unsqueeze(0)  # (1, n_points, in_channels)\n    \n    # Create bounded model with CRITICAL options for max pooling\n    # fixed_reducemax_index=True assumes the argmax indices don't change under perturbation\n    # This is a sound assumption for small epsilon values\n    bounded_model = BoundedModule(\n        model_cpu, \n        sample_tensor, \n        device='cpu',\n        bound_opts={\n            'fixed_reducemax_index': True,  # Required for CROWN with max pooling\n        }\n    )\n    \n    # Define perturbation\n    ptb = PerturbationLpNorm(norm=float('inf'), eps=epsilon)\n    bounded_input = BoundedTensor(sample_tensor, ptb)\n    \n    # Compute bounds using CROWN (α,β-CROWN)\n    lb, ub = bounded_model.compute_bounds(x=(bounded_input,), method=method)\n    \n    # Check if correct class is always highest\n    # Margin = lower_bound(correct_class) - upper_bound(other_class)\n    if label == 0:\n        margin = lb[0, 0] - ub[0, 1]\n    else:\n        margin = lb[0, 1] - ub[0, 0]\n    \n    verified = margin.item() > 0\n    \n    return {\n        'verified': verified,\n        'margin': margin.item(),\n        'lb': lb.detach().numpy(),\n        'ub': ub.detach().numpy(),\n        'method': method\n    }\n\n\ndef verify_safety_lirpa(model, sample, epsilon, method='CROWN'):\n    \"\"\"\n    Verify safety property using α,β-CROWN.\n    \n    Property: For CRITICAL samples, no perturbation causes NON_CRITICAL classification.\n    \n    Args:\n        model: PyTorch model (PointNetVerify)\n        sample: Input sample (n_points, in_channels)\n        epsilon: L∞ perturbation budget\n        method: Verification method ('CROWN', 'alpha-CROWN', 'CROWN-Optimized')\n    \n    Returns:\n        dict with 'verified', 'margin', status info\n    \"\"\"\n    model.eval()\n    model_cpu = model.cpu()\n    \n    # Prepare input\n    sample_tensor = torch.FloatTensor(sample).unsqueeze(0)\n    \n    # First check prediction\n    with torch.no_grad():\n        output = model_cpu(sample_tensor)\n        pred = output.argmax(dim=1).item()\n        confidence = torch.softmax(output, dim=1)[0]\n    \n    # Only verify if predicted as CRITICAL (class 0)\n    if pred != 0:\n        return {\n            'verified': False,\n            'status': 'skipped_wrong_prediction',\n            'original_prediction': pred,\n            'confidence': confidence.numpy()\n        }\n    \n    # Create bounded model with options for max pooling\n    bounded_model = BoundedModule(\n        model_cpu, \n        sample_tensor, \n        device='cpu',\n        bound_opts={\n            'fixed_reducemax_index': True,  # Required for CROWN with max pooling\n        }\n    )\n    \n    # Define perturbation\n    ptb = PerturbationLpNorm(norm=float('inf'), eps=epsilon)\n    bounded_input = BoundedTensor(sample_tensor, ptb)\n    \n    # Compute bounds using CROWN\n    lb, ub = bounded_model.compute_bounds(x=(bounded_input,), method=method)\n    \n    # Safety: CRITICAL (class 0) should always have higher score than NON_CRITICAL (class 1)\n    # If lb[CRITICAL] > ub[NON_CRITICAL], the sample is safe\n    margin = lb[0, 0] - ub[0, 1]\n    verified = margin.item() > 0\n    \n    return {\n        'verified': verified,\n        'margin': margin.item(),\n        'lb': lb.detach().numpy(),\n        'ub': ub.detach().numpy(),\n        'method': method,\n        'original_prediction': pred,\n        'confidence': confidence.numpy()\n    }\n\n\nprint(\"Verification functions defined with α,β-CROWN support!\")\nprint(\"\\nKey settings for PointNet verification:\")\nprint(\"  - fixed_reducemax_index=True: Assumes max indices stable under perturbation\")\nprint(\"  - method='CROWN': Uses CROWN bound propagation (not just IBP)\")\nprint(\"\\nAvailable methods:\")\nprint(\"  - 'CROWN': Standard CROWN bounds (fast)\")\nprint(\"  - 'alpha-CROWN': Optimized CROWN with learnable α (tighter, slower)\")\nprint(\"  - 'CROWN-Optimized': Same as alpha-CROWN\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "save-results",
    "outputId": "1a67f20a-a2e5-4bd2-aff2-b59a53e84359"
   },
   "outputs": [],
   "source": "# Generate fixed verification samples from test dataset\n# We need numpy arrays for verification, so we extract them once\n\nprint(\"Generating fixed verification samples...\")\n\n# Create a fixed set of samples for verification (with seed for reproducibility)\n# Uses the same NSGA-III vulnerability labeling as training\nverify_dataset = LiDAROnTheFlyDataset(\n    frame_features,\n    pareto_set=PARETO_SET,\n    threshold=VULNERABILITY_THRESHOLD,\n    fallback_weights=CRITICALITY_WEIGHTS,\n    n_points=N_POINTS,\n    samples_per_epoch=N_VERIFY_SAMPLES * 2,  # Extra samples to ensure enough of each class\n    seed=12345,  # Fixed seed for verification\n    augment=False\n)\n\n# Extract samples and labels as numpy arrays\ntest_groups = []\ntest_labels = []\nfor i in range(len(verify_dataset)):\n    sample, label = verify_dataset[i]\n    test_groups.append(sample.numpy())\n    test_labels.append(label)\n\ntest_groups = np.array(test_groups)\ntest_labels = np.array(test_labels)\n\nprint(f\"Verification samples: {len(test_groups)}\")\nprint(f\"  CRITICAL (0): {sum(test_labels == 0)}\")\nprint(f\"  NON_CRITICAL (1): {sum(test_labels == 1)}\")\nprint(f\"\\nLabeling: {'NSGA-III vulnerability-based' if PARETO_SET is not None else 'Fallback weights'}\")"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "viz-header"
   },
   "source": "# Property 1: Local Robustness Verification with α,β-CROWN\n# Using PointNetVerify (no T-Net, no Dropout) with CROWN method\n\nprint(\"=\"*70)\nprint(\"PROPERTY 1: LOCAL ROBUSTNESS (L∞) with α,β-CROWN\")\nprint(\"Verifying: ∀x' with ||x' - x₀||∞ ≤ ε : f(x') = f(x₀)\")\nprint(\"Model: PointNetVerify (no T-Net, no Dropout)\")\nprint(\"Method: CROWN (backward bound propagation)\")\nprint(\"=\"*70)\n\n# Verification method to use\nVERIFY_METHOD = 'CROWN'  # Options: 'CROWN', 'alpha-CROWN', 'CROWN-Optimized'\n\nrobustness_results = {}\nerrors_log = []  # Track full error messages\n\nfor eps in EPSILONS:\n    print(f\"\\nε = {eps}\")\n    print(\"-\"*40)\n    \n    verified_count = 0\n    total = 0\n    \n    for i in range(min(N_VERIFY_SAMPLES, len(test_groups))):\n        sample = test_groups[i]\n        label = int(test_labels[i])\n        label_str = \"CRITICAL\" if label == 0 else \"NON_CRITICAL\"\n        \n        try:\n            # Use verify_model (PointNetVerify) with CROWN method\n            result = verify_robustness_lirpa(verify_model, sample, label, eps, method=VERIFY_METHOD)\n            if result['verified']:\n                verified_count += 1\n                status = f\"✓ VERIFIED (margin={result['margin']:.4f})\"\n            else:\n                status = f\"✗ NOT VERIFIED (margin={result['margin']:.4f})\"\n            total += 1\n        except Exception as e:\n            error_msg = str(e)\n            errors_log.append(f\"Sample {i}, eps={eps}: {error_msg}\")\n            status = f\"⚠ ERROR: {error_msg[:60]}...\"\n        \n        print(f\"  Sample {i:3d} ({label_str:12}): {status}\")\n    \n    robustness_results[str(eps)] = {\n        'epsilon': eps,\n        'verified': verified_count,\n        'total': total,\n        'verified_pct': 100 * verified_count / total if total > 0 else 0,\n        'method': VERIFY_METHOD\n    }\n    \n    print(f\"\\n  Summary: {verified_count}/{total} verified ({robustness_results[str(eps)]['verified_pct']:.1f}%)\")\n\n# Print any errors encountered\nif errors_log:\n    print(\"\\n\" + \"=\"*70)\n    print(\"ERRORS ENCOUNTERED:\")\n    print(\"=\"*70)\n    for err in errors_log[:5]:  # Show first 5 errors\n        print(f\"  {err}\")\n    if len(errors_log) > 5:\n        print(f\"  ... and {len(errors_log) - 5} more errors\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Property 2: Safety Verification with α,β-CROWN\n# Using PointNetVerify (no T-Net, no Dropout) with CROWN method\n\nprint(\"=\"*70)\nprint(\"PROPERTY 2: SAFETY PROPERTY with α,β-CROWN\")\nprint(\"Verifying: For CRITICAL samples, never misclassified as NON_CRITICAL\")\nprint(\"Model: PointNetVerify (no T-Net, no Dropout)\")\nprint(\"Method: CROWN (backward bound propagation)\")\nprint(\"=\"*70)\n\n# Get CRITICAL samples (label=0)\ncritical_indices = np.where(test_labels == 0)[0]\nn_critical = min(N_VERIFY_SAMPLES, len(critical_indices))\n\nsafety_results = {}\nsafety_errors_log = []\n\nfor eps in EPSILONS:\n    print(f\"\\nε = {eps}\")\n    print(\"-\"*40)\n    \n    verified_count = 0\n    skipped_count = 0\n    total = 0\n    \n    for i, idx in enumerate(critical_indices[:n_critical]):\n        sample = test_groups[idx]\n        \n        try:\n            # Use verify_model (PointNetVerify) with CROWN method\n            result = verify_safety_lirpa(verify_model, sample, eps, method=VERIFY_METHOD)\n            \n            if result.get('status') == 'skipped_wrong_prediction':\n                skipped_count += 1\n                status = f\"⊘ SKIPPED (model predicts NON_CRITICAL)\"\n            elif result['verified']:\n                verified_count += 1\n                status = f\"✓ SAFE (margin={result['margin']:.4f})\"\n                total += 1\n            else:\n                status = f\"✗ UNSAFE (margin={result['margin']:.4f})\"\n                total += 1\n        except Exception as e:\n            error_msg = str(e)\n            safety_errors_log.append(f\"Sample {idx}, eps={eps}: {error_msg}\")\n            status = f\"⚠ ERROR: {error_msg[:60]}...\"\n        \n        print(f\"  Sample {idx:3d} (CRITICAL): {status}\")\n    \n    safety_results[str(eps)] = {\n        'epsilon': eps,\n        'verified': verified_count,\n        'total': total,\n        'skipped': skipped_count,\n        'verified_pct': 100 * verified_count / total if total > 0 else 0,\n        'method': VERIFY_METHOD\n    }\n    \n    print(f\"\\n  Summary: {verified_count}/{total} safe ({safety_results[str(eps)]['verified_pct']:.1f}%), {skipped_count} skipped\")\n\n# Print any errors encountered\nif safety_errors_log:\n    print(\"\\n\" + \"=\"*70)\n    print(\"ERRORS ENCOUNTERED:\")\n    print(\"=\"*70)\n    for err in safety_errors_log[:5]:\n        print(f\"  {err}\")\n    if len(safety_errors_log) > 5:\n        print(f\"  ... and {len(safety_errors_log) - 5} more errors\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "viz-plot",
    "outputId": "742083d8-4fd0-4606-f49d-a26ed054d4ba"
   },
   "outputs": [],
   "source": "## 6. Results Summary"
  },
  {
   "cell_type": "code",
   "source": "# Results Summary\nprint(\"\\n\" + \"=\"*70)\nprint(\"FINAL RESULTS SUMMARY\")\nprint(\"=\"*70)\n\n# Property 1 Table\nprint(\"\\n### PROPERTY 1: LOCAL ROBUSTNESS ###\")\nprint(f\"{'Epsilon':>10} | {'Verified':>10} | {'Total':>10} | {'Verified %':>12}\")\nprint(\"-\"*50)\nfor eps_str, r in robustness_results.items():\n    print(f\"{float(eps_str):>10.4f} | {r['verified']:>10} | {r['total']:>10} | {r['verified_pct']:>10.1f}%\")\n\n# Property 2 Table\nprint(f\"\\n### PROPERTY 2: SAFETY (CRITICAL -> never NON_CRITICAL) ###\")\nprint(f\"{'Epsilon':>10} | {'Safe':>10} | {'Total':>10} | {'Safe %':>12} | {'Skipped':>10}\")\nprint(\"-\"*65)\nfor eps_str, r in safety_results.items():\n    print(f\"{float(eps_str):>10.4f} | {r['verified']:>10} | {r['total']:>10} | {r['verified_pct']:>10.1f}% | {r['skipped']:>10}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Visualization\nimport matplotlib.pyplot as plt\n\neps_values = [float(e) for e in robustness_results.keys()]\nrobustness_pct = [r['verified_pct'] for r in robustness_results.values()]\nsafety_pct = [r['verified_pct'] for r in safety_results.values()]\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Plot 1: Robustness\nax1 = axes[0]\nax1.plot(eps_values, robustness_pct, 'b-o', linewidth=2, markersize=8)\nax1.axhline(y=50, color='r', linestyle='--', label='50% threshold')\nax1.set_xlabel('Perturbation (ε)', fontsize=12)\nax1.set_ylabel('Verified (%)', fontsize=12)\nax1.set_title('Property 1: Local Robustness', fontsize=14)\nax1.legend()\nax1.grid(True, alpha=0.3)\nax1.set_ylim([0, 105])\n\n# Plot 2: Safety\nax2 = axes[1]\ncolors = ['green' if p == 100 else ('orange' if p > 50 else 'red') for p in safety_pct]\nax2.bar(range(len(eps_values)), safety_pct, color=colors, alpha=0.7)\nax2.set_xticks(range(len(eps_values)))\nax2.set_xticklabels([f'{e:.3f}' for e in eps_values])\nax2.axhline(y=100, color='green', linestyle='-', linewidth=2, label='Safety verified')\nax2.set_xlabel('Perturbation (ε)', fontsize=12)\nax2.set_ylabel('Safe Samples (%)', fontsize=12)\nax2.set_title('Property 2: Safety (CRITICAL → never NON_CRITICAL)', fontsize=14)\nax2.legend()\nax2.grid(True, alpha=0.3, axis='y')\nax2.set_ylim([0, 105])\n\nplt.tight_layout()\nplt.savefig('verification_results.png', dpi=150, bbox_inches='tight')\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Save results locally\nfinal_results = {\n    \"timestamp\": datetime.now().isoformat(),\n    \"model_trained\": {\n        \"type\": \"PointNetForVerification\",\n        \"n_points\": N_POINTS,\n        \"in_channels\": IN_CHANNELS,\n        \"num_classes\": NUM_CLASSES,\n        \"use_tnet\": True,\n        \"feature_transform\": True,\n        \"parameters\": n_params,\n        \"test_accuracy\": best_acc,\n    },\n    \"model_verified\": {\n        \"type\": \"PointNetVerify (with T-Net, no Dropout)\",\n        \"use_tnet\": True,\n        \"feature_transform\": True,\n        \"note\": \"Dropout removed for auto_LiRPA compatibility (Dropout+BatchNorm1d with batch_size=1 not supported)\",\n        \"test_accuracy\": verify_acc,\n    },\n    \"verification_method\": f\"α,β-CROWN ({VERIFY_METHOD})\",\n    \"verification_settings\": {\n        \"method\": VERIFY_METHOD,\n        \"fixed_reducemax_index\": True,\n        \"note\": \"Assumes max indices stable under small perturbations\"\n    },\n    \"n_verify_samples\": N_VERIFY_SAMPLES,\n    \"property1_robustness\": robustness_results,\n    \"property2_safety\": safety_results,\n}\n\nwith open('verification_results.json', 'w') as f:\n    json.dump(final_results, f, indent=2)\n\nprint(\"Results saved locally:\")\nprint(\"  - pointnet_best.pth (model checkpoint)\")\nprint(\"  - verification_results.json\")\nprint(\"  - verification_results.png\")\nprint(\"  - training_curves.png\")\nprint(f\"\\nVerification performed using α,β-CROWN with method='{VERIFY_METHOD}'\")\nprint(f\"  Trained model accuracy: {best_acc:.2f}%\")\nprint(f\"  Verified model accuracy: {verify_acc:.2f}%\")\nprint(f\"\\nVerification model keeps T-Net and feature transform!\")\nprint(\"Only Dropout was removed for compatibility.\")\nprint(\"\\nRun the next cell to download all files to your computer.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Download all files to your computer\nfrom google.colab import files\n\nprint(\"Downloading files...\")\nfiles.download('pointnet_best.pth')\nfiles.download('verification_results.json')\nfiles.download('verification_results.png')\nfiles.download('training_curves.png')\nprint(\"Done! Check your Downloads folder.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}