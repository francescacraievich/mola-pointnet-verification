{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PointNet Formal Verification with \u03b1,\u03b2-CROWN\n",
        "\n",
        "## Safe and Verified AI - Formal Verification Project\n",
        "\n",
        "This notebook verifies two key properties of a PointNet classifier for LiDAR point clouds:\n",
        "\n",
        "### Property 1: Local Robustness (L\u221e)\n",
        "For every correctly classified point x\u2080:\n",
        "```\n",
        "\u2200x' with ||x' - x\u2080||\u221e \u2264 \u03b5 : f(x') = f(x\u2080)\n",
        "```\n",
        "\"Classification remains invariant under perturbation\"\n",
        "\n",
        "### Property 2: Safety Property\n",
        "For every point x\u2080 classified as OBSTACLE (label=1):\n",
        "```\n",
        "\u2200x' with ||x' - x\u2080||\u221e \u2264 \u03b5 : f(x') \u2260 GROUND\n",
        "```\n",
        "\"An obstacle is NEVER misclassified as drivable ground\"\n",
        "\n",
        "### Comparison with NSGA-III SLAM Attack\n",
        "| Perturbation | SLAM Error | Status |\n",
        "|--------------|------------|--------|\n",
        "| 0 cm | 23 cm | Baseline |\n",
        "| 1.5 cm | 32 cm | Degradation starts |\n",
        "| 4.6 cm | 85 cm | SLAM fails |\n",
        "| 20 cm | - | Complete failure |"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Setup and Installation"
      ],
      "metadata": {
        "id": "setup-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check GPU\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "check-gpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install torch numpy onnx onnxruntime pyyaml packaging appdirs gurobipy sortedcontainers -q\n",
        "!git clone https://github.com/Verified-Intelligence/alpha-beta-CROWN.git 2>/dev/null || true\n",
        "!cd /content/alpha-beta-CROWN && git submodule update --init --recursive"
      ],
      "metadata": {
        "id": "install-deps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup paths and imports\n",
        "import sys\n",
        "sys.path.insert(0, '/content/alpha-beta-CROWN/auto_LiRPA')\n",
        "sys.path.insert(0, '/content/alpha-beta-CROWN/complete_verifier')\n",
        "\n",
        "# Mock onnxoptimizer to avoid compilation\n",
        "from types import ModuleType\n",
        "mock = ModuleType('onnxoptimizer')\n",
        "mock.optimize = lambda model, passes=None: model\n",
        "sys.modules['onnxoptimizer'] = mock\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
      ],
      "metadata": {
        "id": "setup-paths"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import alpha-beta-CROWN\n",
        "from api import ABCrownSolver, ConfigBuilder, VerificationSpec, input_vars, output_vars\n",
        "print(\"\u03b1,\u03b2-CROWN imported successfully!\")"
      ],
      "metadata": {
        "id": "import-abcrown"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Model Definitions"
      ],
      "metadata": {
        "id": "model-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PointNetForVerification(nn.Module):\n",
        "    \"\"\"\n",
        "    PointNet Base (~100k parameters)\n",
        "    Based on: Qi et al., \"PointNet: Deep Learning on Point Sets\" (CVPR 2017)\n",
        "    \"\"\"\n",
        "    def __init__(self, num_points=64, num_classes=2, use_tnet=True, pooling=\"max\"):\n",
        "        super().__init__()\n",
        "        self.num_points = num_points\n",
        "        self.num_classes = num_classes\n",
        "        self.use_tnet = use_tnet\n",
        "        self.pooling = pooling\n",
        "\n",
        "        if use_tnet:\n",
        "            self.tnet_conv1 = nn.Conv1d(3, 64, 1)\n",
        "            self.tnet_conv2 = nn.Conv1d(64, 128, 1)\n",
        "            self.tnet_conv3 = nn.Conv1d(128, 256, 1)\n",
        "            self.tnet_fc1 = nn.Linear(256, 128)\n",
        "            self.tnet_fc2 = nn.Linear(128, 64)\n",
        "            self.tnet_fc3 = nn.Linear(64, 9)\n",
        "            self.tnet_fc3.weight.data.zero_()\n",
        "            self.tnet_fc3.bias.data.copy_(torch.eye(3).view(-1))\n",
        "\n",
        "        self.conv1 = nn.Conv1d(3, 64, 1)\n",
        "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
        "        self.conv3 = nn.Conv1d(128, 256, 1)\n",
        "        self.fc1 = nn.Linear(256, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        if x.dim() == 2:\n",
        "            x = x.view(batch_size, self.num_points, 3)\n",
        "\n",
        "        if self.use_tnet:\n",
        "            x_t = x.transpose(1, 2)\n",
        "            t = F.relu(self.tnet_conv1(x_t))\n",
        "            t = F.relu(self.tnet_conv2(t))\n",
        "            t = F.relu(self.tnet_conv3(t))\n",
        "            t = torch.max(t, dim=2)[0] if self.pooling == \"max\" else torch.mean(t, dim=2)\n",
        "            t = F.relu(self.tnet_fc1(t))\n",
        "            t = F.relu(self.tnet_fc2(t))\n",
        "            t = self.tnet_fc3(t).view(batch_size, 3, 3)\n",
        "            x = torch.bmm(x, t)\n",
        "\n",
        "        x = x.transpose(1, 2)\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = torch.max(x, dim=2)[0] if self.pooling == \"max\" else torch.mean(x, dim=2)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return self.fc3(x)\n",
        "\n",
        "\n",
        "class PointNetLarge(nn.Module):\n",
        "    \"\"\"\n",
        "    PointNet Large (~1.5M parameters)\n",
        "    Deeper architecture for more robust verification testing.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_points=64, num_classes=2, use_tnet=True, pooling=\"max\"):\n",
        "        super().__init__()\n",
        "        self.num_points = num_points\n",
        "        self.num_classes = num_classes\n",
        "        self.use_tnet = use_tnet\n",
        "        self.pooling = pooling\n",
        "\n",
        "        if use_tnet:\n",
        "            self.tnet_conv1 = nn.Conv1d(3, 128, 1)\n",
        "            self.tnet_conv2 = nn.Conv1d(128, 256, 1)\n",
        "            self.tnet_conv3 = nn.Conv1d(256, 512, 1)\n",
        "            self.tnet_fc1 = nn.Linear(512, 256)\n",
        "            self.tnet_fc2 = nn.Linear(256, 128)\n",
        "            self.tnet_fc3 = nn.Linear(128, 9)\n",
        "            self.tnet_fc3.weight.data.zero_()\n",
        "            self.tnet_fc3.bias.data.copy_(torch.eye(3).view(-1))\n",
        "\n",
        "        self.conv1 = nn.Conv1d(3, 128, 1)\n",
        "        self.conv2 = nn.Conv1d(128, 256, 1)\n",
        "        self.conv3 = nn.Conv1d(256, 512, 1)\n",
        "        self.conv4 = nn.Conv1d(512, 1024, 1)\n",
        "        self.fc1 = nn.Linear(1024, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.fc4 = nn.Linear(128, num_classes)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        if x.dim() == 2:\n",
        "            x = x.view(batch_size, self.num_points, 3)\n",
        "\n",
        "        if self.use_tnet:\n",
        "            x_t = x.transpose(1, 2)\n",
        "            t = F.relu(self.tnet_conv1(x_t))\n",
        "            t = F.relu(self.tnet_conv2(t))\n",
        "            t = F.relu(self.tnet_conv3(t))\n",
        "            t = torch.max(t, dim=2)[0] if self.pooling == \"max\" else torch.mean(t, dim=2)\n",
        "            t = F.relu(self.tnet_fc1(t))\n",
        "            t = F.relu(self.tnet_fc2(t))\n",
        "            t = self.tnet_fc3(t).view(batch_size, 3, 3)\n",
        "            x = torch.bmm(x, t)\n",
        "\n",
        "        x = x.transpose(1, 2)\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = torch.max(x, dim=2)[0] if self.pooling == \"max\" else torch.mean(x, dim=2)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc3(x))\n",
        "        return self.fc4(x)\n",
        "\n",
        "\n",
        "# Count parameters\n",
        "model_base = PointNetForVerification()\n",
        "model_large = PointNetLarge()\n",
        "print(f\"PointNet Base:  {sum(p.numel() for p in model_base.parameters()):,} parameters\")\n",
        "print(f\"PointNet Large: {sum(p.numel() for p in model_large.parameters()):,} parameters\")"
      ],
      "metadata": {
        "id": "model-defs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Load Data and Model\n",
        "\n",
        "**Upload the following files to `/content/`:**\n",
        "- `pointnet.pth` (trained model)\n",
        "- `test_groups.npy` (test point clouds)\n",
        "- `test_labels.npy` (test labels)"
      ],
      "metadata": {
        "id": "data-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Create folders\n",
        "os.makedirs('models', exist_ok=True)\n",
        "os.makedirs('data/pointnet', exist_ok=True)\n",
        "\n",
        "# Copy files\n",
        "if os.path.exists('/content/pointnet.pth'):\n",
        "    shutil.copy('/content/pointnet.pth', 'models/pointnet.pth')\n",
        "if os.path.exists('/content/test_groups.npy'):\n",
        "    shutil.copy('/content/test_groups.npy', 'data/pointnet/test_groups.npy')\n",
        "if os.path.exists('/content/test_labels.npy'):\n",
        "    shutil.copy('/content/test_labels.npy', 'data/pointnet/test_labels.npy')\n",
        "\n",
        "print(\"Files:\")\n",
        "!ls -la models/\n",
        "!ls -la data/pointnet/"
      ],
      "metadata": {
        "id": "setup-files"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model\n",
        "MODEL_TYPE = \"base\"  # Change to \"large\" after training large model\n",
        "\n",
        "if MODEL_TYPE == \"large\":\n",
        "    model = PointNetLarge(num_points=64, num_classes=2, use_tnet=True, pooling=\"max\")\n",
        "else:\n",
        "    model = PointNetForVerification(num_points=64, num_classes=2, use_tnet=True, pooling=\"max\")\n",
        "\n",
        "checkpoint = torch.load('models/pointnet.pth', map_location='cpu', weights_only=True)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval()\n",
        "\n",
        "# Load data\n",
        "X_test = np.load('data/pointnet/test_groups.npy')\n",
        "y_test = np.load('data/pointnet/test_labels.npy')\n",
        "\n",
        "print(f\"Model: {MODEL_TYPE.upper()} ({sum(p.numel() for p in model.parameters()):,} params)\")\n",
        "print(f\"Test samples: {len(X_test)}\")\n",
        "print(f\"Labels distribution: GROUND={sum(y_test==0)}, OBSTACLE={sum(y_test==1)}\")"
      ],
      "metadata": {
        "id": "load-model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Verification Functions"
      ],
      "metadata": {
        "id": "verify-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def verify_robustness(model, sample, label, epsilon, timeout=120):\n",
        "    \"\"\"\n",
        "    Property 1: Local Robustness\n",
        "    Verify that classification does not change under L-inf perturbation.\n",
        "    \"\"\"\n",
        "    sample_flat = sample.T.flatten() if sample.shape == (3, 64) else sample.flatten()\n",
        "    x = input_vars(192)\n",
        "    y = output_vars(2)\n",
        "\n",
        "    input_constraint = (x >= sample_flat - epsilon) & (x <= sample_flat + epsilon)\n",
        "    output_constraint = y[label] > y[1 - label]\n",
        "\n",
        "    spec = VerificationSpec.build_spec(\n",
        "        input_vars=x, output_vars=y,\n",
        "        input_constraint=input_constraint,\n",
        "        output_constraint=output_constraint,\n",
        "    )\n",
        "\n",
        "    cfg = ConfigBuilder.from_defaults().set(\n",
        "        bab__timeout=timeout,\n",
        "        general__enable_incomplete_verification=True,\n",
        "        general__complete_verifier=\"bab\",\n",
        "        general__conv_mode=\"matrix\",\n",
        "        attack__pgd_order=\"before\",\n",
        "        attack__pgd_steps=100,\n",
        "        attack__pgd_restarts=30,\n",
        "    )\n",
        "\n",
        "    solver = ABCrownSolver(spec, model, config=cfg)\n",
        "    result = solver.solve()\n",
        "    verified = result.status in [\"safe\", \"safe-incomplete\", \"verified\", \"unsat\"]\n",
        "    return {\"status\": result.status, \"verified\": verified}\n",
        "\n",
        "\n",
        "def verify_safety(model, sample, epsilon, timeout=120):\n",
        "    \"\"\"\n",
        "    Property 2: Safety Property\n",
        "    For OBSTACLE samples: verify that no perturbation causes GROUND classification.\n",
        "    \"\"\"\n",
        "    sample_flat = sample.T.flatten() if sample.shape == (3, 64) else sample.flatten()\n",
        "    x = input_vars(192)\n",
        "    y = output_vars(2)\n",
        "\n",
        "    # Input: perturbed OBSTACLE\n",
        "    input_constraint = (x >= sample_flat - epsilon) & (x <= sample_flat + epsilon)\n",
        "    # Output: OBSTACLE (y[1]) > GROUND (y[0]) - i.e., never classified as GROUND\n",
        "    output_constraint = y[1] > y[0]\n",
        "\n",
        "    spec = VerificationSpec.build_spec(\n",
        "        input_vars=x, output_vars=y,\n",
        "        input_constraint=input_constraint,\n",
        "        output_constraint=output_constraint,\n",
        "    )\n",
        "\n",
        "    cfg = ConfigBuilder.from_defaults().set(\n",
        "        bab__timeout=timeout,\n",
        "        general__enable_incomplete_verification=True,\n",
        "        general__complete_verifier=\"bab\",\n",
        "        general__conv_mode=\"matrix\",\n",
        "        attack__pgd_order=\"before\",\n",
        "        attack__pgd_steps=100,\n",
        "        attack__pgd_restarts=30,\n",
        "    )\n",
        "\n",
        "    solver = ABCrownSolver(spec, model, config=cfg)\n",
        "    result = solver.solve()\n",
        "    verified = result.status in [\"safe\", \"safe-incomplete\", \"verified\", \"unsat\"]\n",
        "    return {\"status\": result.status, \"verified\": verified}\n",
        "\n",
        "\n",
        "print(\"Verification functions defined!\")"
      ],
      "metadata": {
        "id": "verify-funcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Property 1: Local Robustness Verification\n",
        "\n",
        "Test epsilon from 0.5cm to 20cm"
      ],
      "metadata": {
        "id": "prop1-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Property 1: Robustness\n",
        "# Epsilon values: 0.5cm to 20cm\n",
        "epsilons_robustness = [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.07, 0.10, 0.13]\n",
        "# 0.003 ~ 0.5cm, 0.005 ~ 0.75cm, 0.01 ~ 1.5cm, 0.02 ~ 3cm, 0.03 ~ 4.5cm\n",
        "# 0.05 ~ 7.5cm, 0.07 ~ 10.5cm, 0.10 ~ 15cm, 0.13 ~ 20cm\n",
        "\n",
        "n_samples = min(10, len(X_test))\n",
        "robustness_results = {}\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"PROPERTY 1: LOCAL ROBUSTNESS (L\u221e)\")\n",
        "print(\"Verifying: \u2200x' with ||x' - x\u2080||\u221e \u2264 \u03b5 : f(x') = f(x\u2080)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for eps in epsilons_robustness:\n",
        "    cm = eps * 150\n",
        "    print(f\"\\n\u03b5 = {eps} (~{cm:.1f} cm)\")\n",
        "    print(\"-\"*40)\n",
        "\n",
        "    verified_count = 0\n",
        "    unsafe_count = 0\n",
        "    timeout_count = 0\n",
        "    sample_details = []\n",
        "\n",
        "    for i in range(n_samples):\n",
        "        sample = X_test[i]\n",
        "        label = int(y_test[i])\n",
        "        label_str = \"GROUND\" if label == 0 else \"OBSTACLE\"\n",
        "\n",
        "        try:\n",
        "            result = verify_robustness(model, sample, label, eps, timeout=120)\n",
        "            if result[\"verified\"]:\n",
        "                verified_count += 1\n",
        "                status = \"\u2713 VERIFIED\"\n",
        "            elif \"timeout\" in result[\"status\"]:\n",
        "                timeout_count += 1\n",
        "                status = \"\u23f1 TIMEOUT\"\n",
        "            else:\n",
        "                unsafe_count += 1\n",
        "                status = f\"\u2717 UNSAFE ({result['status']})\"\n",
        "            sample_details.append({\"sample\": i, \"label\": label_str, \"status\": result[\"status\"], \"verified\": result[\"verified\"]})\n",
        "        except Exception as e:\n",
        "            timeout_count += 1\n",
        "            status = f\"\u26a0 ERROR\"\n",
        "            sample_details.append({\"sample\": i, \"label\": label_str, \"status\": \"error\", \"verified\": False})\n",
        "\n",
        "        print(f\"  Sample {i} ({label_str:8}): {status}\")\n",
        "\n",
        "    robustness_results[str(eps)] = {\n",
        "        \"epsilon\": eps,\n",
        "        \"cm\": cm,\n",
        "        \"verified\": verified_count,\n",
        "        \"unsafe\": unsafe_count,\n",
        "        \"timeout\": timeout_count,\n",
        "        \"verified_pct\": 100 * verified_count / n_samples,\n",
        "        \"samples\": sample_details\n",
        "    }\n",
        "\n",
        "    print(f\"  Summary: {verified_count}/{n_samples} verified ({100*verified_count/n_samples:.0f}%)\")"
      ],
      "metadata": {
        "id": "prop1-verify"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Property 2: Safety Property Verification\n",
        "\n",
        "Only for OBSTACLE samples: verify they never become GROUND"
      ],
      "metadata": {
        "id": "prop2-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Property 2: Safety\n",
        "# Same epsilon range\n",
        "epsilons_safety = [0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.07, 0.10, 0.13]\n",
        "\n",
        "# Get only OBSTACLE samples\n",
        "obstacle_indices = np.where(y_test == 1)[0]\n",
        "n_obstacle_samples = min(10, len(obstacle_indices))\n",
        "\n",
        "safety_results = {}\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"PROPERTY 2: SAFETY PROPERTY\")\n",
        "print(\"Verifying: \u2200x' with ||x' - x\u2080||\u221e \u2264 \u03b5 \u2227 f(x\u2080)=OBSTACLE : f(x') \u2260 GROUND\")\n",
        "print(f\"Testing on {n_obstacle_samples} OBSTACLE samples\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for eps in epsilons_safety:\n",
        "    cm = eps * 150\n",
        "    print(f\"\\n\u03b5 = {eps} (~{cm:.1f} cm)\")\n",
        "    print(\"-\"*40)\n",
        "\n",
        "    verified_count = 0\n",
        "    unsafe_count = 0\n",
        "    timeout_count = 0\n",
        "    sample_details = []\n",
        "\n",
        "    for idx in obstacle_indices[:n_obstacle_samples]:\n",
        "        sample = X_test[idx]\n",
        "\n",
        "        try:\n",
        "            result = verify_safety(model, sample, eps, timeout=120)\n",
        "            if result[\"verified\"]:\n",
        "                verified_count += 1\n",
        "                status = \"\u2713 SAFE (never GROUND)\"\n",
        "            elif \"timeout\" in result[\"status\"]:\n",
        "                timeout_count += 1\n",
        "                status = \"\u23f1 TIMEOUT\"\n",
        "            else:\n",
        "                unsafe_count += 1\n",
        "                status = f\"\u2620 UNSAFE - CAN BECOME GROUND!\"\n",
        "            sample_details.append({\"sample\": int(idx), \"status\": result[\"status\"], \"verified\": result[\"verified\"]})\n",
        "        except Exception as e:\n",
        "            timeout_count += 1\n",
        "            status = f\"\u26a0 ERROR\"\n",
        "            sample_details.append({\"sample\": int(idx), \"status\": \"error\", \"verified\": False})\n",
        "\n",
        "        print(f\"  Sample {idx} (OBSTACLE): {status}\")\n",
        "\n",
        "    safety_results[str(eps)] = {\n",
        "        \"epsilon\": eps,\n",
        "        \"cm\": cm,\n",
        "        \"verified\": verified_count,\n",
        "        \"unsafe\": unsafe_count,\n",
        "        \"timeout\": timeout_count,\n",
        "        \"verified_pct\": 100 * verified_count / n_obstacle_samples if n_obstacle_samples > 0 else 0,\n",
        "        \"samples\": sample_details\n",
        "    }\n",
        "\n",
        "    safety_status = \"\u2705 VERIFIED\" if unsafe_count == 0 else \"\u274c VIOLATED\"\n",
        "    print(f\"  Safety: {safety_status} ({verified_count}/{n_obstacle_samples} samples safe)\")"
      ],
      "metadata": {
        "id": "prop2-verify"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Results Summary"
      ],
      "metadata": {
        "id": "results-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"FINAL RESULTS SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Property 1 Table\n",
        "print(\"\\n### PROPERTY 1: LOCAL ROBUSTNESS ###\")\n",
        "print(f\"{'Epsilon':>8} | {'~cm':>6} | {'Verified':>10} | {'Unsafe':>10} | {'Timeout':>10}\")\n",
        "print(\"-\"*55)\n",
        "for eps_str, r in robustness_results.items():\n",
        "    print(f\"{float(eps_str):>8.3f} | {r['cm']:>5.1f}  | {r['verified_pct']:>8.0f}%  | {100*r['unsafe']/n_samples:>8.0f}%  | {100*r['timeout']/n_samples:>8.0f}%\")\n",
        "\n",
        "# Property 2 Table\n",
        "print(\"\\n### PROPERTY 2: SAFETY (OBSTACLE \u2192 never GROUND) ###\")\n",
        "print(f\"{'Epsilon':>8} | {'~cm':>6} | {'Safe':>10} | {'Unsafe':>10} | {'Status':>15}\")\n",
        "print(\"-\"*60)\n",
        "for eps_str, r in safety_results.items():\n",
        "    status = \"\u2705 VERIFIED\" if r['unsafe'] == 0 and r['timeout'] == 0 else (\"\u26a0 INCOMPLETE\" if r['timeout'] > 0 else \"\u274c VIOLATED\")\n",
        "    print(f\"{float(eps_str):>8.3f} | {r['cm']:>5.1f}  | {r['verified_pct']:>8.0f}%  | {100*r['unsafe']/n_obstacle_samples:>8.0f}%  | {status:>15}\")\n",
        "\n",
        "# Comparison with SLAM\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"COMPARISON WITH NSGA-III SLAM ATTACK\")\n",
        "print(\"=\"*70)\n",
        "print(\"\"\"\n",
        "| Perturbation | SLAM Error | Formal Verification |\n",
        "|--------------|------------|---------------------|\n",
        "| 0 cm         | 23 cm      | Baseline            |\n",
        "| 1.5 cm       | 32 cm      | Check \u03b5=0.01 above  |\n",
        "| 3.0 cm       | ~50 cm     | Check \u03b5=0.02 above  |\n",
        "| 4.5 cm       | ~70 cm     | Check \u03b5=0.03 above  |\n",
        "| 7.5 cm       | -          | Check \u03b5=0.05 above  |\n",
        "| 15 cm        | -          | Check \u03b5=0.10 above  |\n",
        "| 20 cm        | -          | Check \u03b5=0.13 above  |\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "results-summary"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save results\n",
        "final_results = {\n",
        "    \"timestamp\": datetime.now().isoformat(),\n",
        "    \"model\": MODEL_TYPE,\n",
        "    \"n_samples\": n_samples,\n",
        "    \"n_obstacle_samples\": n_obstacle_samples,\n",
        "    \"property1_robustness\": robustness_results,\n",
        "    \"property2_safety\": safety_results,\n",
        "}\n",
        "\n",
        "with open('verification_complete_results.json', 'w') as f:\n",
        "    json.dump(final_results, f, indent=2)\n",
        "\n",
        "print(\"Results saved to verification_complete_results.json\")\n",
        "\n",
        "# Download\n",
        "from google.colab import files\n",
        "files.download('verification_complete_results.json')"
      ],
      "metadata": {
        "id": "save-results"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Visualizations"
      ],
      "metadata": {
        "id": "viz-header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract data for plotting\n",
        "eps_cm = [r['cm'] for r in robustness_results.values()]\n",
        "robustness_pct = [r['verified_pct'] for r in robustness_results.values()]\n",
        "safety_pct = [r['verified_pct'] for r in safety_results.values()]\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Plot 1: Robustness\n",
        "ax1 = axes[0]\n",
        "ax1.plot(eps_cm, robustness_pct, 'b-o', linewidth=2, markersize=8, label='Robustness')\n",
        "ax1.axhline(y=50, color='r', linestyle='--', label='50% threshold')\n",
        "ax1.axvline(x=1.5, color='orange', linestyle=':', label='SLAM degradation (1.5cm)')\n",
        "ax1.axvline(x=4.6, color='red', linestyle=':', label='SLAM failure (4.6cm)')\n",
        "ax1.set_xlabel('Perturbation (cm)', fontsize=12)\n",
        "ax1.set_ylabel('Verified (%)', fontsize=12)\n",
        "ax1.set_title('Property 1: Local Robustness', fontsize=14)\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.set_ylim([0, 105])\n",
        "\n",
        "# Plot 2: Safety\n",
        "ax2 = axes[1]\n",
        "colors = ['green' if p == 100 else ('orange' if p > 50 else 'red') for p in safety_pct]\n",
        "ax2.bar(eps_cm, safety_pct, color=colors, alpha=0.7, width=0.8)\n",
        "ax2.axhline(y=100, color='green', linestyle='-', linewidth=2, label='Safety verified')\n",
        "ax2.axvline(x=1.5, color='orange', linestyle=':', label='SLAM degradation')\n",
        "ax2.axvline(x=4.6, color='red', linestyle=':', label='SLAM failure')\n",
        "ax2.set_xlabel('Perturbation (cm)', fontsize=12)\n",
        "ax2.set_ylabel('Safe Samples (%)', fontsize=12)\n",
        "ax2.set_title('Property 2: Safety (OBSTACLE \u2192 never GROUND)', fontsize=14)\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3, axis='y')\n",
        "ax2.set_ylim([0, 105])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('verification_results.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "files.download('verification_results.png')"
      ],
      "metadata": {
        "id": "viz-plot"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
